# 오늘 내가 배운 것들(Today I Learned)

- 4주차 과제를 진행했다.
---
1. 가상의 학생 성적 데이터를 활용한 데이터 전처리 과정 구현해보세요.

2. 가상 데이터셋을 생성한 뒤, 데이터셋을 학습, 검증, 테스트 데이터셋으로 분할해보세요.

3. 간단한 이진 분류 문제를 k-최근접이웃 알고리즘을 사용해 해결해보세요.

—- 선택 —-
4. OR, NOT 연산을 모델링해보세요. 

5. 논리연산 모델을 다 모아서 어떤 논리연산이라도 모델로 처리하는 AI 서버를 만들어보세요.
---
## 가상의 학생 성적 데이터를 활용한 데이터 전처리 과정 구현
```py
#1
#가상의 학생 성적 데이터 생성

import pandas as pd
import random
import numpy as np

# 학생 이름 목록
students = [f"학생_{i+1}" for i in range(10)]

# 랜덤 성적 생성 (0~100 사이)
data = {
    "이름": students,
    "수학": [random.randint(0, 100) for _ in range(10)],
    "과학": [random.randint(0, 100) for _ in range(10)],
    "영어": [random.randint(0, 100) for _ in range(10)],
    "역사": [random.randint(0, 100) for _ in range(10)],
}

# 데이터프레임 생성
df = pd.DataFrame(data)

# 랜덤하게 몇 개의 성적을 NaN으로 설정
for subject in ['수학', '과학', '영어', '역사']:
    null_indices = random.sample(range(10), 2)  # 2개의 랜덤 인덱스를 선택
    for index in null_indices:
        df.at[index, subject] = np.nan

# 데이터 출력
df
```
- 랜덤으로 데이터셋을 만들고 일부러 NaN값이 생성되도록 하였다.
---
```py
#결측치 정보
df.isna().sum()
```
- 결측치가 몇개인지 출력
---
```py
#이상치 제외
def replace_outliers(column):
    Q1 = column.quantile(0.25)
    Q3 = column.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    #이상치인 경우 NaN으로 대체
    return column.where((column >= lower_bound) & (column <= upper_bound),np.nan)

#각 과목의 이상치를 NaN값으로 대체
df['수학'] = replace_outliers(df['수학'])
df['과학'] = replace_outliers(df['과학'])
df['영어'] = replace_outliers(df['영어'])
df['역사'] = replace_outliers(df['역사'])

df['수학'] = df['수학'].fillna(df['수학'].mean()) #수학은 평균으로 대체
df['과학'] = df['과학'].fillna(df['과학'].median()) #과학은 중간값으로 대체
df['영어'] = df['영어'].fillna(df['영어'].mean()) #영어는 평균으로 대체
df['역사'] = df['역사'].fillna(0) #역사는 0값으로 대체

df
```

- 조건부선택문 `where` 을 이용해 이상치를 선별해서 널값으로 만들었다.
    > 조건부 선택 : column.where(condition, np.nan)은 주어진 condition이 True인 경우 해당 값을 유지하고, False인 경우 np.nan으로 대체

---
## 2 가상 데이터셋을 생성한 뒤, 데이터셋을 학습, 검증, 테스트 데이터셋으로 분할

```py
import pandas as pd
import random
from sklearn.model_selection import train_test_split

# 가상의 학생 성적 데이터 생성
students = [f"학생_{i+1}" for i in range(50)]  # 50명의 학생
data = {
    "이름": students,
    "수학": [random.randint(0, 50) for _ in range(50)],
    "과학": [random.randint(0, 50) for _ in range(50)],
    "영어": [random.randint(0, 50) for _ in range(50)],
    "역사": [random.randint(0, 50) for _ in range(50)],
}

# 데이터프레임 생성
df = pd.DataFrame(data)

#데이터셋을 학습, 검증. 테스트 데이터셋으로 분할
train_df, test_df = train_test_split(df, test_size=0.4, random_state=42)
train_df, val_df = train_test_split(train_df, test_size=0.5, random_state=42)

print(test_df) # 테스트 데이터 출력
print(val_df) # 검증 데이터 출력
print(train_df) # 학습 데이터 출력
```
---
## 간단한 이진 분류 문제를 k-최근접이웃 알고리즘을 사용해 해결

```py
#3
# k최점접알고리즘

import numpy as np
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 데이터 생성
x = np.array([
    [4.2, 0.1],[2.6, 6.9],
    [5.9, 0.3],[3.2, 8.1],
    [4.2, 3.1],[1.8, 7.3],
    [6.6, 5.6],[4.3, 3.2],
    [3.5, 4.2],[4.5, 1.5],
    [4.1, 6.0],[5.1, 1.8]
])
y = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])

# 데이터 분할
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
#샘플수가 2.4 -> 3개로 잡힌다

# KNN 모델 생성 및 학습
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(x_train, y_train)

# 예측
y_pred = knn.predict(x_test)

# 정확도 및 평가 지표 출력
accuracy = accuracy_score(y_test, y_pred)

print(f"예측결과: {y_pred}")
print(f"정확도: {accuracy:.2f}")
```
- 테스트 사이즈가 0.2 라서 총 12개*0.2 =2.4개, 즉 3개의 샘플이 테스트 데이터로 선별된다.
- 정확도는 (정확히 예측한 샘플수)/전체 테스트 샘플수 이다. 따라서 정확히 예측한 샘플수는 2개(클래스0), 전체 샘플 수는 3개가 되므로 2/3 = 0.67이 도출된다.
---

## OR & NOT 연산 모델링(선택)

- OR modeling

```py
import numpy as np
import pandas as pd

#OR modeling
x = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([0,1,1,1])

def Or_model(x):
    w = np.array([0.5,0.5]) #가중치 설정
    b = -0.2
    predictions = [] #예측값을 담을 리스트

    for k in x:
        tmp = np.dot(w,k) + b
        if tmp <= 0:
            predictions.append(0)
        else:
            predictions.append(1)
    return predictions

predictions = Or_model(x)
print(f"예측결과 : {predictions}")
```
-  만약 np.array([1,0.1]) 이면 -> tmp 값이 음수라서 0이 출력된다.
- np.sum(w.x)로 해버리면 요소별 곱을 한후, 합산하는 방식이다.
- KNN 모델에서는 비교적 간단한 .dot()으로 내적을 수행하는것이 일반적이다.
---
- NOT modeling

```py
import numpy as np
import pandas as pd

#NOT modeling
x = np.array([[0],[1]])
y = np.array([1,0])

def Not_model(x):
    w = np.array([-1]) #가중치
    b = 0.7
    predictions = [] #예측값을 담을 리스트

    for k in x:
        tmp = np.dot(w,k) + b
        if tmp <= 0:
            predictions.append(0)
        else:
            predictions.append(1)
    return predictions

predictions = Not_model(x)
print(f"예측결과 : {predictions}")
```


