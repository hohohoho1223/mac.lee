# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 토요일 보충수업을 했다.
- 주제는 AI를 활용한 API실습이었다.

---
## main.py
```py
#main.py
from typing import Union
from fastapi import FastAPI
import model # model.py를 가져온다
import torch

and_model = model.AndModel() # 그안에 있는 AndModel클래스의 인스턴스를 생성한다
or_model = model.OrModel()
xor_model = model.XorModel()

#API 서버 생성
app = FastAPI()

@app.get("/")
def read_root():
    return {"Hello": "World"}
    # return ["Hello": "World"]

@app.get("/items/{item_id}") #endpoint 엔드포인트 부르는 주소 -> 경로 파라메터인데 단순한 값만 넣을떄만 쓰는듯
# /items/{item_id} 경로
# item_id 경로 매개변수(파라미터)
def read_item(item_id: int, q: Union[str, None] = None):
    return {"item_id": item_id, "q": q}

##########################
@app.get("/predict/and/left/{left}/right/{right}") #model 실습
def predict(left: int, right: int):
    and_result = and_model.predict([left,right])
    return {"AND" : and_result}

@app.get("/predict/or/left/{left}/right/{right}") #model 실습    
def predict(left: int, right: int):
    or_result = or_model.predict([left,right])
    return {"OR" : or_result}

@app.get("/predict/xor/left/{left}/right/{right}") #model 실습    
def predict(left: int, right: int):
    xor_result = xor_model.predict([left,right])
    return {"XOR" : xor_result}
##########################

@app.post("/train/and") # 생성 기능은 POST로 진행
def train_and():
    and_model.train()
    return {"result": "and_train is okay!"}

@app.post("/train/or")
def train_or():
    or_model.train()
    return {"reult" : "or_train is okay!"}

@app.post("/train/xor")  # XOR 모델 학습 엔드포인트
def train_xor():
    xor_model.train() # train 메소드랑 다르기에 이름을 따로 지정...
    return {"result": "XOR model training is okay!!!!"}
```
- 한땀한땀 AND,OR,XOR 을 @app.get을 구현했다.

---

##model.py
```py
# model.py
import numpy as np
import pickle
import torch
import torch.optim as optim
import torch.nn as nn


class AndModel:
    def __init__(self):
        # 파라메터
        self.weights = np.random.rand(2)
        self.bias = np.random.rand(1)

    def train(self):
        learning_rate = 0.1
        epochs = 20
        inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
        outputs = np.array([0, 0, 0, 1])
        
        for epoch in range(epochs):
            for i in range(len(inputs)):
                total_input = np.dot(inputs[i], self.weights) + self.bias
                prediction = self.step_function(total_input)
                error = outputs[i] - prediction
                # 가중치와 편향 업데이트
                self.weights += learning_rate * error * inputs[i]
                self.bias += learning_rate * error

    def step_function(self, x):
        return 1 if x >= 0 else 0
    
    def predict(self, input_data):
        total_input = np.dot(input_data, self.weights) + self.bias
        return self.step_function(total_input)

    def save_model(self, filename):
        with open(filename, 'wb') as f:
            pickle.dump((self.weights, self.bias), f)

    def load_model(self, filename):
        with open(filename, 'rb') as f:
            self.weights, self.bias = pickle.load(f)


class OrModel:
    def __init__(self):
        self.weights = np.random.rand(2)
        self.bias = np.random.rand(1)

    def train(self):
        learning_rate = 0.1
        epochs = 20
        inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
        outputs = np.array([0, 1, 1, 1])
        
        for epoch in range(epochs):
            for i in range(len(inputs)):
                total_input = np.dot(inputs[i], self.weights) + self.bias
                prediction = self.step_function(total_input)
                error = outputs[i] - prediction
                
                # 가중치와 편향 업데이트
                self.weights += learning_rate * error * inputs[i]
                self.bias += learning_rate * error

    def step_function(self, x):
        return 1 if x >= 0 else 0
    
    def predict(self, input_data):
        total_input = np.dot(input_data, self.weights) + self.bias
        return self.step_function(total_input)

    def save_model(self, filename):
        with open(filename, 'wb') as f:
            pickle.dump((self.weights, self.bias), f)

    def load_model(self, filename):
        with open(filename, 'rb') as f:
            self.weights, self.bias = pickle.load(f)

class XorModel(nn.Module):
    def __init__(self):
        super(XorModel, self).__init__()
        self.fc1 = nn.Linear(2, 2)  # 입력층 -> 은닉층 
        self.fc2 = nn.Linear(2, 1)  # 은닉층 -> 출력층
        self.sigmoid = nn.Sigmoid()  # 활성화 함수

    def forward(self, x):
        x = self.sigmoid(self.fc1(x))
        x = self.sigmoid(self.fc2(x))
        return x

    def train(self, epochs=10000):
        xor_inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)
        xor_outputs = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)

        criterion = nn.BCELoss()  # 이진 교차 엔트로피 손실 함수
        optimizer = optim.SGD(self.parameters(), lr=0.1)

        for epoch in range(epochs):
            optimizer.zero_grad()  # 경량화
            outputs_pred = self(xor_inputs)  # 예측
            loss = criterion(outputs_pred, xor_outputs)  # 손실 계산
            loss.backward()  # 역전파
            optimizer.step()  # 파라미터 업데이트

            if epoch % 1000 == 0:
                print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}')
    # 예측
    def predict(self, input_data):  # 예측 메소드 추가
        with torch.no_grad(): #PyTorch의 자동 미분 기능이 비활성화 : 예측할 때는 그래디언트 계산이 필요하지 않기 때문
            input_tensor = torch.tensor(input_data, dtype=torch.float32)
            prediction = self(input_tensor).item()  # 예측값 반환(item()함수 : tensor값을 파이썬의 float형식으로 반환
            return 1 if prediction >= 0.5 else 0
        

if __name__ == "__main__": #해당 모듈에서 직접 실행될때를 명시함..!
    # AND 모델 학습
    and_model = AndModel()
    and_model.train()
    and_model.save_model('and_model.pkl')

    # OR 모델 학습
    or_model = OrModel()
    or_model.train()
    or_model.save_model('or_model.pkl')

    # XOR 모델 학습
    xor_model = XorModel()
    xor_model.train()
    torch.save(xor_model.state_dict(), 'xor_model.pth')  # 학습 후 모델 저장
```
--- 

- 여기가 진자 레전드였다.

- 우선 AND & OR과 다르게 XOR은 torch라이브러리를 사용했다.
    > 아마도 XOR은 비선형모델이니까?
- `with torch.no_grad()` PyTorch의 자동 미분 기능을 비활성화
    > 예측할 때는 그래디언트 계산이 필요하지 않기 때문
- `prediction = self(input_tensor).item()` 예측값 반환기능 
    > item() : tensor값을 파이썬의 float형식으로 반환
- AND,OR의 출력기준은 0인데, XOR의 기준은 0.5인 이유
    - AND,OR모델은 단순하게 이진 논리 연산을 수행함
        > 예측결과를 0&1로 직접 반환 가능
	- XOR 모델은 비선형관계를 학습함(신경망)
        > 이때 시그모이드 함수를 쓰기에, 0과 1사이의 '연속적인’값으로 산출되기에 확률로 해석되므로 0.5를 기준으로 둠
- `if name==“main”` 이게 뭐지?
    - 해당 모듈을 "main"으로 실행 시켜 발동됨
    - 다른 모듈에서 `import model`로 접근해오면, name은 model로 처리함.
        > '네임스페이스'와 유사한 개념

```py
if __name__ == "__main__":
    # AND 모델 학습
    and_model = AndModel()
    and_model.train()
    and_model.save_model('and_model.pkl')

    # OR 모델 학습
    or_model = OrModel()
    or_model.train()
    or_model.save_model('or_model.pkl')

    # XOR 모델 학습
    xor_model = XorModel()
    xor_model.train()
    torch.save(xor_model.state_dict(), 'xor_model.pth')  # 학습 후 모델 저장
```
- 그래서 코드를 다시 보면 해당 model.py 모듈을'직접' 실행해야 해당 코드가 돌아가며, 더 나아가 저장한 모델 파라미터는 나중에 다른 스크립트나 모듈에서 `load_model` 메소드를 호출하여 불러올 수 있다!
- 끝!!!!