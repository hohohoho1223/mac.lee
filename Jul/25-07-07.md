# 오늘 내가 배운 것들(Today I Learned)

- FastAPI: 멀티스레드 웹 서버 (메인 프로세스)
- RQ Worker: 별도의 프로세스로 실행되는 작업 처리기
- Redis: 메시지 큐 역할
- vLLM: 별도의 프로세스로 실행되는 LLM 서버

### 서버 한번에 실행 하는법

```python
# 모든 서비스 시작
./start_services.sh
# 서비스 상태 확인
./status_services.sh
# 모든 서비스 중지
./stop_services.sh
```

1. 자동 관리:
    - PID 파일로 프로세스 추적
    - 로그 파일 자동 생성
    - 포트 사용 확인
    - 안전한 시작/종료
2. 확장성:
    - RQ 워커 개수 조정 가능
    - 각 서비스별 독립적 관리
3. 모니터링:
    - 실시간 상태 확인
    - 리소스 사용량 모니터링
    - 로그 파일 관리

---

### 피드백 PUB/SUB 설정?

- 현재는 Redis Queue만사용하고 있는중.

```python
# feedback_router.py
from rq import Queue
from redis import Redis

# Redis 연결 및 큐 생성
redis_conn = Redis(host='localhost', port=6379, db=0)
feedback_queue = Queue('feedback', connection=redis_conn)

# 작업을 큐에 등록
job = feedback_queue.enqueue('Text.LLM.model.feedback.tasks.generate_feedback_task', request.model_dump())
```

- 예외처리 문제점

> 현재 구조에서 RQ 워커의 예외처리를 FastAPI에서 직접 처리할 수 없는 이유

```python
# FastAPI 서버 (프로세스 A)
@router.post("/ai/feedback")
async def create_feedback(request: FeedbackRequest):
    # 작업을 큐에 등록하고 즉시 202 응답
    job = feedback_queue.enqueue('generate_feedback_task', request.model_dump())
    return JSONResponse(status_code=202, ...)  # 여기서 끝!

# RQ 워커 (프로세스 B) - 별도 프로세스에서 실행
def generate_feedback_task(data):
    try:
        # 피드백 생성 로직
        feedback_result = asyncio.run(feedback_model.generate_feedback(data))
        # 콜백 전송
    except Exception as e:
        print(f"오류 발생: {e}")  # 로그만 남기고 끝
        raise  # 예외를 다시 발생시킴
```

#### 문제점 과 해결방안

- 문제점1:  워커 예외가 클라이언트에게 전달되지 않음
  - FastAPI는 이미 202 응답을 보냈기 때문에 워커에서 발생한 예외를 클라이언트에게 알릴 수 없음
  - 워커가 실패해도 클라이언트는 "성공적으로 요청이 접수되었습니다"라는 응답만 받음
- 문제점2: 예외 상황 추적 불가
  - 워커에서 발생한 예외를 FastAPI 서버에서 실시간으로 모니터링하기 어려움
  - 작업 상태를 확인하려면 별도의 모니터링 시스템 필요

---

## Redis Queue → Google cloud Pub/Sub 도입

- 구조도

![IMG_5396.heic](https://resv2.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/A30D4FB3-EE1E-41A9-ABB1-A2BC2B7F20BD_2/omWyOUWBZyB5zA61qG1AryUhlxywf7PQ6NioVFuV5n8z/IMG_5396.heic)

- 예외처리 발생시, 내가 BE한테 

```python
{
memberId: 3,
content: 502
}
```

- 이런 형태로 기존 피드백 내용 대신, `StatusCode` 를 보내기로 했다.
> BE에서 DLQ처리

### 생성된 파일들

1. gcp_pubsub_worker.py - 피드백 요청 구독 및 처리
2. publisher_ai_to_be.py - AI에서 백엔드로 결과 발행
3. publisher_be_to_ai.py - 백엔드에서 AI로 요청 발행
4. start_gcp_pubsub_worker.sh - 워커 시작 스크립트
5. test_gcp_pubsub.py - 테스트 스크립트

### 메세지 흐름

- Wren: BE , Mac(본인): AI

```python
[Wren] ──▶ [Mac]:
leafresh-feedback-topic ──▶ leafresh-feedback-sub (구독자: Mac)

[Mac] ──▶ [Wren]:
leafresh-feedback-result-topic
  └──▶ leafresh-feedback-result-sub (구독자: Wren)
        └──(DLQ)▶ leafresh-feedback-result-dlq-topic ─▶ leafresh-feedback-result-dlq-sub
```

### 기존 Redis Queue 아키텍쳐

```plaintext
┌─────────────────────────────────────────────────────────────┐
│                    FastAPI 서버 (포트 8000)                  │
│  ┌─────────────────┐  ┌─────────────────┐  ┌──────────────┐ │
│  │   feedback_router│  │   Redis Queue   │  │   RQ Worker  │ │
│  │   (API 엔드포인트)│  │   (메모리 큐)   │  │   (별도 프로세스)│ │
│  └─────────────────┘  └─────────────────┘  └──────────────┘ │
└─────────────────────────────────────────────────────────────┘
                                │
                                ▼
                    ┌─────────────────┐
                    │   Redis 서버    │
                    │   (포트 6379)   │
                    └─────────────────┘
```

### 각 컴포넌트 역할
    1. FastAPI 서버 (포트 8000)
        - feedback_router.py에서 요청 받음
        - Redis Queue에 작업 등록: feedback_queue.enqueue()
        - 즉시 202 응답 반환
    2. Redis 서버 (포트 6379)
        - 큐 데이터 저장소
        - 별도 프로세스로 실행
    3. RQ Worker (별도 프로세스)
        - rq worker feedback 명령으로 실행
        - Redis Queue에서 작업 꺼내서 처리
        - tasks.py의 generate_feedback_task() 실행

## Redis Queue vs GCP Pub/Sub 비교

1. Redis Queue 방식(기존)

> FastAPI가 징검다리 역할 이었음ㅇㅇ

```plaintext
1. 클라이언트 → FastAPI 서버 (포트 8000)
2. FastAPI → Redis Queue (localhost:6379) 
3. RQ Worker → Redis Queue에서 작업 꺼냄
4. RQ Worker → LLM 처리
5. RQ Worker → BE 서버로 콜백
```

2. GCP Pub/Sub 방식(현재)

> FastAPI 없이 직접 Pub/Sub 통신ㅇㅇ

```plaintext
1. 백엔드(Wren) → GCP Pub/Sub 토픽에 직접 발행
2. AI(Mac) 워커 → GCP Pub/Sub 구독
3. AI 워커 → LLM 처리  
4. AI 워커 → GCP Pub/Sub 결과 토픽에 발행
5. 백엔드 → GCP Pub/Sub 결과 구독
```

| **구분** | **Redis Queue**   | **GCP Pub/Sub**        |
| ------ | ----------------- | ---------------------- |
| 서버     | 로컬 Redis 서버       | GCP 관리형 서비스            |
| 워커     | 별도 RQ Worker 프로세스 | 별도 Pub/Sub Worker 프로세스 |
| 메시지 보장 | ❌ 손실 가능           | ✅ at-least-once        |
| 재시도    | ❌ 수동 구현 필요        | ✅ 자동 재시도               |
| DLQ    | ❌ 없음              | ✅ 자동 DLQ               |
| 스케일링   | ❌ 수동              | ✅ 자동                   |

- DLQ:

> Dead Letter Queue의 약자로, 처리 실패한 메시지를 따로 저장해두는 큐

#### 차이점

- 기존: FastAPI가 중간 다리 역할을 했고, Redis Queue는 로컬 메모리에 데이터 저장
- 현재: FastAPI 없이 백앤드와 AI가 직접 GCP Pub/Sub으로 통신, 데이터는 클라우드에 저장      

| **구분** | **Redis Queue**          | **GCP Pub/Sub**             |
| ------ | ------------------------ | --------------------------- |
| 요청 경로  | 클라이언트 → FastAPI → Redis  | 백엔드 → GCP Pub/Sub           |
| 응답 경로  | RQ Worker → BE 서버 (HTTP) | AI 워커 → GCP Pub/Sub → 백엔드   |
| 중간 다리  | FastAPI 서버               | 없음 (직접 통신)                  |
| 메시지 저장 | 로컬 Redis                 | GCP 클라우드                    |
| 워커 실행  | rq worker feedback       | python gcp_pubsub_worker.py |

### 실행 방법

- 다음 중 하나를 선택해주세요:

  1. 권한 부여 후 실행: 

```plaintext
chmod +x start_gcp_pubsub_worker.sh
```

- chmod +x start_gcp_pubsub_worker.sh 명령어는 start_gcp_pubsub_worker.sh 파일에 실행 권한을 부여하는 명령

  2. 직접 실행: 

```plaintext
bash start_gcp_pubsub_worker.sh
```

### 왜 필요한가?

- 리눅스/유닉스 계열 시스템에서는 스크립트 파일(예: .sh 파일)을 실행하려면 실행 권한이 있어야 함
- 실행 권한이 없으면 bash: ./start_gcp_pubsub_worker.sh: Permission denied와 같은 에러가 발생함
- chmod +x를 해주면, 터미널에서 ./start_gcp_pubsub_worker.sh로 바로 실행할 수 있음