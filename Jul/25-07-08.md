# 오늘 내가 배운 것들(Today I Learned)

- 추후에 피드백 모델 과 챗봇 모델을 따로 로드 할거다.
- 이유:
  - vLLM은 파인튜닝해서 허깅페이스에서 업로드 후 다시 다운 받을거임.
  - 피드백은 Pub/Sub사용으로 4비트 양자화 모델 로드로 메모리에 적재할거임
  - 아 근데 피드백 모델(4비트 양자화) 7GB + 챗봇 모델 (vLLM) 20GB > 23GB(L4 환경)
  - 당연히 OOM이 떴다ㅋ

![Image.png](https://resv2.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/93B44191-0571-4B40-9E63-340526946389_2/88QVO8QqyNiLYIzL6OPR71ctDfbyxdCB8xnFFdySycgz/Image.png)

- 아 그러면 우선 vLLM 메모리 최적화를 해보자!

```plaintext
     python3 -m vllm.entrypoints.openai.api_server \
       --model ... \
       --host 0.0.0.0 \
       --port 8800 \python3 -m vllm.entrypoints.openai.api_server \
  --model /home/ubuntu/mistral/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db \
  --host 0.0.0.0 \
  --port 8800 \
  --gpu-memory-utilization 0.5
       --gpu-memory-utilization 0.5
```

### 실행!!!!

- 결과는:

![Image.png](https://resv2.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/0DEC90B9-589B-4D75-89CD-4415D6F0B044_2/tHePOJOykRgkSG93ufE21nDDRa8521ipEN6H2LA9ib8z/Image.png)

- 실패~

### 에러 메세지 요약:

“`ValueError: No available memory for the cache blocks. Try increasing gpu_memory_utilization when initializing the engine.` “

- 모델은 13.5GB 정도로 잘올라갔는데
- 남은 GPU메모리(약2~3GB)로는 KV 캐시(Attention Cache)를 할당할 수 없어서 실패

### 해결방안:

### KV 캐시 크기(시퀀스 길이, batch size 등) 줄이기

- vLLM의 --max-model-let(기본 32768) 값을 줄이면 캐시 메모리 사용량이 줄어든다고함
- 아래와 같이 `--gpu-memory-utilization 0.6 --max-model-len 8192` 로 실행 해보았다.

```plaintext
python3 -m vllm.entrypoints.openai.api_server \
  --model /home/ubuntu/mistral/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db \
  --host 0.0.0.0 \
  --port 8800 \
  --gpu-memory-utilization 0.6 \
  --max-model-len 8192
```

## 1. `—gpu-memory-utilization` 

- 의미:
  - vLLM이 전체 GPU 메모리 중 몇 %까지 사용할지 결정
  > (예: 0.5면 50%, 0.7이면 70%까지 사용)

- 낮추면?
  - 모델 파라미터와 KV 캐시 모두 적은 메모리만 사용
  - 여러 프로세스가 GPU를 나눠쓸 때 유리
  - 너무 낮추면 모델은 올라가도 캐시가 부족해서 서비스 불가(OOM/캐시 에러)

- 올리면?
  - 모델과 KV 캐시 모두 더 많은 메모리 사용
  - 단일 vLLM 서버에 최적
  - 너무 높이면 OOM(Out Of Memory) 발생

---

## 2. `—max-model-len` 

- 의미:
  - 한 번에 처리할 수 있는 최대 토큰 길이(컨텍스트 길이)
  > (예: 32768이면 32K 토큰까지, 8192면 8K 토큰까지)

- 줄이면?
  - KV 캐시(Attention Cache) 메모리 사용량이 크게 감소 
  - 긴 문장/문서 처리는 제한되지만, 더 많은 동시 요청/긴 서비스 가능
- 늘리면?
  - 더 긴 문장/문서 처리 가능
  - KV 캐시 메모리 사용량이 급격히 증가 → OOM/캐시 부족 에러 발생 가능

---

## 왜 두 옵션을 조절해야 하나?

- vLLM은 모델 파라미터 + KV 캐시(토큰별 Attention 메모리)를 모두 GPU에 올려야 함

> `—max-model-len(=max_seq_len)` 은 모델 파라미터와는 별개로

> “KV 캐시(토큰별 Attention 메모리)의 크기에만” 직접적인 영향을 줌

## 상세 설명

1. 모델 파라미터
    - 모델 파라미터(weights)는 모델 크기(예: Mistral-7B)로 결정됨
    - \--max-model-len과는 무관하게, 모델이 GPU에 올라갈 때 항상 고정된 메모리 차지
2. KV 캐시(Attention Cache)
    - KV 캐시는 "현재 대화/문서에서 몇 토큰까지 기억할 수 있나"를 결정
    - \--max-model-len이 커질수록, 각 요청마다 더 많은 토큰의 Attention 결과를 저장해야 하므로
    → KV 캐시 메모리 사용량이 선형적으로 증가

    - 예시:
    - 4K(4096) → 8K(8192) → 16K(16384)로 늘릴수록 캐시 메모리 2배, 4배로 증가
3. 전체 GPU 메모리 사용 구조
    - 총 사용량 = 모델 파라미터 + KV 캐시
    - \--gpu-memory-utilization은 이 둘의 합이 GPU 전체의 몇 %까지 쓸지 결정

- 여러 프로세스가 GPU를 나눠쓰면(예: 피드백 모델 + vLLM), 각 프로세스가 사용할 수 있는 메모리가 줄어듦
- `—gpu-memory-utilization`을 올리면

    → vLLM이 더 많은 메모리를 확보해서 캐시까지 할당 가능

    → 단, 너무 높이면 OOM

- `—max-model-len` 을 줄이면

    → 캐시 메모리 사용량이 줄어들어, 적은 메모리로도 서비스 가능

---

- 아래와 같이 설정값을 조정해봤다.

```plaintext
python3 -m vllm.entrypoints.openai.api_server   
--model /home/ubuntu/mistral/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db
--host 0.0.0.0   --port 8800
--gpu-memory-utilization 0.7   --max-model-len 2048
```

- 결과:

> 아래와 같이 약 16기가나 사용한다ㄷㄷ

![Image.png](https://resv2.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/75DD141E-B4AF-47AD-9562-D5BE6E835D49_2/xBx87kz2xMyyiktBIV1aVPe4mGoOAOCt1NBNKn2gSJUz/Image.png)

- 다시 아래와 같이 조정해서  적재해봤다.
  - \--gpu-memory-utilization: 0.7 → 0.5로 하향 조정 

```plaintext
python3 -m vllm.entrypoints.openai.api_server   --model /home/ubuntu/mistral/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db
--host 0.0.0.0   --port 8800   
--gpu-memory-utilization 0.5   --max-model-len 2048
```

- 결과:

> 에러남ㅎ
> 아니 --gpu-memory-utilization 0.5로 낮췄고 오히려 메모리도 피드백 모델 안올라간 상태여서 널널한데 왜이러지?

![Image.png](https://resv2.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/3C6EA206-CAE2-4E5E-9BF3-B4350DD31995_2/Vy0YC4DAbcdCrNDl6rjUqRspmxWhympbdffOiBSmqzYz/Image.png)

---

### 원인은 다른곳에,,,

- 평소에 `pip install -r requirements.txt` -> `pip install vllm` 진행했었다.
- 이유는 vllm 설치시 torch가 필요하다고 해서 torch가 있는 requirements루ㅡㄹ 먼저 설치 후 , 이어서 vllm 설치하면 되는줄 알았다.

## 왜 이 순서가 문제가 될 수 있나?

1. vLLM은 설치 시 torch, transformers, bitsandbytes 등 여러 패키지의 “최소/최적 버전”을 요구함
2. requirements.txt에서 이미 설치된 패키지 버전이 vLLM이 요구하는 버전과 다르면, pip가 vLLM 설치 시 기존 패키지를 업그레이드/다운그레이드 하거나 심지어 서로 호환되지 않는 버전이 섞여서 런타임 오류가 발생할 수 있음

> 이 때문에, 기존 서비스는 requirements.txt의 패키지 버전 기준으로 잘 동작하지만 vLLM 실행 시에는 “패키지 충돌”로 인해 오류가 발생할 수 있음

### 싹다 requirements에 갖다 박고 호환성 맞춰보자 → 포기ㅇㅇ

- 왜냐면 내가 피드백 모델을 양자화 모델로 모델 로드하고 vLLM 챗봇 모델을 동시에 적재하려 하는 상황
- vLLM 설치시 PyTorch를 먼저 다운 받아야 하는 상황에 `requirements.txt` 파일에 있는 환경변수들이 특히 vLLM에서 내부적으로 요구하는 torch, transformers,acceleraate의 특정 버전과 충돌이 발생
- 따라서 vLLM(챗봇)과 기존 4비트 양자화 모델(피드백) 코드를 같은 Python 환경에서 동시에 돌릴 수가 없다
- vLLM 서버는 별도의 가상환경(venv or conda)에서 띄우던가 서버를 분리해야함
- 서버를 또 분리? 흠...안된다

---

### 결론:피드백 답변 생성에도 vLLM 적용시키자