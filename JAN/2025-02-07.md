# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 2주차 팀원들과 딥다이브를 진행하였다.
- 내가 맡은 주제는 'Pandas의 누락 데이터 처리 기능이 데이터 정리에 어떤 이점을 제공하는지 설명하시오.'이다.
    ## 누락값이란?
    - 누락값은 NaN NAN nan 처럼 표기하며 아예 존재하지 않는 값임
    - 심지어 자기 자신과 비교도 할수가 없음(False 출력)
    ```python
    print(0 == NaN)
    print(True == NaN)
    print(False == NaN)
    print('' == NaN)
    print(None == NaN)
    print(NaN == NaN)
    print(nan == NaN)
    print(NAN == NaN)
    ```
    - 모든 출력값은 False로 나온다.

- 그 중에서, Missing Value를 처리하는 7가지 방법(Time-series 미포함)에 대해 알아보았다.
    1. 아무것도 안하기

        - 일부 알고리즘([xgboost](https://bommbom.tistory.com/entry/Boosting-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-XGBoost-%ED%8A%B9%EC%A7%95-%EB%B0%8F-%EC%9E%A5%EB%8B%A8%EC%A0%90#XGBoost_%EB%9E%80?)) : 결측 값을 고려하여 학습함
        - 무시 알고리즘(LightGBM의 use_missing = false) : 결측 값을 무시하는 파라미터 대입
        - 하지만 Sklearn 의 LinearRegression은 결측값 처리 알고리즘이 없기에 누락된 데이터를 처리해야함


	2. 누락된 데이터 제거

        - 그러나 중요한 정보를 같이 삭제할수도 있어서 위험함

	3.  평균/중앙값 대입

        - 결측치가 없는 다른컬럼의 평균이나 중앙값으로 대체하것(**숫자형 데이터에만 사용**)


	4. 최빈값 / 0 / 지정값 대입

        - 최빈값 : 범주형에도 잘 동작함

        - 0 값으로 대입

        - 지정한 상수값으로 대체

        - 장점 : categorical(범주형) 특성에 잘 동작함

        - 단점 : 다른 특성간의 상관관계가 고려되지 않으며 데이터 편향이 생길수 있음

	5. K-NN(k nearest neighbors) 대입

        - classification에 사용되는 알고리즘

        - ‘feature similarity'를 이용하여 가장 닮은 데이터 k개를 찾음

    ```python
    #impyute 라이브러리 사용
    from impyute.imputation.cs import fast_knn
    np_imputed =fast_knn(df_null.values, k =5)
    df_imputed = pd.DataFrame(np_imputed)
    
    df_imputed.head() #확인
    ```


        - K-D Tree를 생성한 후 가장 가까운 이웃(NN)을 탐색  

        - K개의 NN을 찾은 뒤 거리에 따라 가중치(평균)를 부여함


	6.  MICE(Multivariate Imputation by Chained Equation) 대입

        - 누락된 데이터를 여러 번 채우는 방식으로 작동함

        ![image](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/D5EBD83E-946A-49FD-B1CE-0BA89D5C6A80_2/lospEcA56yUZMBPD1ylRNKyGmQOTt5x0fEzleoyC0Fsz/Image.png)

        - Multiple Imputation(MI)는 불확실성을 고려했을때 chained equation 접근법은 매우 유연하여 연속형, 이진형, 범위형, survey skip 패턴도 처리가능함

        - survey skip 패턴이란?

            → 사용자가 특정 조건에만 대답할수 있도록 질문을 생략하는것 

            ex) ”오늘 음주운전 했습니까?” → “아니오” 답변시 추후 질문 생략

        - Imputation : distribution 을 바탕으로 m개의 데이터셋을 대입

        - Analysis : 완성된 m개의 데이터셋 분석

        - Pooling : 평균, 분산, 신뢰 구간을 계산하여 결과를 취합

    ```python
    from impyute.imputation.cs import mice
    np_imputed = mice(df_null.values) #mice학습
    df_imputed = pd.DataFrame(np_imputed)
    
    df_imputed #확인
    ```

    7. Deep Learning을 이용한 imputation /Datawig

        - DNN을 이용하여 머신러닝 모델을 학습 & 널값 유추

    ```python
    import datawig
    imputer = datawig.SimpleImputer(
      imput_columns = [1,2,3,4], #impute에 사용할 컬럼을 지정해줄수 있음.
      output_columns = 0 #컬럼 0에 missing_value 를 채우기
      )
    imputer.fit(train_df = df_null, num_epochs = 50)
    df_null_only = df_null[df_null[0].isnull()]
    np_imputed = imputer.predict(df_null_only)
    df_imputed = pd.DataFrame(np_imputed)
    
    df_imputed #확인
    ```

        - 한번 실행시 하나의 column 에 대해서만 가능함.

        - 대규모 데이터 셋의 경우 속도가 매우 느릴수 있음.

        - 유추할 특성에 관련된 정보가 들어있는 다른 특성들을 직접 지정해야함.
