# 오늘 내가 배운 것들(Today I Learned)

- 전이학습 : 이미 학습된 모델을 다른 작업에 투입 시키는 것
- 파인튜닝 : 좀더 해당 LLM모델 컨셉(특정 분야)에 맞게 특화(추가적인 학습) 시키는 것
    - 파인튜닝은 전이학습의 일부이다
- 파인튜닝을 하려면 `질문 - 답변` 형태로 작업이 이루어져야한다 → 근데 검증은 누가하는가?→ 해당 전문가가 해야한다 
    - 따라서 현재 진행중인 파이널 프로젝트 “Leafresh”도 친환경 챌린지에 대해 숙지하고 있어야 한다
- 아래 코드 중, `temperature` , `top_p` , `frequency_panelty` , `presence_penalty` 이게 뭘까?

```python
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "바다에 관한 시를 써줘"}],
    temperature=0,
    max_tokens=300,
    top_p = 0.9,
    frequency_panelty = 0,
    presence_penalty = 0
)
```

- `temperature` : 확률 분포를 넓게 / 좁게 퍼뜨리는것 (높을 수록 답변이 다양)
- `top_p` : 가장 확률 높은 단어들의 누적합(p%) 안에서만 선택하여 답변(p=1.0이면 모든 후보)
    - 예시

| **단어** | **확률** |
| ------ | ------ |
| “고양이”  | 60%    |
| “강아지”  | 25%    |
| “코끼리”  | 10%    |
| “거북이”  | 5%     |

- 만약, `top_p = 0.9` 이라면 : 60%(”고양이”) + 25%(“강아지”) = 85% < 90% 이므로 두개만 고려함
- `frequency_panelty=0` : 같은 단어 여러 번 반복하는 걸 방지
    - “봄이는 귀엽다. 봄이는 차타는걸 무서워 한다"
    - (0이 기본값 , 올라갈 수록 반복 싫어함)
- `presence_panelty =0` : “한 번”이라도 나오면 다신 안쓰려고 함
    - "봄이는 귀엽다” → 이후 "봄이”라는 단어를 피하려고 함
    - (0이 기본값 , 올라갈 수록 재등장 싫어함)

## RAG 구현 과정 중

- 정보검색 : 해당 쿼리와 관련된 정보를 DB나 인터넷에서 찾는 과정
    - 유사도 검색 : 사용자가 입력한(쿼리) 단어나 구를 데이터베이스나 인터넷에서 직접 찾는 방식식
    - 시맨틱 검색 : 단순 유사도 처리보다 훨씬 복잡한 알고리즘일 필요(문맥을 파악해야하기에)
    - 랭킹 처리 : 모델이 생성할 텍스트와 유사도가 가장 높은 정보를 선택하는 과정
        1. 유사도 계산 : 코사인 유사도 사용
        2. 문맥과 의도 파악
        3. 랭킹 산출

- 시맨틱 검색과 정보 검색의 차이점을 잘 모르겠어서 찾아봤다.

| **구분**    | **랭킹 처리 (Ranking)**                  | **시맨틱 검색 (Semantic Search)**         |
| --------- | ------------------------------------ | ------------------------------------ |
| **목적**    | 이미 검색된 결과를 “중에서” 더 좋은 순서로 정렬         | 질문의 의미를 이해해서 “관련 있는 결과”를 찾음          |
| **핵심 기능** | 점수 매기기, 순서 정렬 (Scoring, Ranking)     | 의미 기반 유사성 검색 (Embedding, Similarity) |
| **입력**    | (1) 이미 검색된 결과 + (2) 각 결과의 점수         | (1) 사용자 질문(텍스트)                      |
| **출력**    | 입력된 결과를 “순서만” 바꾼 리스트                 | “새로 찾아낸” 관련 문서 리스트                   |
| **기술**    | BM25 스코어, Learning to Rank, 재정렬 알고리즘 | 임베딩(벡터화), 코사인 유사도, 벡터 검색             |
| **대표 예시** | 구글 검색 결과 1~10위 재정렬                   | 질문 “파란 하늘” → “맑은 날씨” 문서 검색           |

- 정리하자면
    - 시맨틱 검색 : 어떤 자료를 찾을지 결정하는 것
    - 랭킹 검색 : 이미 찾은 자료를 어떻게 순위를 매길건지 결정하는 것
    
## 벡터 데이터 베이스

- 사용자 질문 : “배송 상태를 어떻게 확인해?”
- 해당 질문은 임베딩되어 벡터로 변환됨ㅇㅇ
- 그 이후에 벡터 데이터베이스에 다음과 같이 질의를 함

```python
POST/ search
{
  "query_vector": [0.12,-0.24, ..., 0.78],
  "top_k": 5
}
```

- 여기서 `top_k` 는 반환 받고자 하는 가장 유사한 문서의 수(참고할 문서 수)
> 내가 파이널 프로젝트에서 쓸 벡터DB는 Qdrant(쿼드란트)이다.