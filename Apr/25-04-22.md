# 오늘 내가 배운 것들(Today I Learned)

-  오늘은 내가 맡은 모델:
    - 사용자 맞춤형 챌린지 추천 챗봇
    - 사용자 참여 기반 주간 피드백 생성 모델
- 이 두가지 모델에 대해서 다음과 같은 LangChain 기반 멀티스텝 AI구현 검토를 해야한다  
    - LangChain이나 유사 프레임워크를 활용하여 설계한 AI 추론 흐름도 (체인의 각 단계와 작동 방식 설명).
    - 체인 내에서 사용된 도구나 외부 리소스(예: 위키백과 검색, 계산기 API 등)가 있다면 무엇을 어떻게 활용했는지 명시.
    - 실제 구현한 코드의 일부 (프롬프트 구성 또는 LangChain 체인 정의 부분 등) 또는 의사코드.
    - 서비스를 위해 멀티스텝 체인을 도입한 경우, **그에 따른 장점** (예: 답변 정확도 향상, 복잡한 작업 자동화 등)과 **서비스 기능과의 연관성**에 대한 설명

---

###  LangChain이나 유사 프레임워크를 활용하여 설계한 AI 추론 흐름도 (체인의 각 단계와 작동 방식 설명)

# 1.  /ai/chatbot/select-category

1.1. LangChain이나 유사 프레임워크를 활용하여 설계한 AI 추론 흐름도 (체인의 각 단계와 작동 방식 설명)

```mermaid
graph LR
    A[사용자 입력<br/>(거주 환경, 직군, 카테고리)] --> B[프롬프트 템플릿 생성]
    B --> C[LLM 호출 (카테고리 기반 추천)]
    C --> D[추천 결과 생성<br/>(3개 챌린지)]
    D --> E[Output Guardrails 필터링]
    E --> F[최종 응답 반환]
```

- 다이어그램 설명

| **A** | 사용자가 /select-category에 요청 전송              |
| ----- | ----------------------------------------- |
| B     | 입력값을 기반으로 미리 설계된 프롬프트 템플릿을 구성             |
| C     | 해당 템플릿을 LLM에게 전달하여 추천을 생성                 |
| D     | 추천된 챌린지 리스트 (예: 텀블러 사용, 장바구니 지참 등)가 생성    |
| E     | Output Guardrails를 통해 무의미하거나 부적절한 응답을 필터링 |
| F     | 최종적으로 클라이언트에 JSON 형식으로 응답을 전달             |

1.2. 체인 내에서 사용된 도구나 외부 리소스

| 구성요소           | *도구/리소스*                                  | 사용방              | 설명                                       |
| -------------- | ----------------------------------------- | ---------------- | ---------------------------------------- |
| **프롬프트 템플릿 구** | LangChain.PromptTemplate *(또는 자체 문자열 처리)* | 사용자 입력값을 템플릿화    | 예: "사용자는 {category}에 관심이 있습니다. 추천해 주세요." |
| **LLM 호출**     | LLM API (Gemini, Mistral 등)               | LLM 모델에게 프롬프트 전달 | 카테고리에 따라 정형화된 챌린지를 자연어로 생성               |
| **출력 필터링**     | Output Guardrails *(직접 구현 또는 외부 패키지 가능)*  | 생성된 응답 후처리       | 금칙어, 무의미 답변 필터링 (예: “잘 모르겠어요” 제거)        |
| 외부 검색 및 도      | 없음                                        | N/A              | N/A                                      |

1.3. 실제 구현한 코드의 일부

`````python
%%writefile chatbot_app_Mistral.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from llm_model_Mistral_7B_Instruct_v3 import get_llm_response
import json

app = FastAPI()

class CategoryRequest(BaseModel):
    userId: int
    category: str
    location: str
    work_type: str

@app.post("/chatbot/select-category")
def select_category(req: CategoryRequest):
    prompt = f"""
    {req.location} 환경에 있는 {req.work_type} 사용자가 {req.category}를 실천할 때,
    절대적으로 환경에 도움되는 챌린지를 아래 JSON 형식으로 3가지 추천해줘.

    **오직 순수한 JSON만 출력하세요. 마크다운 코드블럭(````json`)이나 설명 없이, 아래 형식을 그대로 사용하세요.**

    {{
        "status": 200,
        "message": "성공!",
        "data": {{
            "recommand": "설명 텍스트",
            "challenges": [
                {{"title": "...", "description": "..."}}
            ]
        }}
    }}
    """
    return get_llm_response(prompt)
`````

1.4. 체인을 도입하지 않은 이유

1. 해당 LLM은 **선호 카테고리**에 따라 **정형화된 챌린지 목록**만 추천하면 되는 구조
    - 이 Task는 복잡한 추론이 아닌 **정해진 범위 내에서 생성**되므로 별도 문서 검색(RAG)또는 다단계 체인의 이점이 없다고 판단
    - 추가로 체인을 구성하면 부가 처리 단계가 추가되어 불필요한 지연이 발생함을 고려
1. 단순 프롬프트 기반 설계로도 충분한 성능 확보
2. Output_Guardrails만으로도 응답 품질과 안전성 관리가 가능할 것으로 판단

# 2. /ai/chatbot/freetext

2.1. **체인 작동 방식 (LangChain + RAG Retrieval):**

```mermaid
graph LR
    A[사용자 입력<br/>(자연어 챌린지 희망 내용 + 지역/직군)] --> B[Query 재구성 또는 전처리<br/>(LangChain PromptTemplate)]
    B --> C[Vector DB 검색<br/>(챌린지 임베딩 유사도 기반)]
    C --> D[관련 문서 Context 반환]
    D --> E[LLM 입력 생성<br/>(사용자 요청 + 검색된 문서)]
    E --> F[LLM 응답 생성<br/>(개인화 챌린지 추천)]
    F --> G[Output Guardrails 필터링]
    G --> H[최종 응답 반환]
```

-  다이어그램 설명

| **A** | 사용자가 자연어로 자유롭게 입력 (예: “요즘 자전거 타기 재밌어서 출퇴근에 활용하고 싶어요”) |
| ----- | ----------------------------------------------------- |
| **B** | LangChain이 입력을 전처리 또는 Query Rewriting (예: 요약, 키워드 추출) |
| **C** | Vector DB에서 챌린지 벡터를 기반으로 유사한 문서 검색                    |
| **D** | 검색된 챌린지 관련 문서를 Context로 구성                            |
| **E** | LLM에 사용자 입력 + 검색 Context를 함께 전달                       |
| **F** | LLM이 개인화된 챌린지를 생성 및 추천                                |
| **G** | 부적절하거나 무관한 응답 필터링 (Output Guardrails)                 |
| **H** | 프론트로 JSON 응답 반환 (title/description 쌍)                 |

2.2 체인 내에서 사용된 도구나 외부 리소스

| **구성 요소**           | **도구/리소스**                           | **사용 방식**                   | **설명**                         |
| ------------------- | ------------------------------------ | --------------------------- | ------------------------------ |
| **프롬프트 템플릿 구성**     | LangChain.PromptTemplate             | 사용자 입력을 템플릿화                | 자체 모델에 전달할 프롬프트 형식 고정          |
| **문서 검색 (벡터 검색)**   | VectorEB (예정)                        | 사용자 입력 임베딩 → 유사 문서 검색       | 사용자의 맥락과 유사한 챌린지 사례 검색         |
| **임베딩 모델**          | 자체 임베딩 모델 or sentence-transformers 등 | Vector DB에 넣기 위한 텍스트 벡터화 처리 | HuggingFace 모델 등 자유롭게 교체 가능    |
| **LLM (자체 모델)**     | Mistral 7B, Zephyr, Gemma, etc.      | 사용자의 요청 + 검색 결과를 바탕으로 응답 생성 | FastAPI 등 통해 자체 호스팅 중          |
| **LangChain 체인 구성** | RetrievalQA 등                        | 검색 + 생성 흐름을 연결              | LLM 호출 전, 후 과정 포함              |
| **응답 검증**           | Guardrails, Pydantic, 또는 커스텀 로직      | JSON 포맷 확인, 금칙어 필터링 등       | 정형 포맷(title/description) 응답 보장 |

2.3. 실제 구현한 코드의 일부

```python
%%writefile chatbot_app_Mistral.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from llm_model_Mistral_7B_Instruct_v3 import get_llm_response
import json

app = FastAPI()

class FreeTextRequest(BaseModel):
    userId: int
    location: str
    work_type: str
    user_message: str

@app.post("/chatbot/freetext")
def free_text(req: FreeTextRequest):

    #  🔍 환경 키워드 필터링
    ENV_KEYWORDS = [
        "환경", "지구", "에코", "제로웨이스트", "탄소", "분리수거", "플라스틱", "텀블러", "기후", "친환경",
        "일회용", "미세먼지", "재활용", "자원", "대중교통", "도보", "비건", "탄소중립", "그린", "에너지", "쓰래기"
    ]

    if req.user_message is None:
        raise HTTPException(status_code=400, detail="user_message는 필수입니다.")
    if not isinstance(req.user_message, str) or len(req.user_message.strip()) < 5:
        raise HTTPException(status_code=422, detail="user_message는 문자열이어야 하며, 최소한의 의미를 가져야 합니다.")
    if not any(keyword in req.user_message for keyword in ENV_KEYWORDS)
        return {
            "status" : 403,
            "message" : "저는 친환경 챌린지를 추천해드리는 Leafresh 챗봇이에요! 환경 관련 질문을 해주시면 더 잘 도와드릴 수 있어요.",
            "data" : None
        }

    prompt = (
    f"{req.location} 환경에서 {req.work_type} 사용자가 '{req.user_message}'라고 했을 때 "
    "환경에 도움되는 챌린지를 아래 JSON 형식으로만 출력하세요. "
    "**절대 설명이나 코드블럭 없이 순수 JSON만 출력하세요.**\n\n"
    "{\n"
    "  \"status\": 200,\n"
    "  \"message\": \"성공!\",\n"
    "  \"data\": {\n"
    "    \"recommand\": \"...\",\n"
    "    \"challenges\": [\n"
    "      {\"title\": \"...\", \"description\": \"...\"}\n"
    "    ]\n"
    "  }\n"
    "}"
    )
    return get_llm_response(prompt)
```

2.4. LangChain을 도입한 이유 

1. 자유 입력에 대한 이해력 강화(Query Rewriting + Context Construction)
    - 사용자의 입력은 자연어 형태로 다양하게 들어오며, 키워드만으로는 정확한 의도 파악이 어려움
    - LangChain의 PromptTemplate, LLMChain, ConversationChain 등을 활용하여 입력을 재구성(Query Rewriting) 하거나 문맥(Context)을 명확히 구성함으로써 더 정밀한 LLM 추론 가능
1. RAG 구조에서 Retreival 단계 자동화
    - VectorDB에서 유사 챙인지를 검색하는 RAG(Retrieval-Augmented Generation) 패턴은 단순한 LLM 호출만으로는 불가능함
    - LangChain의 Retrieval1QA, VectorStoreRetriever, load_aq_chain 등을 활용해 사용자의 요청과 가장 관련 높은 챌린지 문서를 VectorDB에서 찾아냄

3. 멀티스텝 체인 구성으로 확장성 확보

    - LangChain을 사용하면, 챌린지 추천 외에도 인증사진 해석 결과 보정 등 다른 모듈과 체인 방식으로 확장 가능
    - 체인 기반 설계로 기능 추가 시 **모듈 간 의존도 낮고**, 유지보수 용이
4. LLM결과 일관성 확보 및 Guardrails 통합 용이
    - LLM 응답이 편향되거나 무관할 수 있는 경우를 대비 LangChain에 Guardrails 로직을 포함시켜 불건전 & 무의미 & 반복 추천 방지 가능  