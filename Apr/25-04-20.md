# 오늘 내가 배운 것들(Today I Learned)

- 사용자의 챌린지 인증 사진을 비동기 방식으로 구현해서 메세지 큐를 사용하기로 했는데,
- Redis를 왜 써야하는지 또 Celery를 왜 쓰는지 궁금해졌다.

---
- Redis를 왜 쓰지? 
    - 메모리에 데이터를 저장하는 초고속 Key-Value DB라고 함
    - 특히 메세지 큐 시스템에서 `Queue 저장소 ` 역할로 널리 쓰인다고 함
- Redis + Celery 조합 구조

| **구성**  | **역할**                                         | **예시**           |
| ------- | ---------------------------------------------- | ---------------- |
|  Redis  | 작업(Task)을 큐처럼 저장하는 **중간 저장소**                  | 사진 인증 요청을 넣어둠    |
|  Celery | Redis에 쌓인 작업을 꺼내서 **비동기로 처리**하는 **Worker 시스템** | 모델 호출, DB 업데이트 등 |

- 그럼 Redis말고 다른 대안은 없나?
    - 있다. 아래와 같다. 

| **대안**             | **설명**           | **Redis와 차이점**               |
| ------------------ | ---------------- | ---------------------------- |
| **RabbitMQ**       | 메시지 큐 전용 고급 미들웨어 | 멀티 큐/라우팅/우선순위 큐 등 큐 특화 기능 많음 |
| **Kafka**          | 스트리밍, 로그 수집에 특화  | 대용량 이벤트 스트리밍 (실시간 로그 처리 등)   |
| **Amazon SQS**     | AWS 기반 큐 서비스     | 서버리스 큐, 유지 관리 필요 없음          |
| **Google Pub/Sub** | GCP 기반 메시지 브로커   | 글로벌 분산 메시지 전송에 강함            |

- Redis가 왜 가장 많이 쓰이는거지?
    - 간편하고 빠름
    - 설정 쉽다
    - 로컬 개발에도 바로 적용 가능
    - Queue뿐만 아니라 Cashe,Session까지 활용 가능

—> 가볍고 범용적으로 쓸 수 있고, 빠르다

## 단계별 정리 : AI 챗봇 및 모듈 설계 방향성과 연결

---

1. **기본 LLM 호출**
    - 그냥 사용자 질의 → 모델 응답 → 사용자 반환
    - LLM API (예: OpenAI, Gemini, Mistral 등)에 요청만 하는 구조
    - 챗봇 MVP 구조와 동일
2. **Context Construction (문맥 구성 / RAG / Query Rewriting)**
    - 모델이 응답을 잘 하려면 **배경 정보가 필요**
    - DB 문서, 검색, 툴 호출, 유저 정보 등 → 프롬프트에 포함시킴
        - **예시**: 챌린지 추천 챗봇이면 유저 위치, 직무, 과거 챌린지 이력 삽입
    - 구현 방식:
        - 벡터 DB (ChromaDB 등) 검색 결과
        - 날짜 기반 필터링
        - query rewriting → 모호한 질문 보완
3. **Input/Output Guardrails**
    - **입력 단계**:
        - 개인정보(PII), 민감 정보 탐지 및 마스킹
        - 악성 프롬프트, 비속어 등 차단
    - **출력 단계**:
        - 유해 콘텐츠, 말이 안 되는 답변, JSON 포맷 오류 등 검증
    - 인증 이미지 처리나 챌린지 생성에서 **엄청 중요**
    - 활용 예: OpenAI Moderation API, NeMo Guardrails, Perspective API
4. **Routing & Gateway (멀티 모델 구조)**
    - 여러 모델/툴 중에 **어떤 걸 쓸지 자동 판단**
    - Intent 분류 → 적절한 엔진/모델/사람에게 라우팅
    - 예시:
        - "챌린지 추천" → ChatBot
        - "인증 실패 사유 분석" → Feedback
        - "시간이 지난 챌린지 재검토" → Human handoff
    - Gateway는 다양한 모델(API or 로컬)을 통합적으로 제어하는 허브
5. **Caching (Exact / Semantic)**
    - 똑같은 질의 or 유사 질의에 대해 결과 재사용
    - **Exact Cache**:
        - 동일한 질문 → 동일 응답 재사용
        - 인증 규약 설명, 자주 묻는 챌린지 설명 등
    - **Semantic Cache**:
        - "서울 날씨 알려줘" ≈ "서울의 기온은?"
        - 벡터 기반 유사도 판단 → 응답 재활용
6. **Agent Patterns (고급 로직 제어)**
    - 모델이 스스로 판단해서:
        - 여러 번 Tool 호출
        - Loop, Branch
        - 중간 결과 분석 후 다음 행동 결정
    - 예시:
        - 인증 사진 → 실패 → 추가 설명 필요 판단 → 규약 재검색 → 피드백 생성
        - 챌린지 추천 후 유저 반응 기반 추가 추천 반복

---

-  아니 근데 LLM모델 4개 다 모듈화 하는데 
    - 1,2번은 LLM모델 모듈화 확정인데
    - 3,4번은 응답 데이터 형태도 그렇고 비슷함(검열 & 피드백)
        - 프롬프팅만 달라지는데 이것도 따로 모듈화 해야할까?

    - GPT 답변  : ㅇㅇ

    > **처리 방식(프롬프트 구조, 목적, 응답 형태)이 다르면 모듈화해서 분리하는 것이 좋습니다.**

    > 특히 “**역할 책임이 다르다**”면 프롬프팅만 바꿔서 재사용 하기보다는 모듈 분리가 유지보수성과 테스트 효율성을 높임

---

-   그럼 왜 다르게 봐야할까?(몰론 세세하게 따지면 두 모델은 다르긴함ㅇㅇ)

| **구분**      | **/ai/validate-challenge **(검열/중복 확인)**** | **/ai/feedback **(결과 기반 피드백 생성)**** |
| ----------- | ----------------------------------------- | ----------------------------------- |
| **목적**      | 챌린지 생성이 가능한지 **판단**                       | 사용자 행동에 대한 **피드백 생성**               |
| **프롬프트 구조** | “입력된 챌린지가 기존 목록과 유사한가?”                   | “이 유저의 챌린지 성공/실패에 대해 자연어 리뷰를 생성해줘”  |
| **입력 구조**   | 단일 챌린지 + 기존 챌린지 목록 비교                     | 다수 챌린지 결과 success 여부 기반 피드백         |
| **응답 형태**   | { result: True/False } + 보조 메시지           | "잘했어요! 멀티탭은 아쉬웠지만 텀블러는 꾸준하셨네요!"     |
| **결론**      | 유사도 판단용 → 분류/검열                           | 사용자 맞춤 설명 생성 → 생성형 NLP              |

- 아 처리 목적이 다름
    - 검열 -> true & false
    - 피드백 -> 자연어 멘트
- 그럼 모듈화를 하면 좋은점? 

| **항목**              | **이유**                                   |
| ------------------- | ---------------------------------------- |
|  **역할 단일화 (SRP)**   | 피드백은 설명 생성 / 검열은 판단 분류 → 책임 명확           |
|  **프롬프트 구조 최적화 가능** | 각각에 특화된 시스템 메시지, 예시, temperature 등 설정 가능 |
|  **유닛 테스트 가능**      | 각각의 입력/출력 기준이 다르므로 검증 기준 분리 용이           |
|  **확장성 확보**         | 피드백만 다국어 대응 or 평가 모델 도입 등 발전 경로 다름       |
|  **디버깅 편리**         | 어느 모듈에서 실패했는지 추적이 명확해짐                   |

- 비록 이번 프로젝트에서는 되도록이면 각 모델별로 분리하라는 알렉스 피드백이 있었지만,
- 만에 하나 모델을 합치고 싶다면 공통된 부분이 있긴하다 
    - 내부적으로 shared_llm_inference() 같은 공통 호출 로직은 재사용 가능

```python
# 내부적으로는 이렇게 재사용 가능
def call_llm(prompt: str, temperature: float = 0.7):
    return openai.chat_completion(prompt=prompt, temp=temperature)
```

- BUT, **모듈(= use case 단위)** 는 분리해서 유지하는 것이 설계적으로 안전(뭐 당연한 소리)

    

##  ChatBot 수정

-  [**Context Construction]블록은 왜Query Rewriting+RAG Retrieval** **로 구성되나?**

    > Context Construction은 모델이 답변을 생성하기 위한 정보를 구성하는 **전체과정을 의**미

    - Query Rewriting : 질문을 더 명확하게 만든다 (다듬기)
    - RAG Retrieval : 명확해진 질문을 기반으로 외부 정보를 찾아오기
    - 두개를 함축적으로 나타낸 이유는 단지 단순화 하기 위함임 
        - 보통 복잡한 시스템을 도식화할 때
            - `기능적 책임 단위` 로 묶기
            - `상위 추상화 레벨` 로 보여주기
    -  나는 [Context construction] 과 DataBase를 `양방향`으로 연결하였음
        - 만약 RAG기법으로 DB(벡터)에서 정보를 찾기만 한다면 단방향이지만
        - 동시에 사용자의 대화 이력을 저장해야하기에 양방향을 채택함

        >  문맥 구성뿐 아니라 과거 대화, 사용자 정보도 가져온다 / 저장할 수도 있다

## 라우터(Router) 위치 수정

-  라우터는 자유입력일 때에 표기하는 것이 유용하다
    - But, 해당 구조는 /freetext 요청을 분류해서 ChatBot, Feedback, Censor등으로 보내는 의도 라우팅 구조가 아니기 때문에 아키텍처상에 표기할 필요가 없다
    - 각 API는 이미 고정된 API 주소 및 경로가 지정되어있어 굳이 거칠 필요가 없다

## Output Guardrails 수정

- 아웃풋 가드레일이란, LLM 모델의 답변이 예상치 못하게 되었을 때 수정해주는 모듈이다 

| **문제 유형** | **예시**                          |
| --------- | ------------------------------- |
| 포맷 오류     | JSON 응답인데 따옴표 빠짐, 리스트 깨짐        |
| 의미 오류     | “텀블러 챌린지”인데 전혀 상관없는 “식물 키우기” 제안 |
| 유해 응답     | 욕설, 혐오, 성적 내용 등                 |
| 보안 이슈     | 개인정보 유출, 허위 사실, 회사 정책 위반        |

- 따라서, 실질적인 LLM답변을 **사용자에게 직접 노출되는 경우인** ChatBot, Feedback 모델에만 Output Guardrails를 통과하도록 설계함

---

# 아래는 AI 서비스 아키텍처 모듈화 수정한 내용이다.

## 내용

<img width="800" alt="Image" src="https://github.com/user-attachments/assets/97473848-391d-4f42-b5e1-5eb9d618c658" />

<br>

### 1. 각 모듈의 책임(Domain)과 기능

| 모듈 | 설명 | 분리 이유 |
|------|------|-----------|
| **Backend (BE)** | 모델 호출, 챌린지 등록/조회 처리 | 다양한 AI/DB 연계 및 확장성 확보 |
| **LLM ChatBot** | 챌린지 추천 (카테고리 기반/자유 입력 기반) | LLM 비용 최적화 및 챗봇 로직 분리 |
| **LLM Feedback** | 챌린지 참여 결과 피드백 생성               | 개인/단체 챌린지 성공/실패 이력을 기반으로 코멘트 생성 |
| **LLM Censor**   | 챌린지 중복 여부 판단 및 필터링                 | 기존 챌린지와 유사 여부 비교 → 생성 가능 여부 판단 |
| **LLM Verify**   | 이미지 기반 인증 판단                         | 업로드된 인증 사진에 대해 성공/실패 여부 판독 |
| **Message Queue** | 이미지 인증 비동기 처리 | 안정적 분산 처리 및 확장성 확보 |
| **Database** | 사용자, 챌린지, 인증 결과 저장 | 영속성 및 조회 기능 담당 |
| **Input Guardrails** | 입력값 검증 (비속어, 키워드 누락 등)      | 잘못된 요청 방지, Query Rewriting 전에 실행 |
| **Output Guardrails** | 출력 포맷 및 유해성 검증                | 응답 JSON 포맷 확인, 필터링 및 Fallback 처리 |
| **Context Construction** | Query Rewriting + RAG Retrieval    | freetext 입력을 구조화하고 관련 문서 검색 후 포함 |


### 1.1 Context Construction 블록 구분

1.  Context Construction A – freetext 전용

 - 위치: `/chatbot/freetext` 흐름 중간
 - 기능: 사용자 자연어 입력을 구조화한 후, 관련 문서를 RAG 방식으로 검색해 context에 포함
 - 기술: Query Rewriting + RAG Retrieval

2.  Context Construction B – 챌린지 검열 전용

 - 위치: `/validate-challenge` 요청 흐름 상단
 - 기능: 입력된 챌린지 정보(이름/기간 등)를 LLM이 잘 처리할 수 있도록 포맷 정규화
 - 기술: Query Rewriting Only (RAG 없음)

<br>

### 2. 모듈 간 인터페이스 설계 (API 명세 및 데이터 포맷)

| API 경로 | 호출 방향 | 요청 데이터 예시 | 응답 예시 |
|----------|-----------|------------------|------------|
| `POST /verify-image` | Backend → AI Model | `{ "file": img, "userId": 123, ... }` | `202 Accepted` (비동기 처리) |
| `POST /verify-result` | AI Model → Backend | `{ "userId": 123, "result": 1 }` | `200 OK` |
| `POST /chatbot/select-category` | Backend → ChatBot LLM | `{ "userId": 123, "category": "제로웨이스트" }` | 챌린지 추천 리스트 응답 |
| `POST /chatbot/freetext` | Backend → ChatBot LLM | `{ "message": "...", "context": ... }` | 자연어 기반 챌린지 추천 응답 |
| `POST /validate-challenge` | Backend → Censor LLM | `{ "title": "..." }` | `{ "valid": true }` |
| (Message Queue 처리) | Backend → Queue | 인증 요청 메시지 JSON | 비동기 처리 (ex. Celery, Redis 등) |
| (DB 저장) | Backend → Database | ORM 또는 SQL insert | 내부 트랜잭션 처리 (응답 없음) |

<br>

### 3. 모듈화로 기대되는 효과와 장점

- 도메인 책임 분리 (SRP) : 기능별 LLM을 분리함으로써 개발, 테스트, 배포 범위 최소화
-  확장성 높은 구조 : 새로운 기능 추가 시 다른 모듈에 영향 없이 병렬 확장 가능
- 에러 영향 최소화 : 한 모듈의 장애가 전체 시스템에 전파되지 않음
- 성능 튜닝 최적화 : 모델별 Prompt/토큰/메모리 튜닝이 개별화 가능

<br>
 
### 4. 모듈화된 설계가 팀의 서비스 시나리오에 부합하는 이유

| 변화 시나리오 | 변경 대상 모듈 | 영향을 받는 범위 |
|--------------------------|----------------------|------------------------|
| 챌린지 추천 정책 변경 | `ChatBot LLM` | LLM만 fine-tune, 다른 모듈 영향 없음 |
| 챌린지 생성 시 검열 기준 변경 | `Censor LLM` | 검열 LLM만 교체, Backend/DB 영향 없음 |
| 이미지 추론 모델 업그레이드 | `AI Model` | 모델만 교체 가능, 인증 로직 전체 유지 |
| 프론트 UI 리뉴얼 | `Client / Frontend` | 백엔드/API 구조 변경 불필요 |
| DB 스키마 변경 | `Database`, `Backend` | 프론트/LLM/모델 영향 없음 |

- `ChatBot`은 사용자의 추천 요청에만 반응하고, `Feedback`, `Censor`, `Verify`는 각기 독립적으로 동작
- 예시: 챌린지 생성 정책이 변경되어도 `LLM Censor`만 업데이트하면 되며, `ChatBot`, `Feedback`은 영향 없음
- 자유 입력(`/freetext`)이 다양한 의도로 분기되어도, 단일 Router가 아닌 **정적 API 분기로 처리되기 때문에 확장과 테스트가 용이**

<br>