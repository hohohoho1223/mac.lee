# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 leafresh 챗봇 테스트 및 프롬프팅 내용 변경을 진행했다.

---

# Leafresh 챗봇 성능 테스트 보고서

## 1. 테스트 개요

- Leafresh 챗봇은 다음 두 가지 방식의 친환경 챌린지 추천 기능을 제공함

| 테스트 모드     | 설명                                                             |
|----------------|------------------------------------------------------------------|
| Base-info      | location, workType, category 세 가지 structured 정보를 기반으로 챌린지 추천 |
| Free-text (RAG) | 자유 입력 문장과 문서 검색 기반 RAG 방식으로 챌린지 추천               |

---

## 2. 테스트 구성

### Base-info 테스트 케이스

총 224개의 조합:
- 모든 필드가 포함된 정상 케이스
- 각 필드가 누락된 에러 케이스 (`400 Bad Request`)
- 누락된 필드가 있는 경우는 정확도 평가 대상에서 제외

### Free-text 테스트 케이스

총 14개 시나리오:
- 환경 키워드 포함/미포함
- 길이 부족 에러 (422)
- 대화 맥락 유지 여부 테스트
- 예상 키워드/문맥/응답 포맷 등을 기준으로 평가

---

## 3. 테스트 방식

### (1) 응답 시간 측정

- 각 케이스별 `requests.post()`로 API 호출
- 응답까지 걸린 시간(ms 단위) 측정 및 기록
- 전체 평균/최대/최소 응답 시간 도출

### (2) 정확도 측정

| 평가 항목              | 기준 설명                                                             |
|------------------------|----------------------------------------------------------------------|
| Base-info Accuracy     | 응답 성공률 (200 OK 기준) ※ 필수값 누락은 제외                         |
| Free-text Accuracy     | 키워드 및 컨텍스트 포함 여부, 포맷 일치율, 에러 응답 적절성 등              |
| Partial Match          | 키워드 OR 문맥이 일치하는 경우 비율                                      |
| Format Accuracy        | JSON 응답이 `recommend: str`, `challenges: list` 형식에 맞는 비율         |
| Error Handling Accuracy| 400/422 등 예외를 정확하게 처리했는지 평가                                |
| Average Keyword Coverage | 응답 내 예상 키워드 포함 비율 평균                                     |
| Response Length        | 응답 내용의 길이 평균 (토큰 기반 품질 간접 지표)                          |

---

## 4. 성능 측정 결과

| 항목                 | base-info | free-text |
|----------------------|-----------|-----------|
| 평균 응답 시간        | 2.837s    | 1.390s    |
| 최대 응답 시간        | 3.464s    | 3.721s    |
| 최소 응답 시간        | 1.826s    | 0.003s    |
| 정확도                | 100.0%    | 0.0%      |
| 문맥 반영 정확도       | -         | 64.29%    |
| 형식 정확도           | -         | 57.14%    |
| 에러 핸들링 정확도     | -         | 7.14%     |

---

## 5. 평가 기준 정리

| 지표             | 설명                                                              |
|------------------|-------------------------------------------------------------------|
| 응답 시간         | API 성능과 LLM 추론 속도 측정                                      |
| 정확도            | 예상된 정보(키워드/포맷 등)의 응답 반영 여부                         |
| 형식 일치         | 응답이 JSON 형식 요건 충족하는지 여부                                 |
| 에러 대응력       | 유효하지 않은 입력에 대해 적절히 대응하는지                           |
| 대화 맥락 유지     | 동일한 conversation_id 내에서 응답 일관성 확인                         |

---

## 6. 향후 개선 포인트

- RAG 성능 분석을 위해 문서 정확도와 검색 latency 분리
- 응답의 자연어 품질(논리성, 요약력 등)을 자동화 기준으로 측정
- 통계/시각화 대시보드 연동 (예: Streamlit + matplotlib)
- 실패 케이스 저장 기능 추가 (debug log용)

---

**작성 시각:** 2025-05-15T09:18:11.512730

---

## 1. 사용자 정보 부재로 인한 문제

- 처음 챗봇은 회원이든 비회원이든 사용가능 하도록 접근성을 높이기 위해 `memberId` 설정을 API설계 당시 제외하였다.
- 근데 이렇게 되버리니까 챗봇이 사용자의 정보를 모르니 이전에 대한 대화내용을 모르는 상황이 발생하였다.(대화가 안이어짐)
    
    ![image.png](attachment:f1ae8691-e8f1-484a-a1be-c662852c1ef6:image.png)
    
- 사용자가 이전 대화를 바탕으로 요구사항을 입력 시, 엉뚱한 대답이 나오는 것이 확인됐다.

---

## 2. 키워드 관련 프롬프팅 문제

- 아래는 해당 카테고리를 선택시, 해당 키워드와 상관 없는 답변이 나오는 것을 확인했다.
    
    ![스크린샷 2025-05-15 오후 10.27.46.png](attachment:b03f0c01-8efb-4060-9d00-401be03fe540:스크린샷_2025-05-15_오후_10.27.46.png)
    
- 프롬프팅 조정이 필요해 보인다.
- 아래는 기존 프롬프팅 내용 및 출력문이다.

```python
base_prompt = PromptTemplate(
    input_variables=["location", "workType", "category"],
    template=f"""
{{location}} 환경에 있는 {{workType}} 사용자가 {{category}}를 실천할 때,
절대적으로 환경에 도움이 되는 챌린지를 아래 JSON 형식으로 3가지 추천해주세요.

JSON 포맷:
{escaped_format}

응답은 반드시 위 JSON 형식 그대로, 마크다운 없이 순수 JSON만 출력하세요.

"""
```

```python
{
  "status": 200,
  "message": "성공!",
  "data": {
    "recommend": "도시 환경 사무직 비건을 위한 환경 보호 챌린지를 추천합니다.",
    "challenges": [
      {
        "title": "플라스틱 포장재 없는 점심 식사 도전",
        "description": "개인 용기를 사용하여 포장 쓰레기를 줄이고, 직접 도시락을 준비하거나 포장재 없는 비건 식당을 이용합니다."
      },
      {
        "title": "대중교통/자전거 이용 늘리기",
        "description": "자가용 대신 대중교통을 이용하거나 자전거를 타서 탄소 배출량을 줄이고 건강도 챙깁니다."
      },
      {
        "title": "사무실 개인 컵/텀블러 사용 생활화",
        "description": "일회용 컵 사용을 줄이기 위해 개인 컵이나 텀블러를 항상 휴대하고 사용합니다."
      }
    ]
  }
}
```

- 아래는 수정된 프롬프팅 내용 및 출력문이다.

```python
base_prompt = PromptTemplate(
    input_variables=["location", "workType", "category"],
    template=f"""
{{location}} 환경에 있는 {{workType}} 사용자가 {{category}}를 실천할 때,
{{category}}를 활용한 환경에 도움되는 챌린지를 아래 JSON 형식으로 3가지 추천해주세요.

JSON 포맷:
{escaped_format}

응답은 반드시 위 JSON 형식 그대로, 마크다운 없이 순수 JSON만 출력하세요.

"""
)
```

```python
{
  "status": 200,
  "message": "성공!",
  "data": {
    "recommend": "도시 환경 사무직 비건 사용자를 위한 환경 보호 챌린지를 추천합니다.",
    "challenges": [
      {
        "title": "점심 도시락 & 텀블러 사용 생활화 챌린지",
        "description": "매일 비건 도시락을 직접 준비하고 텀블러를 사용하여 일회용품 소비를 최소화합니다."
      },
      {
        "title": "대중교통/친환경 이동수단 이용 챌린지",
        "description": "출퇴근 시 대중교통을 이용하거나 자전거, 도보 등 친환경적인 이동수단을 선택하여 탄소 배출량을 줄입니다."
      },
      {
        "title": "사무실 내 비건 & 제로 웨이스트 실천 챌린지",
        "description": "사무실에서 개인 컵 사용, 비건 간식 선택, 재활용률 높이기 등 제로 웨이스트를 실천합니다."
      }
    ]
  }
}
```

- 좀더 `category` (=”비건”)를 집중으로 환경 챌린지 추천을 받을 수 있었다.