# 오늘 내가 배운 것들(Today I Learned)

- feedback(API) 모델 설계 및 SSE방식 적용
- 챗봇 업데이트 진행(V2)

---

# 챗봇 및 피드백 모델 변경사항 분석 보고서
[data.25-05-28(수)]

## 1. 피드백 모델 (`LLM_feedback_model.py`)

### 1.1 주요 변경사항

- **스트리밍 응답 구현**
  ```python
  response = self.model.generate_content(
      prompt,
      generation_config={
          "temperature": 0.7,
          "top_p": 1,
          "top_k": 32,
          "max_output_tokens": self.max_tokens
      },
      stream=True
  )
  ```

- **응답 형식 표준화**
  ```python
  {
      "status": 200,
      "message": "피드백 생성 중",
      "data": {
          "feedback": "생성된 피드백 텍스트"
      }
  }
  ```

- 현재 피드백 시스템은 비동기 방식과 SSE(Server-Sent Events)를 함께 사용하고있다.

1. 비동기 처리
    - asyncio를 리용한 비동기 스트리밍 구현
    - 메인 스레드 블로킹을 방지하는 구조
2. 스트리밍 응답:
    - Vertex AI 모델의 stream=True 옵션을 사용하여 실시간 스트리밍
    - 청크 단위로 피드백을 전송

- 이러한 구조를 통해 사용자는 피드백이 생성되는 즉시 실시간으로 응답을 받을 수 있으며 서버의 메인 스레드가 블로킹 되지 않아 다른 요청들도 동시에 처리 가능하다.

#### 그럼 왜 비동기로 했을까?

1. 비동기 + SSE 방식의 의미:
    - 비동기: 서버가 요청을 받았을 때, 응답이 완료될 때까지 기다리지 않고 다른 작업을 할 수 있음
    - SSE: 서버에서 클라이언트로 실시간으로 데이터를 스트리밍하는 방식
    - 이 두 가지를 조합하면, 서버는 피드백을 생성하면서 동시에 다른 사용자의 요청도 처리할 수 있음

2. 동기 + SSE 방식:
    - 동기 방식도 SSE와 함께 사용 가능합니다
    - 차이점은:
        - 동기: 한 요청이 완료될 때까지 다른 요청을 처리하지 않음
        - 비동기: 여러 요청을 동시에 처리 가능

- 여러 사용자의 요청을 고려하면 비동기 + SSE 방식으로 구현해야 할 것 같다.

### 1.2 개선된 기능

- **실시간 피드백 생성**
  - 청크 단위로 피드백 전송
  - 비동기 처리로 성능 최적화
  - 한글 인코딩 지원

- **에러 처리 강화**
  - 모델 오류와 일반 서버 오류 구분
  - 상세한 에러 메시지 제공
  - 스택 트레이스 로깅

## 2. 챗봇 모델 (`LLM_chatbot_free_text_model.py`)

### 2.1 주요 변경사항
- **대화 상태 관리 시스템 도입**
  ```python
  class ChatState(TypedDict):
      messages: Annotated[Sequence[str], "대화 기록"]
      current_query: str
      context: str
      response: str
      should_continue: bool
      error: Optional[str]
      docs: Optional[list]
      sessionId: str
  ```

- **대화 그래프 구현**
  ```python
  def create_chat_graph():
      workflow = StateGraph(ChatState)
      workflow.add_node("validate", validate_query)
      workflow.add_node("retrieve", retrieve_context)
      workflow.add_node("generate", generate_response)
      workflow.add_node("handle_error", handle_error)
  ```

### 2.2 개선된 기능
- **세션 기반 대화 관리**
  - `sessionId`를 통한 대화 컨텍스트 유지
  - 대화 기록 저장 및 관리
  - 세션별 독립적인 상태 관리

- **RAG 시스템 개선**
  - 검색 결과 수 증가 (k=5)
  - 컨텍스트 기반 응답 생성
  - JSON 파싱 및 검증 강화

- **응답 품질 향상**
  - 필수 필드 검증
  - 응답 형식 표준화
  - 에러 처리 개선

## 3. 공통 개선사항

### 3.1 API 응답 형식
```python
{
    "status": int,      # HTTP 상태 코드
    "message": str,     # 응답 메시지
    "data": Any        # 응답 데이터
}
```

### 3.2 에러 처리
- **표준화된 에러 응답**
  - 400: 잘못된 요청
  - 500: 서버 오류
  - 상세한 에러 메시지

### 3.3 성능 최적화
- **비동기 처리**
  - `asyncio`를 활용한 비동기 스트리밍
  - 메인 스레드 블로킹 방지