# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 알렉스와 이력서 및 포트폴리오 피드백이 있는 날 이었다.
- 프로젝트 "Leafresh"에서 내가 맡은 챗봇 개발 중 코드 리뷰를 하였다.

---


## 알렉스 feedback

- 이력서에서 fact위주로 서류전달이 진행된다
- 씨랩?(멘토링)
- 포트폴리오는 집요하게 멘토링이 들어올예정
- 생산력을 보여주고싶다면 프로젝트를 넣긴 넣는데 중요한것 위주로 정렬하기
- 포트폴리오 내용을 이력서에 “항목" 자체는 넣어야 함(명시하기)
- 프로젝트는 여러명이서 하는 프로젝트를 부각시키는것이 좋다 (개인보단)
- 협업에 관련된 내용을 포폴에 녹여보기
- 멘토한테 포폴 보여달라하기ㅎ
- 이미지 첨부하여 시각화를 하기(포트폴리오)
- 최근지원 여부에 따라 서류도 안볼지도..ㅋㅋ

---

## 코드 리뷰

-  generate_challenge_docs_unified.py: **RAG 문서를 수정하고 싶을 때**

```python
# generate_challenge_docs_unified.py
import random

def generate_challenge_docs(file_path="challenge_docs.txt", mode="random", num_paragraphs=100):# fixed, random으로 변경 가능
    """
    챌린지 문서를 생성합니다.

    Args:
        file_path (str): 저장할 파일 경로
        mode (str): "fixed" (고정 데이터) 또는 "random" (랜덤 조합 데이터)
        num_paragraphs (int): 랜덤 모드일 때 생성할 문단 수 (default: 100)
    """

    # 고정 데이터
    fixed_contents = [
        "플라스틱 사용을 줄이기 위해 텀블러를 사용하고, 장바구니를 지참합시다.",
        "제로웨이스트 생활을 실천하기 위해 쓰레기를 줄이고 재사용 가능한 제품을 사용합시다.",
        "탄소중립을 위해 대중교통을 이용하고, 걷기와 자전거 타기를 생활화합시다.",
        "에너지를 절약하기 위해 불필요한 전기 제품을 끄고, 에너지 효율이 높은 제품을 사용합시다.",
        "비건 식단을 시도하여 축산업에 의한 탄소 배출을 줄입시다."
    ]

    # 랜덤 데이터 후보 문장
    random_sentences = [
        "텀블러 사용으로 플라스틱 쓰레기를 줄이자.",
        "비건 식단을 통해 탄소 배출을 줄이자.",
        "에코백을 들고 다니며 비닐봉지 사용을 줄이자.",
        "대중교통을 이용해 탄소중립 실천하기.",
        "재활용 가능한 제품을 구매하자.",
        "제로웨이스트를 목표로 생활하자.",
        "불필요한 전등 끄기로 에너지 절약하자.",
        "걷기와 자전거 타기를 생활화하자.",
        "물 절약을 위해 양치컵 사용을 생활화하자.",
        "일회용품 대신 다회용품을 사용하자."
    ]

    try:
        with open(file_path, "w", encoding="utf-8") as f:
            if mode == "fixed":
                for line in fixed_contents:
                    f.write(line + "\n\n")
                print(f"고정 모드: {len(fixed_contents)}개 문단 저장 완료")

            elif mode == "random":
                for _ in range(num_paragraphs):
                    paragraph = " ".join(random.sample(random_sentences, k=3))  # 문장 3개 랜덤 조합
                    f.write(paragraph + "\n\n")
                print(f"랜덤 모드: {num_paragraphs}개 문단 저장 완료")

            else:
                print(f"오류: 지원하지 않는 모드입니다. ('fixed' 또는 'random' 사용)")

    except Exception as e:
        print(f"파일 생성 실패: {str(e)}")

# 테스트용 실행 코드
if __name__ == "__main__":
    # 예시: "fixed" 또는 "random" 모드 선택
    generate_challenge_docs("challenge_docs.txt", mode="random")
    # generate_challenge_docs("challenge_docs.txt", mode="random", num_paragraphs=100)
```

- ### 실행

```python
python generate_challenge_docs_unified.py
```

- embed_init.py: **Qdrant에 저장하고 싶을 때**

```python
# embed_init.py
# Qdrant와 SentenceTransformerEmbeddings를 사용하여 문서 임베딩 및 저장
from generate_challenge_docs_unified import generate_challenge_docs
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_qdrant import Qdrant
from qdrant_client import QdrantClient
from qdrant_client.http.models import VectorParams, Distance
from dotenv import load_dotenv
import os

load_dotenv()

# 환경변수 로드
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION_NAME = "my-new-collection" 

# Qdrant 클라이언트
qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

# 현재 존재하는 컬렉션 목록 조회
try:
    existing_collections = qdrant_client.get_collections().collections
    existing_names = [coll.name for coll in existing_collections]
    print(f"현재 Qdrant에 존재하는 컬렉션 목록: {existing_names}")
except Exception as e:
    print(f"컬렉션 목록 조회 중 오류 발생: {str(e)}")

# 콜렉션 없으면 새로 생성
try:
    collections = qdrant_client.get_collections().collections
    collection_names = [coll.name for coll in collections]

    if not qdrant_client.collection_exists(COLLECTION_NAME):
        print(f"📦 '{COLLECTION_NAME}' 컬렉션 생성")
        qdrant_client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=384, distance=Distance.COSINE)
        )
    else:
        print(f"'{COLLECTION_NAME}' 컬렉션이 이미 존재합니다.")
except Exception as e:
    print(f"컬렉션 생성 중 오류 발생: {str(e)}")

# 임베딩 모델
embedding_fn = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")

# Qdrant vectorstore 객체
vectorstore = Qdrant(
    client=qdrant_client,
    collection_name=COLLECTION_NAME,
    embeddings=embedding_fn,
)


retriever = vectorstore.as_retriever()

# 문서 임베딩 및 저장
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

try:
    # 챌린지 문서 자동 생성
    generate_challenge_docs(file_path="challenge_docs.txt", mode="fixed")  # 또는 "random"
    documents = TextLoader("challenge_docs.txt").load()
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(documents)
    vectorstore.add_documents(chunks)
    print("문서 임베딩 및 Qdrant 저장 완료")
    try:
        collection_info = qdrant_client.get_collection(COLLECTION_NAME)
        vector_count = collection_info.points_count
        print(f"현재 Qdrant에 저장된 벡터 수: {vector_count}")
    except Exception as e:
        print(f"벡터 수 조회 중 오류 발생: {str(e)}")
except Exception as e:
    print(f"문서 임베딩 중 오류 발생: {str(e)}")

__all__ = ["embedding_fn", "vectorstore", "retriever", "qdrant_client", "COLLECTION_NAME"]

```

- 여기서 보험용(fallback) 코드가 숨겨져 있다.

```python
RESET_COLLECTION = os.getenv("RESET_COLLECTION", "false").lower() == "true"
```

- 해당 코드는 .env 파일 내부에  `RESET_COLLECTION` 가 명시되어 있지 않으면 `false` 로 간주, 명시 되어있다면, 대소문자 상관없이 `true` 로 간주
- 만약 `true` 로 간주되면 해당 파일 실행시, QdrantDB내 해당 컬렉션은 삭제 및 초기화

---

## QdrantDB

1. **random_sentences 리스트를 수정하면 Qdrant 벡터DB 데이터가 바뀌나요?**

**조건부로 YES입니다.**

- random_sentences 리스트를 수정하면 → generate_challenge_docs()로 생성되는 challenge_docs.txt 내용이 달라짐
- 그 후 **embed_init.py를 실행**하면 → 이 새로운 텍스트를 기반으로 다시 벡터 임베딩이 수행됨
- 이때 **기존 Qdrant 벡터DB에 추가되거나, 중복 저장될 수 있음** (자동 갱신은 아님)

2. **그럼 기존 벡터는 삭제되지 않나요?**

**아니요. LangChain의 .add_documents()는 기본적으로 “기존 컬렉션에 덧붙이는(additive)” 방식입니다.**

- 이전에 저장된 벡터는 그대로 유지됨
- 새로 임베딩된 벡터는 **추가로 저장됨**
- 따라서 Qdrant 컬렉션 내 벡터 수가 계속 늘어남

---

- chatbot_langchain_rag_chain.py

## **결론**

> PromptTemplate은 f-string이 **절대 아니다다*. f-string을 쓰면 PromptTemplate 자체 기능이 **무력화**되므로,

> 반드시 그냥 """ ... """ 문자열로 쓰자!

| **상황**                         | **{}**가 변수로 해석됨?****            | **{{}}**로 이스케이프 해야 함?**** | **이유**                          |
| ------------------------------ | ------------------------------- | ------------------------- | ------------------------------- |
| f""" ... """                   | 네 (Python이 처리함)               | 예                       | Python의 f-string                |
| """ ... """                    | 아니요                           | 아님                      | 일반 문자열                          |
| PromptTemplate(template="...") | 네 (LangChain이 .format()으로 처리) | 예                       | LangChain 내부가 .format() 기반이기 때문 |

- ## 프롬프팅으로 ```json 사용하지 말라고 유도하는 것" vs "코드로 마크다운을 후처리로 제거하는 것" 중어느 쪽이 응답 속도에 더 영향을 덜 주느냐?

- 정답: 응답 속도 관점에서는 “둘 다 거의 차이 없다”
    1. 프롬프팅 추가는 LLM이 생성하는 데 걸리는 시간에 거의 영행없음
        - 프롬프트가 수십 token 늘어나는 정도
        - LLM 응답 생성하는 중요한 정보(질문,contex)만이 시간에 큰 영향을 줌

        > 그럼 수십 token이 뭐 코딱지 만한건가?

        > 아래 표를 보자

| **항목**                     | **영향 크기**                          |
| -------------------------- | ---------------------------------- |
| **Prompt 길이 +50 token**    | 응답 속도에 **거의 영향 없음** (0.01~0.1초 이내) |
| **Prompt 길이 +500 token**   | 다소 영향 있음 (0.3~0.5초 정도 느려짐)         |
| **Prompt 길이 +1000+ token** | 명확하게 느려짐 (1초 이상 증가 가능)             |

1. 코드 후처리(re.sub)는 응답을 받은 이후의 작업임
    - 그래서 거의 뭐 무시할 수준이다 (코드 한줄 추가했다고 속도 차이 없으니)   