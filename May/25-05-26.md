# 오늘 내가 배운 것들(Today I Learned)

- 중복 임배딩 이슈 발생

![Image.png](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/3CD21776-9D75-4691-8152-9EDBCB9607EB_2/ReMUUK92O3NcGJxnn25zKPM874jLKthEmjdQyamhmIgz/Image.png)

---

## 트러블 슈팅

1. 웹 크롤링을 하여 Qdrant에 저장하려고 하니 오류가 발생함.

```plaintext
크롤링 기반 챌린지 (환경일보 뉴스만) 38개 생성 완료
파일 생성 실패: expected str, bytes or os.PathLike object, not NoneType
'88'개 문서 로드 및 '88'개 청크 생성 완료
문서 임베딩 중 오류 발생: Unexpected Response: 400 (Bad Request)
Raw response content:
b'{"status":{"error":"Format error in JSON body: value 9b3152bd5b36c59cdd2d39206cd834a9cf2d6473d816734236a6f29e789517ff is not a valid point ID, valid values are either an unsigned integer or a UUID" ...'
```

- Qdrant는 포인트 ID로 다음 두가지 형식만 러용함.

    1. unsigned integer(부호 없는 정수)
    2. UUID

-  현재 코드는 SHA256해시(64자리 16진수 문자열)를 ID로 사용하고 있어서 오류가 발생함
+ model/chatbot/embed_init.py

```python
# embed_init.py
# Qdrant와 SentenceTransformerEmbeddings를 사용하여 문서 임베딩 및 저장
from generate_challenge_docs import generate_challenge_docs
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_qdrant import Qdrant
from qdrant_client import QdrantClient, models
from qdrant_client.http.models import VectorParams, Distance, PointStruct
from langchain.text_splitter import CharacterTextSplitter
from langchain.schema import Document
from dotenv import load_dotenv
import os
import hashlib

load_dotenv()

# 환경변수 로드
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME")

# Qdrant 클라이언트
qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

# 현재 존재하는 컬렉션 목록 조회
try:
    existing_collections = qdrant_client.get_collections().collections
    existing_names = [coll.name for coll in existing_collections]
    print(f"현재 Qdrant에 존재하는 컬렉션 목록: {existing_names}")
except Exception as e:
    print(f"컬렉션 목록 조회 중 오류 발생: {str(e)}")

# 콜렉션 없으면 새로 생성
try:
    collections = qdrant_client.get_collections().collections
    collection_names = [coll.name for coll in collections]

    if not qdrant_client.collection_exists(COLLECTION_NAME):
        print(f" '{COLLECTION_NAME}' 컬렉션 생성")
        qdrant_client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=384, distance=Distance.COSINE)
        )
    else:
        print(f" '{COLLECTION_NAME}' 컬렉션이 이미 존재합니다.")
except Exception as e:
    print(f"컬렉션 생성 중 오류 발생: {str(e)}")

# 임베딩 모델
embedding_fn = SentenceTransformerEmbeddings(model_name="BAAI/bge-small-en-v1.5")

# Qdrant vectorstore 객체
vectorstore = Qdrant(
    client=qdrant_client,
    collection_name=COLLECTION_NAME,
    embeddings=embedding_fn,
)

RESET_COLLECTION = os.getenv("RESET_COLLECTION", "false").lower() == "true"
"""
환경변수 RESET_COLLECTION이 존재하지 않으면 기본값은 "false"로 간주"
컬렉션을 리셋할지 여부 (환경변수 또는 코드로 지정)
환경변수로 설정된 경우 우선 적용
예: export RESET_COLLECTION=true
기존 컬렉션을 완전히 삭제 후 새로 생성
"""

if RESET_COLLECTION:
    try:
        print(f"기존 컬렉션 '{COLLECTION_NAME}' 삭제 중")
        qdrant_client.delete_collection(collection_name=COLLECTION_NAME)
        qdrant_client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=384, distance=Distance.COSINE)
        )
        print(f"컬렉션 초기화 완료: '{COLLECTION_NAME}'")
    except Exception as e:
        print(f"컬렉션 초기화 중 오류 발생: {str(e)}")

# 문서 생성 및 벡터 저장은 항상 실행
try:
    # 크롤링 및 데이터 생성
    result = generate_challenge_docs(file_path=None, mode="random")
    fixed_challenges = result["fixed_challenges"]
    crawled_challenges = result["crawled_challenges"]
    
    # 청크 분할
    splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=20)
    documents = []
    
    # 1. 고정 데이터 처리
    for challenge in fixed_challenges:
        # 고정 데이터의 메타데이터 추출
        metadata = {
            "category": (
                "제로웨이스트" if "제로웨이스트" in challenge or "플라스틱" in challenge or "분리수거" in challenge else
                "플로깅" if "플로깅" in challenge or "정화" in challenge or "청소" in challenge else
                "비건" if "비건" in challenge or "채식" in challenge or "식단" in challenge else
                "에너지절약" if "에너지" in challenge or "전기" in challenge or "냉난방" in challenge else
                "업사이클" if "업사이클" in challenge or "재활용" in challenge or "DIY" in challenge else
                "문화공유" if "공유" in challenge or "캠페인" in challenge or "워크숍" in challenge else
                "디지털탄소" if "디지털" in challenge or "이메일" in challenge or "클라우드" in challenge else
                "기타"
            ),
            "source": "기본데이터"
        }
        documents.append(Document(page_content=challenge, metadata=metadata))
    
    # 2. 크롤링 데이터 처리
    for challenge in crawled_challenges:
        documents.append(Document(
            page_content=challenge["content"],
            metadata=challenge["metadata"]
        ))
    
    # 청크 분할
    chunks = splitter.split_documents(documents)
    
    print(f"'{len(documents)}'개 문서 로드 및 '{len(chunks)}'개 청크 생성 완료")

    # 임베딩 및 Qdrant 저장 (중복 방지 - upsert 사용)
    points_to_insert = []
    for chunk in chunks:
        # 문서 내용의 해시값을 ID로 사용 (중복 방지)
        doc_id = hashlib.sha256(chunk.page_content.encode('utf-8')).hexdigest()
        
        vector = embedding_fn.embed_query(chunk.page_content)
        points_to_insert.append(
            PointStruct(
                id=doc_id,
                vector=vector,
                payload=chunk.metadata
            )
        )

    # Qdrant에 포인트 삽입
    if points_to_insert:
        # upsert: ID가 존재하면 업데이트, 없으면 삽입 (중복 방지)
        # wait=True: 작업 완료까지 대기
        response = qdrant_client.upsert(
            collection_name=COLLECTION_NAME,
            wait=True,
            points=points_to_insert
        )
        print(f"Qdrant 삽입 응답: {response.status}")
        print(f"{len(points_to_insert)}개 포인트 삽입 시도 완료 (중복 포함)")
        
        try:
            collection_info = qdrant_client.get_collection(COLLECTION_NAME)
            vector_count = collection_info.points_count
            print(f"현재 Qdrant에 저장된 총 누적 벡터 수: {vector_count}")
        except Exception as e:
            print(f"벡터 수 조회 중 오류 발생: {str(e)}")
    else:
        print("삽입할 포인트가 없습니다.")

except Exception as e:
    print(f"문서 임베딩 중 오류 발생: {str(e)}")

```

    - 해결 방안:
        - SHA256해시를 unsigned integer로 변환하는 해시의 첫 8바이트를 정수로 변환
            1. struct 모듈을 추가하여 바이너리 데이터 처리
            2. SHA256 해시를 생성할 때 hexdigest() 대신 digest()를 사용하여 바이너리 형태로 가져옴
            3. 해시의 첫 8바이트를 struct.unpack('!Q', ...)를 사용하여 unsigned integer로 변환
                - !Q는 네트워크 바이트 순서(big-endian)의 8바이트 unsigned integer를 의미
    + 수정한 model/chatbot/embed_init.py

```python
# embed_init.py
# Qdrant와 SentenceTransformerEmbeddings를 사용하여 문서 임베딩 및 저장
from generate_challenge_docs import generate_challenge_docs
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_qdrant import Qdrant
from qdrant_client import QdrantClient, models
from qdrant_client.http.models import VectorParams, Distance, PointStruct
from langchain.text_splitter import CharacterTextSplitter
from langchain.schema import Document
from dotenv import load_dotenv
import os
import hashlib
import struct

load_dotenv()

# 환경변수 로드
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME")

# Qdrant 클라이언트
qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

# 현재 존재하는 컬렉션 목록 조회
try:
    existing_collections = qdrant_client.get_collections().collections
    existing_names = [coll.name for coll in existing_collections]
    print(f"현재 Qdrant에 존재하는 컬렉션 목록: {existing_names}")
except Exception as e:
    print(f"컬렉션 목록 조회 중 오류 발생: {str(e)}")

# 콜렉션 없으면 새로 생성
try:
    collections = qdrant_client.get_collections().collections
    collection_names = [coll.name for coll in collections]

    if not qdrant_client.collection_exists(COLLECTION_NAME):
        print(f" '{COLLECTION_NAME}' 컬렉션 생성")
        qdrant_client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=384, distance=Distance.COSINE)
        )
    else:
        print(f" '{COLLECTION_NAME}' 컬렉션이 이미 존재합니다.")
except Exception as e:
    print(f"컬렉션 생성 중 오류 발생: {str(e)}")

# 임베딩 모델
embedding_fn = SentenceTransformerEmbeddings(model_name="BAAI/bge-small-en-v1.5")

# Qdrant vectorstore 객체
vectorstore = Qdrant(
    client=qdrant_client,
    collection_name=COLLECTION_NAME,
    embeddings=embedding_fn,
)

RESET_COLLECTION = os.getenv("RESET_COLLECTION", "false").lower() == "true"
"""
환경변수 RESET_COLLECTION이 존재하지 않으면 기본값은 "false"로 간주"
컬렉션을 리셋할지 여부 (환경변수 또는 코드로 지정)
환경변수로 설정된 경우 우선 적용
예: export RESET_COLLECTION=true
기존 컬렉션을 완전히 삭제 후 새로 생성
"""

if RESET_COLLECTION:
    try:
        print(f"기존 컬렉션 '{COLLECTION_NAME}' 삭제 중")
        qdrant_client.delete_collection(collection_name=COLLECTION_NAME)
        qdrant_client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=384, distance=Distance.COSINE)
        )
        print(f"컬렉션 초기화 완료: '{COLLECTION_NAME}'")
    except Exception as e:
        print(f"컬렉션 초기화 중 오류 발생: {str(e)}")

# 문서 생성 및 벡터 저장은 항상 실행
try:
    # 크롤링 및 데이터 생성
    result = generate_challenge_docs(file_path=None, mode="random")
    fixed_challenges = result["fixed_challenges"]
    crawled_challenges = result["crawled_challenges"]
    
    # 청크 분할
    splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=20)
    documents = []
    
    # 1. 고정 데이터 처리
    for challenge in fixed_challenges:
        # 고정 데이터의 메타데이터 추출
        metadata = {
            "category": (
                "제로웨이스트" if "제로웨이스트" in challenge or "플라스틱" in challenge or "분리수거" in challenge else
                "플로깅" if "플로깅" in challenge or "정화" in challenge or "청소" in challenge else
                "비건" if "비건" in challenge or "채식" in challenge or "식단" in challenge else
                "에너지절약" if "에너지" in challenge or "전기" in challenge or "냉난방" in challenge else
                "업사이클" if "업사이클" in challenge or "재활용" in challenge or "DIY" in challenge else
                "문화공유" if "공유" in challenge or "캠페인" in challenge or "워크숍" in challenge else
                "디지털탄소" if "디지털" in challenge or "이메일" in challenge or "클라우드" in challenge else
                "기타"
            ),
            "source": "기본데이터"
        }
        documents.append(Document(page_content=challenge, metadata=metadata))
    
    # 2. 크롤링 데이터 처리
    for challenge in crawled_challenges:
        documents.append(Document(
            page_content=challenge["content"],
            metadata=challenge["metadata"]
        ))
    
    # 청크 분할
    chunks = splitter.split_documents(documents)
    
    print(f"'{len(documents)}'개 문서 로드 및 '{len(chunks)}'개 청크 생성 완료")

    # 임베딩 및 Qdrant 저장 (중복 방지 - upsert 사용)
    points_to_insert = []
    for chunk in chunks:
        # 문서 내용의 해시값을 계산
        hash_obj = hashlib.sha256(chunk.page_content.encode('utf-8'))
        # 해시의 첫 8바이트를 unsigned integer로 변환
        doc_id = struct.unpack('!Q', hash_obj.digest()[:8])[0]
        
        vector = embedding_fn.embed_query(chunk.page_content)
        points_to_insert.append(
            PointStruct(
                id=doc_id,  # unsigned integer ID 사용
                vector=vector,
                payload=chunk.metadata
            )
        )

    # Qdrant에 포인트 삽입
    if points_to_insert:
        # upsert: ID가 존재하면 업데이트, 없으면 삽입 (중복 방지)
        # wait=True: 작업 완료까지 대기
        response = qdrant_client.upsert(
            collection_name=COLLECTION_NAME,
            wait=True,
            points=points_to_insert
        )
        print(f"Qdrant 삽입 응답: {response.status}")
        print(f"{len(points_to_insert)}개 포인트 삽입 시도 완료 (중복 포함)")
        
        try:
            collection_info = qdrant_client.get_collection(COLLECTION_NAME)
            vector_count = collection_info.points_count
            print(f"현재 Qdrant에 저장된 총 누적 벡터 수: {vector_count}")
        except Exception as e:
            print(f"벡터 수 조회 중 오류 발생: {str(e)}")
    else:
        print("삽입할 포인트가 없습니다.")

except Exception as e:
    print(f"문서 임베딩 중 오류 발생: {str(e)}")

```

+ 출력 값

![Image.png](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/4E2223B9-DE97-43A2-A16F-41CDA673D896_2/si3n2EUho5hk7OCkZBxAyEUJzGXW6e7dkHwcgy2MjdEz/Image.png)

- 실행 결과를 분석해보면:
    1. 데이터 로드 결과:
        - 고정 데이터: 50개
        - 크롤링 데이터: 35개
        - 총 문서 수: 85개
    2. 청크 분할 결과:
        - 고정 데이터 청크: 50개
        - 크롤링 데이터 청크: 35개
        - 총 청크 수: 85개
        - 청크 크기: 300자, 중복: 20자
    3. Qdrant 저장 결과:
        - 삽입 시도: 85개
        - 최종 저장된 벡터 수: 75개
        - 중복 제거된 수: 10개 (85 - 75)
    4. 문서 검색이 안되는 오류
        - 아래와 같이 문서 검색이 되지 않았다.

![Image.png](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/57A34464-9406-4D78-95EF-C726315C2D9D_2/MIyhB27baxh5RX8MTec2tF5ryUdxqyvage1V4lQ2gdsz/Image.png)

- 현재 LLM_chatbot_free_text_model.py 코드에서 `qa_chain` 생성을 아래와 같이 하였다.

```python
# LLMChain 체인 생성 (retriever는 app_router에서 별도 사용)
qa_chain = LLMChain(
    llm=llm,
    prompt=custom_prompt
)
```

- 주석에도 쓰여 있듯이, `LLMChain` 은 `retriever` 기능을 내장하고 있지 **않는다.**
- 해당 체인은 단순히 주어진 프롬프트와 입력 변수(context, query)를 LLM에 전달하고 응답받는 역할만 함
- 그래서 “chatbot_router.py” 에서 아래와 같이 호출하여 뮨서를 검색함

```python
docs = retriever.invoke(req.message)
```

- 검색된 문서들을 context_text로 합쳐서 qa_chain.invoke({"context": context_text, "query": req.message})를 통해 LLM에게 전달하는 로직은 구성이 되어있음.

---

## 테스트

+ search_performance_test.py

```python
# search_performance_test.py
# 검색 성능 테스트 스크립트
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_qdrant import Qdrant
from qdrant_client import QdrantClient
from qdrant_client.http.models import SearchParams
from dotenv import load_dotenv
import os
import time
from datetime import datetime
from collections import defaultdict
import numpy as np

# 환경변수 로드
load_dotenv()

# Qdrant 클라이언트 초기화
qdrant_client = QdrantClient(
    url=os.getenv("QDRANT_URL"),
    api_key=os.getenv("QDRANT_API_KEY")
)

# 임베딩 모델 초기화
embedding_fn = SentenceTransformerEmbeddings(model_name="BAAI/bge-small-en-v1.5")

# Qdrant vectorstore 객체 초기화
vectorstore = Qdrant(
    client=qdrant_client,
    collection_name=os.getenv("QDRANT_COLLECTION_NAME"),
    embeddings=embedding_fn,
)

def search_similar_challenges(query, limit=5, ef_value=128):
    """
    유사한 챌린지를 검색하는 함수
    Args:
        query (str): 검색 쿼리
        limit (int): 반환할 결과 수
        ef_value (int): HNSW ef 파라미터 값
    Returns:
        list: 검색 결과 문서 리스트와 점수
    """
    try:
        # 검색 파라미터 설정
        search_params = SearchParams(
            hnsw_ef=ef_value,  # ef 값 설정
            exact=False   # 근사 검색 사용
        )
        
        # 검색 실행 (점수 포함)
        results = vectorstore.similarity_search_with_score(
            query,
            k=limit,
            search_params=search_params
        )
        
        return results
        
    except Exception as e:
        print(f"검색 중 오류 발생: {str(e)}")
        return []

def calculate_quality_score(results, search_time):
    """
    검색 결과의 품질 점수를 계산하는 함수
    Args:
        results (list): 검색 결과와 점수
        search_time (float): 검색 시간
    Returns:
        float: 품질 점수
    """
    if not results:
        return 0.0
    
    # 1. 평균 유사도 점수 (0~1 사이로 정규화)
    similarity_scores = [score for _, score in results]
    avg_similarity = np.mean(similarity_scores)
    
    # 2. 카테고리 다양성 점수
    categories = set()
    for doc, _ in results:
        category = doc.metadata.get('category', 'N/A')
        categories.add(category)
    diversity_score = len(categories) / 5  # 최대 5개 카테고리 기준
    
    # 3. 시간 점수 (1초를 기준으로 정규화)
    time_score = 1.0 / (1.0 + search_time)
    
    # 최종 품질 점수 계산 (가중치 조정 가능)
    quality_score = (
        0.5 * avg_similarity +  # 유사도 점수 (50%)
        0.3 * diversity_score +  # 다양성 점수 (30%)
        0.2 * time_score  # 시간 점수 (20%)
    )
    
    return quality_score

def analyze_results(query_results):
    """
    검색 결과를 분석하는 함수
    Args:
        query_results (dict): 쿼리별 ef 값에 따른 검색 결과
    Returns:
        dict: 분석 결과
    """
    analysis = {
        'best_ef': None,
        'best_quality_score': -1,
        'best_time': float('inf'),
        'avg_time': 0,
        'total_docs': 0,
        'category_distribution': defaultdict(int),
        'quality_scores': {}  # 각 ef 값별 품질 점수
    }
    
    total_time = 0
    for ef, result in query_results.items():
        time = result['time']
        total_time += time
        
        # 품질 점수 계산
        quality_score = calculate_quality_score(result['results'], time)
        analysis['quality_scores'][ef] = quality_score
        
        if quality_score > analysis['best_quality_score']:
            analysis['best_quality_score'] = quality_score
            analysis['best_ef'] = ef
            analysis['best_time'] = time
            
        for doc, _ in result['results']:
            analysis['total_docs'] += 1
            category = doc.metadata.get('category', 'N/A')
            analysis['category_distribution'][category] += 1
    
    analysis['avg_time'] = total_time / len(query_results)
    return analysis

def run_performance_test():
    """
    검색 성능 테스트를 실행하고 결과를 파일로 저장하는 함수
    """
    # 테스트 쿼리 목록
    test_queries = [
        "환경 보호를 위한 일상적인 실천 방법",
        "플라스틱 사용 줄이기",
        "에너지 절약 방법",
        "친환경 교통수단",
        "재활용과 업사이클링"
    ]
    
    # 테스트할 ef 값 목록
    ef_values = [40, 100, 128, 200, 400]
    
    # 결과를 저장할 파일명 (현재 시간 포함)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = f"search_performance_test_{timestamp}.txt"
    
    # 전체 테스트 결과 분석을 위한 데이터
    overall_analysis = {
        'query_results': {},
        'best_ef_counts': defaultdict(int),
        'quality_scores': defaultdict(list)  # ef 값별 품질 점수 누적
    }
    
    with open(result_file, "w", encoding="utf-8") as f:
        f.write("=== 검색 성능 테스트 결과 ===\n")
        f.write(f"테스트 시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        for query in test_queries:
            print(f"\n{'='*50}")
            print(f"테스트 쿼리: {query}")
            print(f"{'='*50}")
            
            f.write(f"\n{'='*50}\n")
            f.write(f"테스트 쿼리: {query}\n")
            f.write(f"{'='*50}\n")
            
            # 각 쿼리의 결과를 저장할 딕셔너리
            query_results = {}
            
            # 각 ef 값에 대한 테스트
            for ef in ef_values:
                print(f"\n--- ef={ef} 테스트 ---")
                f.write(f"\n--- ef={ef} 테스트 ---\n")
                
                # 검색 실행 및 결과 저장
                start_time = time.time()
                results = search_similar_challenges(query, ef_value=ef)
                end_time = time.time()
                search_time = end_time - start_time
                
                # 결과 저장
                query_results[ef] = {
                    'time': search_time,
                    'results': results
                }
                
                # 실행 시간 기록
                print(f"검색 시간: {search_time:.3f}초")
                f.write(f"검색 시간: {search_time:.3f}초\n")
                
                # 검색 결과 저장
                if results:
                    print(f"검색된 문서 수: {len(results)}")
                    f.write(f"검색된 문서 수: {len(results)}\n")
                    for i, (doc, score) in enumerate(results, 1):
                        print(f"\n[문서 {i}]")
                        print(f"내용: {doc.page_content}")
                        print(f"카테고리: {doc.metadata.get('category', 'N/A')}")
                        print(f"유사도 점수: {score:.4f}")
                        
                        f.write(f"\n[문서 {i}]\n")
                        f.write(f"내용: {doc.page_content}\n")
                        f.write(f"카테고리: {doc.metadata.get('category', 'N/A')}\n")
                        f.write(f"유사도 점수: {score:.4f}\n")
                else:
                    print("검색 결과가 없습니다.")
                    f.write("검색 결과가 없습니다.\n")
                
                print("\n" + "-"*30)
                f.write("\n" + "-"*30 + "\n")
            
            # 쿼리별 결과 분석
            analysis = analyze_results(query_results)
            overall_analysis['query_results'][query] = analysis
            overall_analysis['best_ef_counts'][analysis['best_ef']] += 1
            
            # 각 ef 값의 품질 점수 누적
            for ef, score in analysis['quality_scores'].items():
                overall_analysis['quality_scores'][ef].append(score)
            
            # 쿼리별 분석 결과 출력
            print(f"\n=== 쿼리 분석 결과 ===")
            print(f"최적의 ef 값: {analysis['best_ef']}")
            print(f"최고 품질 점수: {analysis['best_quality_score']:.4f}")
            print(f"최고 검색 시간: {analysis['best_time']:.3f}초")
            print(f"평균 검색 시간: {analysis['avg_time']:.3f}초")
            print(f"총 검색된 문서 수: {analysis['total_docs']}")
            print("카테고리 분포:")
            for category, count in analysis['category_distribution'].items():
                print(f"- {category}: {count}개")
            print("\n각 ef 값별 품질 점수:")
            for ef, score in analysis['quality_scores'].items():
                print(f"- ef={ef}: {score:.4f}")
            
            f.write(f"\n=== 쿼리 분석 결과 ===\n")
            f.write(f"최적의 ef 값: {analysis['best_ef']}\n")
            f.write(f"최고 품질 점수: {analysis['best_quality_score']:.4f}\n")
            f.write(f"최고 검색 시간: {analysis['best_time']:.3f}초\n")
            f.write(f"평균 검색 시간: {analysis['avg_time']:.3f}초\n")
            f.write(f"총 검색된 문서 수: {analysis['total_docs']}\n")
            f.write("카테고리 분포:\n")
            for category, count in analysis['category_distribution'].items():
                f.write(f"- {category}: {count}개\n")
            f.write("\n각 ef 값별 품질 점수:\n")
            for ef, score in analysis['quality_scores'].items():
                f.write(f"- ef={ef}: {score:.4f}\n")
            
            print("\n" + "="*50)
            f.write("\n" + "="*50 + "\n")
        
        # 전체 테스트 분석 결과
        print("\n=== 전체 테스트 분석 결과 ===")
        print("ef 값별 최적 성능 횟수:")
        for ef, count in overall_analysis['best_ef_counts'].items():
            print(f"ef={ef}: {count}회")
        
        print("\n각 ef 값별 평균 품질 점수:")
        for ef, scores in overall_analysis['quality_scores'].items():
            avg_score = np.mean(scores)
            print(f"ef={ef}: {avg_score:.4f}")
        
        f.write("\n=== 전체 테스트 분석 결과 ===\n")
        f.write("ef 값별 최적 성능 횟수:\n")
        for ef, count in overall_analysis['best_ef_counts'].items():
            f.write(f"ef={ef}: {count}회\n")
        
        f.write("\n각 ef 값별 평균 품질 점수:\n")
        for ef, scores in overall_analysis['quality_scores'].items():
            avg_score = np.mean(scores)
            f.write(f"ef={ef}: {avg_score:.4f}\n")
        
        f.write(f"\n테스트 종료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

if __name__ == "__main__":
    print("검색 성능 테스트를 시작합니다...")
    run_performance_test()
    print("테스트가 완료되었습니다. 결과는 search_performance_test_[timestamp].txt 파일에서 확인할 수 있습니다.") 
```

+ 테스트 결과

```python
=== 쿼리 분석 결과 ===
최적의 ef 값: 200
최고 품질 점수: 0.7537
최고 검색 시간: 0.210초
평균 검색 시간: 0.222초
총 검색된 문서 수: 25
카테고리 분포:
- 업사이클: 10개
- 기타: 15개

각 ef 값별 품질 점수:
- ef=40: 0.7484
- ef=100: 0.7525
- ef=128: 0.7529
- ef=200: 0.7537
- ef=400: 0.7528

==================================================

=== 전체 테스트 분석 결과 ===
ef 값별 최적 성능 횟수:
ef=400: 2회
ef=128: 1회
ef=100: 1회
ef=200: 1회

각 ef 값별 평균 품질 점수:
ef=40: 0.7409
ef=100: 0.7557
ef=128: 0.7556
ef=200: 0.7552
ef=400: 0.7562

테스트 종료 시간: 2025-05-27 00:52:20
```

![Image.png](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/0FABC7EC-2084-4C10-A783-BA762894ED84_2/Wkr0iieIuBhqibPkhDnUjrD66UD1Ru61FcpPBAVi8pAz/Image.png)

- HNSW(Hierarchical Navigable Small World) 알고리즘의 ef 파라미터는 검색의 정확도와 속도 사이의 트레이드오프를 조절:

1. ef 값의 일반적인 범위:
    - ef=40: 매우 빠른 검색, 낮은 정확도
    - ef=100: 중간 속도, 중간 정확도
    - ef=200: 느린 검색, 높은 정확도
    - ef=400: 매우 느린 검색, 매우 높은 정확도
1. 현재 설정 (ef=128):
    - 중간~높은 정확도 범위에 속합니다
    - 대부분의 일반적인 검색 케이스에 적합한 값입니다
    - 검색 속도와 정확도의 균형이 잘 맞춰져 있습니다

### 결론

- ### 최적의 값은 128로 지정