# 오늘 내가 배운 것들(Today I Learned)

- 현재 스프린트4(v1유지보수기간)이다.
- 나는 챗봇 담당을 하고 있는 상황
- 기존에 작업했던 sessionId  추가 & 이전 대화 저장이 사실상 V2로 결정이 되었다.
- 심지어 백엔드측은 해당 사항을 미리 배포한 상황
- 프론트&백 엔드와의 소통 문제로 서로 다르게 생각 하고 있었다.
- 앞으로 데드라인을 지켜서 협업해야 겠다는 생각이 들었다.

##  무엇보다 현재 내가 하고 있는 챗봇 수정이 “기능 추가 "인지 "유지보수" 인지 애매하였다.

- 그래서 이번 스프린트4 유지보수 기간이라서 기존에 작업하던 "sessionId  추가 & 이전 대화 저장”은 기능 추가로, V2 배포때 구현되기로 했다. 
- 그래서 이번주 스프린트4 기간에는, 프롬프팅 재 설계부터 해서 필터링 추가 작업 및 RAG기법 강화 그리고 테스트를 진행 예정이다.
- 다음주 스프린트 5시작(3주)에는 V2 버전 작업에 들어갈 예정이고 우선은 DEV에서 자체서빙으로 제작하고 있는 모델에만 SSE도입 결정하였다.

---

###  RAG기법 고도화를 진행함.(test)

+ test_RAG.py 생성

```python
# LLM_chatbot_free_text_model.py
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_qdrant import Qdrant
from langchain_community.embeddings import SentenceTransformerEmbeddings
from qdrant_client import QdrantClient
from langchain_google_vertexai import VertexAI
from dotenv import load_dotenv
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
# from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated, Sequence, Optional, Dict, List
import os
import json
import time
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain.retrievers.multi_query import MultiQueryRetriever

load_dotenv()

QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME")

qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
embedding_model = SentenceTransformerEmbeddings(model_name="BAAI/bge-small-en-v1.5")

vectorstore = Qdrant(
    client=qdrant_client,
    collection_name=COLLECTION_NAME,
    embeddings=embedding_model
)
# 기본 RAG
base_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# 유사도 임계값 적용 RAG
threshold_retriever = vectorstore.as_retriever(
    search_kwargs={
        "k": 5,
        "score_threshold": 0.7
    }
)

# MMR 적용 RAG
mmr_retriever = vectorstore.as_retriever(
    search_kwargs={
        "k": 5,
        "mmr": True,
        "mmr_threshold": 0.7
    }
)

# 메타데이터 필터링 적용 RAG
metadata_retriever = vectorstore.as_retriever(
    search_kwargs={
        "k": 5,
        "filter": {
            "category": "환경보호"  # 예시 필터
        }
    }
)

# RAG 방식 챌린지 추천을 위한 Output Parser 정의
rag_response_schemas = [
    ResponseSchema(name="recommend", description="추천 텍스트를 한 문장으로 출력해줘."),
    ResponseSchema(name="challenges", description="추천 챌린지 리스트, 각 항목은 title, description 포함, description은 한 문장으로 요약해주세요.")
]

# LangChain의 StructuredOutputParser를 사용하여 JSON 포맷을 정의
rag_parser = StructuredOutputParser.from_response_schemas(rag_response_schemas)

# JSON 포맷을 이스케이프 처리
escaped_format = rag_parser.get_format_instructions().replace("{", "{{").replace("}", "}}")

# 테스트용 프롬프트 템플릿
test_prompt = PromptTemplate(
    input_variables=["context", "query"],
    template=f"""
반드시 문서에서 제공된 정보를 기반으로 사용자에게 적절한 친환경 챌린지를 3개 추천해주세요.

문서:
{{context}}

현재 요청:
{{query}}

응답은 반드시 다음 JSON 형식을 따라주세요:
{escaped_format}
"""
)

# 테스트용 LLMChain
test_chain = LLMChain(
    llm=VertexAI(model_name="gemini-2.0-flash", temperature=0.5),
    prompt=test_prompt
)

def test_rag_performance(query: str, num_runs: int = 3):
    """RAG 성능 테스트 함수
    
    Args:
        query: 테스트할 쿼리
        num_runs: 각 설정별 실행 횟수
    """
    retrievers = {
        "기본 RAG": base_retriever,
        "유사도 임계값 RAG": threshold_retriever,
        "MMR RAG": mmr_retriever,
        "메타데이터 필터링 RAG": metadata_retriever
    }
    
    results = {}
    
    for name, retriever in retrievers.items():
        total_time = 0
        total_docs = 0
        successful_runs = 0
        
        print(f"\n=== {name} 테스트 ===")
        
        for i in range(num_runs):
            try:
                # 검색 시간 측정
                start_time = time.time()
                docs = retriever.get_relevant_documents(query)
                search_time = time.time() - start_time
                
                # 문서 수 기록
                total_docs += len(docs)
                
                # LLM 응답 생성 시간 측정
                start_time = time.time()
                context = "\n".join([doc.page_content for doc in docs])
                response = test_chain.invoke({
                    "context": context,
                    "query": query
                })
                llm_time = time.time() - start_time
                
                total_time += (search_time + llm_time)
                successful_runs += 1
                
                print(f"실행 {i+1}:")
                print(f"- 검색된 문서 수: {len(docs)}")
                print(f"- 검색 시간: {search_time:.2f}초")
                print(f"- LLM 응답 시간: {llm_time:.2f}초")
                print(f"- 총 소요 시간: {search_time + llm_time:.2f}초")
                
            except Exception as e:
                print(f"실행 {i+1} 실패: {str(e)}")
        
        if successful_runs > 0:
            avg_time = total_time / successful_runs
            avg_docs = total_docs / successful_runs
            results[name] = {
                "평균 소요 시간": f"{avg_time:.2f}초",
                "평균 검색 문서 수": f"{avg_docs:.1f}개",
                "성공률": f"{(successful_runs/num_runs)*100:.1f}%"
            }
    
    print("\n=== 테스트 결과 요약 ===")
    for name, metrics in results.items():
        print(f"\n{name}:")
        for metric, value in metrics.items():
            print(f"- {metric}: {value}")

# 테스트 실행 예시
if __name__ == "__main__":
    test_query = "환경을 위해 분리수거를 잘하고 싶어요"
    test_rag_performance(test_query)

# LLM 초기화 (VertexAI)
llm = VertexAI(model_name="gemini-2.0-flash", temperature=0.5)

# LLMChain 체인 생성 (retriever는 app_router에서 별도 사용)
qa_chain = LLMChain(
    llm=llm,
    prompt=custom_prompt
)
```

- 현재 기존 코드에서는 단순 코사인 유사도로 RAG기법을 사용하고 있었다.
- 고도화 테스트를 하기위해 다음과 같은 항목 옵션이 있다.
    1. 유사도 임계값 적용
    2. MMR 적용
    3. 메타데이터 필터링 적용

---

### 테스트 결과 

```plaintext
(PY312_0) iwonho@iwonhoui-MacBookPro v1_AI_api_refactoring % python test_RAG.py
/Users/iwonho/Desktop/[카카오 부트캠프] 파일/[카카오 부트캠프] Leafresh/[leafresh] v1/v1_AI_api_refactoring/test_RAG.py:26: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embedding_model = SentenceTransformerEmbeddings(model_name="BAAI/bge-small-en-v1.5")
/Users/iwonho/Desktop/[카카오 부트캠프] 파일/[카카오 부트캠프] Leafresh/[leafresh] v1/v1_AI_api_refactoring/test_RAG.py:28: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.1.2 and will be removed in 0.5.0. Use :class:`~QdrantVectorStore` instead.
  vectorstore = Qdrant(
/Users/iwonho/Desktop/[카카오 부트캠프] 파일/[카카오 부트캠프] Leafresh/[leafresh] v1/v1_AI_api_refactoring/test_RAG.py:94: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.
  test_chain = LLMChain(

=== 기본 RAG 테스트 ===
/Users/iwonho/Desktop/[카카오 부트캠프] 파일/[카카오 부트캠프] Leafresh/[leafresh] v1/v1_AI_api_refactoring/test_RAG.py:126: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.
  docs = retriever.get_relevant_documents(query)
실행 1:
- 검색된 문서 수: 5
- 검색 시간: 1.15초
- LLM 응답 시간: 2.79초
- 총 소요 시간: 3.94초
실행 2:
- 검색된 문서 수: 5
- 검색 시간: 0.27초
- LLM 응답 시간: 1.56초
- 총 소요 시간: 1.83초
실행 3:
- 검색된 문서 수: 5
- 검색 시간: 0.54초
- LLM 응답 시간: 2.25초
- 총 소요 시간: 2.79초

=== 유사도 임계값 RAG 테스트 ===
실행 1:
- 검색된 문서 수: 5
- 검색 시간: 0.30초
- LLM 응답 시간: 2.01초
- 총 소요 시간: 2.31초
실행 2:
- 검색된 문서 수: 5
- 검색 시간: 0.27초
- LLM 응답 시간: 1.63초
- 총 소요 시간: 1.90초
실행 3:
- 검색된 문서 수: 5
- 검색 시간: 0.25초
- LLM 응답 시간: 1.92초
- 총 소요 시간: 2.17초

=== MMR RAG 테스트 ===
실행 1 실패: Unknown arguments: ['mmr', 'mmr_threshold']
실행 2 실패: Unknown arguments: ['mmr', 'mmr_threshold']
실행 3 실패: Unknown arguments: ['mmr', 'mmr_threshold']

=== 메타데이터 필터링 RAG 테스트 ===
실행 1 실패: Unexpected Response: 403 (Forbidden)
Raw response content:
b'{"status":{"error":"Forbidden: Index required but not found for \\"metadata.category\\" of one of the following types: [keyword]. Help: Create an index for this key or use a different filter."},"time ...'
실행 2 실패: Unexpected Response: 403 (Forbidden)
Raw response content:
b'{"status":{"error":"Forbidden: Index required but not found for \\"metadata.category\\" of one of the following types: [keyword]. Help: Create an index for this key or use a different filter."},"time ...'
실행 3 실패: Unexpected Response: 403 (Forbidden)
Raw response content:
b'{"status":{"error":"Forbidden: Index required but not found for \\"metadata.category\\" of one of the following types: [keyword]. Help: Create an index for this key or use a different filter."},"time ...'

=== 테스트 결과 요약 ===

기본 RAG:
- 평균 소요 시간: 2.85초
- 평균 검색 문서 수: 5.0개
- 성공률: 100.0%

유사도 임계값 RAG:
- 평균 소요 시간: 2.12초
- 평균 검색 문서 수: 5.0개
- 성공률: 100.0%
Traceback (most recent call last):
  File "/Users/iwonho/Desktop/[카카오 부트캠프] 파일/[카카오 부트캠프] Leafresh/[leafresh] v1/v1_AI_api_refactoring/test_RAG.py", line 179, in <module>
    prompt=custom_prompt
           ^^^^^^^^^^^^^
NameError: name 'custom_prompt' is not defined. Did you mean: 'test_prompt'?
```

1. 기본 RAG와 유사도 임계값 RAG의 성능
    - 기본 RAG: 평균 2.85초 소요
    - 유사도 임계값 RAG: 평균 2.12초 소요
    - 두 방식 모두 100% 성공률을 보이며, 안정적으로 5개의 문서를 검색
    - 유사도 임계값 RAG가 약간 더 빠른 성능을 보임
1. MMR RAG의 문제점
    - **오류: "Unknown arguments: ['mmr', 'mmr_threshold']"**
    - 현재 Qdrant 클라이언트가 MMR 파라미터를 지원하지 않아 실패
    - 해결 방안: Qdrant의 *최신* 버전으로 업데이트하거나, 다른 방식의 다양성 확보 방법 고려
1. 메타데이터 필터링 RAG의 문제점
    - **오류: "Forbidden: Index required but not found for 'metadata.category'"**
    - Qdrant 컬렉션에 메타데이터 인덱스가 설정되어 있지 않아 발생
    - 해결 방안: Qdrant 컬렉션에 필요한 메타데이터 인덱스를 생성해야 함
1. 개선 제안
    1. 기본 RAG와 유사도 임계값 RAG는 잘 작동하므로, 이 두 방식을 주로 사용
    2. MMR 기능이 필요한 경우:
        - Qdrant 클라이언트 업데이트
        - 또는 다른 다양성 확보 방법 구현 (예: 클러스터링 기반)

### 결론

- 우선 유사도 임계값 추가와 Qdrant 버전에 맞는 MMR RAG 및 메타 데이터 필터링 수정이 필요해 보임