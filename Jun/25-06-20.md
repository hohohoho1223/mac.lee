# ì˜¤ëŠ˜ ë‚´ê°€ ë°°ìš´ ê²ƒë“¤(Today I Learned)

- í”¼ë“œë°± ë‚´ìš©ì´ ì§¤ë¦°ë‹¤ã… ã… 

---

### ë¬¸ì œ

<p align="center">
<img src="https://resv2.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/41ceb31e-d254-ba0f-c4aa-293f7bf054ec/LuFwOFT9zuA5hpXgtzxoQacNuFnPhtCCUOraKRzeqygz/Image.png" alt ="Image.png"/>
</p>

- í”¼ë“œë°± ìƒì„± ê²°ê³¼ì— í”„ë¡¬í”„íŠ¸ê¹Œì§€ í•¨ê»˜ ì¶œë ¥ë˜ëŠ” ë¬¸ì œëŠ”, ëª¨ë¸ì˜ ì¶œë ¥ì—ì„œ í”„ë¡¬í”„íŠ¸ì™€ ìƒì„±ëœ ë‹µë³€ì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆê¸° ë•Œë¬¸

```python
full_feedback = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
```

### í•´ê²°

1. í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ë§Œí¼ì„ ì˜ë¼ë‚´ê³ , ê·¸ ì´í›„ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ
    - í”„ë¡¬í”„íŠ¸ì˜ í† í° ê¸¸ì´ë¥¼ êµ¬í•œë‹¤
    - ëª¨ë¸ ì¶œë ¥ì˜ í† í° ì‹œí€€ìŠ¤ì—ì„œ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì´í›„ì˜ í† í°ë§Œ ë””ì½”ë”©
    - ì•„ë˜ëŠ” ìˆ˜ì • ì½”ë“œì´ë‹¤

```python
try:
    # Mistral ëª¨ë¸ì„ í†µí•œ í”¼ë“œë°± ìƒì„±
    inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)
    prompt_length = inputs["input_ids"].shape[1]  # í”„ë¡¬í”„íŠ¸ í† í° ê¸¸ì´
    outputs = self.model.generate(
        **inputs,
        max_new_tokens=self.max_tokens,
        temperature=0.7,
        do_sample=True,
        pad_token_id=self.tokenizer.eos_token_id
    )
    # ìƒì„±ëœ ì „ì²´ ì‹œí€€ìŠ¤ì—ì„œ í”„ë¡¬í”„íŠ¸ ì´í›„ ë¶€ë¶„ë§Œ ë””ì½”ë”©
    generated_ids = outputs[0][prompt_length:]
    full_feedback = self.tokenizer.decode(generated_ids, skip_special_tokens=True)
```

- `skip_special_tokens` ì€ ë””ì½”ë”© ìŠ¤í‚µ ì²˜ë¦¬ (<s>, </s>, <pad>, <unk> ë“±)

# ê·¼ë° ì–´ë–»ê²Œ í”„ë¡¬í”„íŠ¸ì˜ í† í° ê¸¸ì´ë¥¼ ì•Œ ìˆ˜ ìˆëŠ”ê±¸ê¹Œ?

- `prompt_length = inputs["input_ids"].shape[1]`
- í”„ë¡¬í”„íŠ¸ë¥¼ í† í¬ë‚˜ì´ì €ì— ë„£ìœ¼ë©´

```python
inputs = self.tokenizer(prompt, return_tensors="pt")
```

- `inputs[â€œinput_idsâ€]` ëŠ” í”„ë¡¬í”„íŠ¸ ì „ì²´ë¥¼ í† í°í™”í•œ ê²°ê³¼
- `Ã¬nputs[â€œinput_idsâ€]` ì˜ shape
  - ì´ ê°’ì€ shapeê°€ (batch_size, sequence_length) ì´ë‹¤
    - batch_size: í•œ ë²ˆì— ëª‡ ê°œì˜ ë¬¸ì¥ì„ í† í°í™” í•˜ëŠ”ì§€
    - sequence_length: í”„ë¡¬í”„íŠ¸ì˜ í† í° ê°œìˆ˜
  - ê·¸ë˜ì„œ `inputs["input_ids"].shape[1]` ìš”ê²Œ í”„ë¡¬í”„íŠ¸ì˜ í† í° ê°œìˆ˜ë‹¤ ì´ ë§ì”€

### `generated_ids = outputs[0][prompt_length:]` ì´ê±´ ë­˜ê¹Œ?

- ì—¬ê¸°ì„œ outputsëŠ” í† ì¹˜(Torch) í…ì„œ ë˜ëŠ” ë„˜íŒŒì´ ë°°ì—´ í˜•íƒœë¡œ ë³€í™˜ ëœë‹¤.
  - ì¼ë°˜ì ìœ¼ë¡œ outputsì˜ shapeì€: (batch_size, ì „ì²´ ì‹œí€€ìŠ¤(í† í°) ê¸¸ì´)
- â€œoutputs[0]â€ ì˜ ì˜ë¯¸?
  - ë°°ì¹˜ì—ì„œ ì²«ë²ˆì§¸ ìƒ˜í”Œì˜ í† í° ì‹œí€€ìŠ¤ë¥¼ ì˜ë¯¸
  - ì¦‰, outpust[0]ì€ -> [í”„ë¡¬í”„íŠ¸ í† í°ë“¤... , ìƒì„±ëœ í† í°ë“¤...] ì´ê³ ,  `outputs[0][prompt_length:]` ->ìƒì„±ëœ í† í°ë“¤ë§Œ ìŠ¬ë¼ì´ì‹±

### í”„ë¡¬í”„íŒ… ìˆ˜ì •

```python
self.prompt_template = os.getenv("FEEDBACK_PROMPT_TEMPLATE",
        """
        ë‹¤ìŒ {personal_challenges}ì™€ {group_challenges} ê¸°ë¡ì„ í†µí•©í•˜ì—¬ ìš”ì•½í•˜ê³ , ì‚¬ìš©ìì˜ ë…¸ë ¥ì„ ì¸ì •í•˜ê³  ê²©ë ¤í•˜ëŠ” í”¼ë“œë°±ì„ í•œê¸€ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.
        ì‹¤íŒ¨í•œ ì±Œë¦°ì§€ì— ëŒ€í•´ì„œëŠ” ìœ„ë¡œì™€ í•¨ê»˜ ë‹¤ìŒ ê¸°íšŒë¥¼ ê¸°ëŒ€í•œë‹¤ëŠ” ë©”ì‹œì§€ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
        ìœ ë‹ˆì½”ë“œ(Unicode) í‘œì¤€ì— í¬í•¨ëœ ì´ëª¨ì§€(ì˜ˆ: ğŸ˜Š, ğŸŒ±, ğŸ‰ ë“±)ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼í•˜ê³  ë°ì€ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        ê°™ì€ ì˜ë¯¸ì˜ ë¬¸ì¥ì„ ë°˜ë³µí•˜ì§€ ë§ê³ , êµ¬ì²´ì ì´ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        ë¬¸ì¥ì´ ì¤‘ê°„ì— ëŠê¸°ì§€ ì•Šê²Œ ì™„ê²°ëœ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        ì „ì²´ ë‹µë³€ì€ í•œê¸€ ê¸°ì¤€ 250ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”.

        ê°œì¸ ì±Œë¦°ì§€:
        {personal_challenges}

        ë‹¨ì²´ ì±Œë¦°ì§€:
        {group_challenges}
        """)
```

- `self.max_tokens` ê°’ì„ 200 -> 250ìœ¼ë¡œ ì¦ê°€
  - ë‹µë³€ì´ ì¤‘ê°„ì— ì§¤ë¦¬ëŠ” í˜„ìƒ ë°©ì§€ ëª©ì 