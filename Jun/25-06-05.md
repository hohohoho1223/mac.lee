# 오늘 내가 배운 것들(Today I Learned)

- prod에 올린 모델에서 오류가 발생했다는 팀원의 피드백이 있었다.
- 아마 내가 직접 파일 수정하다가 오류가 발생한 모양이다.
- main(prod)에 PR했는데 아래와 같이 /base-info호출이 오류가 났다.

---

![Image.png](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/96869268-242d-9663-9edb-8c6e0c9370a5/e3omJpsjvgxE6ugDovr7yux4ydxsNx0RyyuTF6xkfUoz/Image.png)

- 코드를 본 결과, 아래와 같은 오류가 있었다.

# LLM_chatbot_base_info_model.py의 응답 형식 문제 설명

## 문제 상황

- `get_llm_response` 함수가 `JSONResponse`를 직접 반환하고 있었다.

## 현재 코드의 문제점

```python
def get_llm_response(prompt):
    try:
        # ... LLM 호출 및 파싱 로직 ...
        return JSONResponse(  # 문제가 되는 부분
            status_code=200,
            content={
                "status": 200,
                "message": "성공!",
                "data": parsed
            }
        )
```

이 구현의 문제점:

1. **계층 구조 위반**:
    - 모델 레이어(`model/`)가 HTTP 응답 형식(`JSONResponse`)을 직접 반환
    - 이는 관심사 분리(Separation of Concerns) 원칙 위반
1. **중복 응답 래핑**:
    - 라우터에서 이미 `JSONResponse`로 감싸서 반환
    - 모델에서도 `JSONResponse`로 감싸면 이중으로 래핑됨

## 올바른 구현

```python
def get_llm_response(prompt):
    try:
        # ... LLM 호출 및 파싱 로직 ...
        return parsed  # 파싱된 데이터만 반환
```

이렇게 수정하면:

1. **관심사 분리**:
    - 모델 레이어는 순수하게 데이터 처리만 담당
    - HTTP 응답 형식은 라우터 레이어에서 처리
1. **일관된 응답 구조**:
    - 라우터에서 한 번만 `JSONResponse`로 감싸서 반환
    - 응답 형식이 일관되게 유지됨

## 실제 동작 예시

```python
# router/chatbot_router.py
@router.post("/ai/chatbot/recommendation/base-info")
def select_category(req: CategoryRequest):
    # ... 검증 로직 ...
    try:
        parsed = get_llm_response(prompt)  # 모델에서 파싱된 데이터만 받음
        return JSONResponse(  # 라우터에서 HTTP 응답 형식으로 변환
            status_code=200,
            content={
                "status": 200,
                "message": "사용자 기본 정보 키워드 선택을 기반으로 챌린지를 추천합니다.",
                "data": {
                    "recommend": parsed.get("recommend", ""),
                    "challenges": [...]
                }
            }
        )
```

- 이렇게 수정하였다.