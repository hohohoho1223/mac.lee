# 오늘 내가 배운 것들(Today I Learned)

- V2 배포 및 리펙토링 기간이다.
- 근데 v2 출시가 늦었다..ㅎㅎ
- 팀원들과 협업하다보니 배포가 늦어진 것 같다(난 괜찮아)

- 그래서 SSE 작업을 이어서 했다.(SSE_통신작업_5)

---

- 모델 로드하려고 서버를 켰는데, 아래와 같이 에러가 떴다.
- 엥 공간부족?

![Image.png](https://resv2.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/BF26F62E-3193-418E-A027-F2F8B5A4036D_2/HZJiO7CdamNTzxbxxTLnCeMQEE1bFjaWZOYP4A5sIaoz/Image.png)

- `df -h` 명령어로 확인해보자

![Image.png](https://resv2.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/8C22AEAE-8C03-48B1-AF85-92712FDA6657_2/Qn20h2kTEy0doE1O2paHHtBAAhti7cdYI1DifPxlIJEz/Image.png)

- “tmp” 메모리가 꽉차 있었다(100%사용)
- `rm -rf ~/.cache/* && rm -rf /tmp/ubuntu/* 2>/dev/null || true` 명령어로 임시 파일들을 정리

![Image.png](https://resv2.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/40408A4C-3236-4CB8-B3D6-C8C11E92AE48_2/3YH8Dywg3xz5ZZHH4Y02QDroCU2Uf0sPchDbR3lJnigz/Image.png)

- 싹 사라졌다.

### 1. /tmp 디스크에 뭐가 있었나?

- /tmp는 리눅스 시스템에서 임시 파일을 저장하는 공간입니다.
- Python, PyTorch, transformers, Hugging Face, FastAPI 등 다양한 프로그램이 임시 파일, 캐시, 언패킹 파일, 소켓, lock 파일 등을 여기에 저장합니다.
- 특히 대용량 모델을 로드할 때, 모델 파일을 임시로 압축 해제하거나, 캐시 파일을 만들거나, 메모리가 부족할 때 일부 데이터를 임시로 저장할 수 있습니다.
- 서버가 오래 켜져 있거나, 여러 번 모델을 로드/언로드 하다 보면 /tmp에 임시 파일이 쌓여서 공간을 다 쓸 수 있습니다.

### 2. 모델 로드 시 /tmp가 필요한가?

- 네, 필요할 수 있습니다.
- Hugging Face의 from_pretrained 함수는 모델 파일을 다운로드하거나 압축 해제할 때 /tmp를 임시 저장소로 사용합니다.
- PyTorch도 텐서 임시 저장, 체크포인트 언패킹, offload 등에서 /tmp를 활용할 수 있습니다.
- 특히 offload_folder="offload" 같은 옵션을 쓸 때, offload 폴더가 /tmp 아래에 위치하면 더 많은 임시 공간이 필요합니다.
- 만약 /tmp가 가득 차 있으면, 모델 로드/추론/캐시 생성이 실패할 수 있습니다.

### 3. 실무 팁

- 주기적으로 /tmp를 정리해주는 것이 좋습니다.
- 대용량 모델을 자주 다루는 서버라면 /tmp의 용량을 넉넉하게 잡거나, 별도의 임시 디렉토리를 지정하는 것도 방법입니다.
- 모델 로드 시 cache_dir나 offload_folder를 /tmp가 아닌, 용량이 넉넉한 디렉토리로 지정할 수도 있습니다.

---

## 스트리머 설정

```python
streamer = TextIteratorStreamer(
        tokenizer, # 토큰을 텍스트로 변환하는 데 사용할 토크나이저
        skip_prompt=True, # skip_prompt: True로 설정하면 입력 프롬프트는 스트리밍에서 제외하고 모델의 응답만 스트리밍
        timeout=None,  # timeout: None으로 설정하여 무한정 대기 (응답이 늦어도 연결 유지)
        decode_kwargs={ # decode_kwargs: 토큰을 텍스트로 변환할 때 사용할 추가 옵션
            "skip_special_tokens": True, # True로 설정하여 [PAD], [CLS] 등의 특수 토큰을 제외
            "clean_up_tokenization_spaces": True # 토큰화 공백 정리
        }
    )
```

- 특수 토큰 [PAD]&[CLS]란?
- 특수 토큰(Special Tokens)은 텍스트 처리 과정에서 특별한 목적으로 사용되는 토큰들입니다. 주요 특수 토큰들을 설명하면:
    1. [PAD] (Padding Token)
        - 배치 처리 시 모든 문장을 같은 길이로 맞추기 위해 사용
        - 예: "안녕하세요"와 "반갑습니다"를 같은 길이로 만들 때 짧은 문장 뒤에 [PAD]를 추가
    2. [CLS] (Classification Token)
        - 문장의 시작을 나타내는 토큰
        - 주로 분류 작업에서 문장의 전체 의미를 파악하는데 사용
        - 예: "[CLS] 안녕하세요 반갑습니다"
    3. [SEP] (Separator Token)
        - 두 문장을 구분하는 토큰
        - 예: "첫 번째 문장 [SEP] 두 번째 문장"
    4. [UNK] (Unknown Token)
        - 모델이 알 수 없는 단어나 토큰을 만났을 때 사용
        - 예: "안녕하세요 [UNK] 반갑습니다" (중간에 모르는 단어가 있을 때)
    5. [MASK] (Mask Token)
        - 마스킹된 단어를 예측하는 작업에서 사용
        - 예: "안녕하세요 [MASK] 반갑습니다" (중간 단어를 예측하는 작업)
- 이러한 특수 토큰들은 모델의 학습과 추론 과정에서 중요한 역할을 하지만, 최종 사용자에게는 보여줄 필요가 없다. 그래서 `skip_special_tokens=True`로 설정하여 이 토큰들을 제외하고 실제 의미 있는 텍스트만 전달

---

- FastAPI 서버에서 SSE 스트리밍 응답 처리 중 `RuntimeError: Unexpected ASGI message 'http.response.body' sent, after response already completed` 에러 발생

![Image.png](https://resv2.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/AC7BB962-FB44-4CC3-8226-624949488444_2/LyycY5qleNnYHEhaX4XQNTxO9SwLE10s9kPmPUYuIgEz/Image.png)

- 모델의 응답은 정상적으로 생성되고 파싱되었으나, 클라이언트로 전송하는 과정에서 문제 발생

### 원인 분석

- SSE 스트리밍이 완전히 종료되기 전에 연결이 끊어짐
- 응답이 이미 완료된 상태에서 추가 응답을 보내려고 시도
- 이는 주로 다음과 같은 상황에서 발생:
  1. 클라이언트가 연결을 일찍 종료
  2. 네트워크 연결 불안정
  3. 서버의 응답 처리 로직이 비정상적으로 종료

### 해결 과정

1. SSE 스트리밍 응답 처리 로직 검토
2. 응답 완료 시점 명확히 지정
3. 예외 처리 강화

### 실무 팁

- SSE 스트리밍 사용 시 클라이언트와 서버 간의 연결 상태 모니터링
- 응답 완료 시점을 명확히 하고, 불필요한 추가 응답 방지
- 네트워크 연결 불안정 상황에 대한 예외 처리 구현
- 클라이언트 측에서도 연결 종료 시점 적절히 처리