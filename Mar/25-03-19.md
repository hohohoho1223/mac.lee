# 오늘 내가 배운 것들(Today I Learned)

- DataBase_Index 수업 및 개인과제2를 시작하였다.

---

- 인덱스에는 클러스터형 인덱스와 비클러스터형 인덱스가 존재한다.

    - 클러스터 : 데이터가 인덱스 순서대로 **물리적으로 정렬되어 저장되는 인덱스**
    - 비클러스터형 : 인덱스와 데이터가 **물리적으**로 분리되어 있음 -> 해당 테이블에는 원본 데이터의 위치를 가리키는 포인터만 포함되어있는 인덱스

- 비클러스터형 인덱스의 동작 방식 

| **id** | **이름** | **핸드폰 번호**    | **주소**   |
| ------ | ------ | ------------- | -------- |
| 1      | 연시완    | 010-1234-5678 | 서울시 동대문구 |
| 2      | 유태봉    | 010-2345-6789 | 서울시 강남구  |
| 3      | 홍길동    | 010-3456-7890 | 서울시 양천구  |
| 4      | 김철수    | 010-4567-8901 | 서울시 성북구  |
| 5      | 박영희    | 010-5678-9012 | 제주시 제주로  |
| 6      | 이순신    | 010-6789-0123 | 익산시 영동로  |
| 7      | 정일호    | 010-7890-1234 | 부산시 해운대로 |

- 인덱스가 `이름` 과 `핸드폰 번호` 조합으로 구성되어 있으며, 이 두 컬럼의 값을 기준으로 별도의 인덱스 페이지가 생성됨
- 인덱스 페이지는 실제 데이터가 아닌 원본 데이터의 위치를 가리키는 포인터 정보만 포함하여 빠르게 조회가 가능
- 카디널리티란?
    - 데이터베이스 테이블의 열(컬럼)에서 데이터 값의 고유성을 나타내는 지표이다. -> 컬럼당 고유한 값의 개수

| **ID** | **Name** | **Location** |
| ------ | -------- | ------------ |
| 0      | void     | 서울           |
| 1      | wayne    | 부산           |
| 2      | joey     | 서울           |
| 3      | wayne    | 서울           |
| 4      | yaro     | 서울           |
| 5      | claire   | 인천           |
| 6      | warden   | 서울           |
| 7      | void     | 서울           |
| 8      | void     | 서울           |
| 9      | yaro     | 서울           |

-  Name의 고유값(Name's Cardinality) : 6개
- Location의 고유값(Location's Cardinality) : 3개

---

## 개인과제_2 시작

- 데이터셋 링크 : https://www.kaggle.com/datasets/hafiznouman786/potato-plant-diseases-data/data

- 3개의 클래스가 존재함
    1. **Potato___Early_blight** (감자의 초기 잎마름병)
    2. **Potato___Late_blight** (감자의 후기 잎마름병)
    3. **Potato___healthy** (건강한 감자 잎)

- 말만 다르지 **초기와 후기는 완전히 다른 질병이다!!!**
    -  초기역병
        - 잎에 **동그란 갈색 반점**(표적 모양)이 생기며 점차 확대.
        - 감자의 잎과 줄기가 말라 죽지만, 전염 속도는 상대적으로 느림
    - 후기역병
        - 잎과 줄기에 **불규칙한 갈색 반점** 이 생기며 빠르게 퍼짐.
        - 감자의 덩이줄기(괴경)까지 감염되어 **썩어버리는 피해** 발생.
        - 심한 경우 작물 전체가 며칠 만에 고사할 수도 있음.

- 초기 역병은 어느정도 대처가 가능함(잎 제거 & 식물 면역력 증가)
- 후기 역병은 재앙 그자체임.(1840년대 아일랜드 대기근의 원인)
    -> 초기와 후기 역병을 분별하여 대기근을 막자!

- 내가 생각한 학습 흐름도

    > 학습데이터를 가지고 가중치 학습 하기 or 이미 가중치 모델이 있는 ResNet 이나 VGG16 사용하기

    - 근데 내가 가지고 있는 데이터 이미지는 몇천장 뿐이라서 학습능력이 낮게 나올 수 있음(과적합이 나올수 있다는 얘기)
    - 그래서 `전이 학습` 방식으로 기존 ResNet의 특징추출 Layer + Fully Connected Layer부분만 학습하여 모델링 함
    - **데이터가 적을 때 CNN을 처음부터 학습하면 오버피팅 가능성이 높아** → 사전 학습된 모델을 활용하는 것이 효과적

| **방식**      | **CNN을 처음부터 학습** | **ResNet 특징 추출기 + FCL** |
| ----------- | ---------------- | ----------------------- |
| **데이터 요구량** | 많아야 함            | 적어도 가능                  |
| **학습 속도**   | 느림               | 빠름                      |
| **오버피팅 위험** | 높음               | 낮음                      |
| **성능**      | 데이터가 많아야 좋음      | 적은 데이터에서도 우수            |

- ResNet의 초기 컨볼루션 및 풀링 계층은 **텍스처, 모양, 패턴 등 기초적인 시각적 특징을 추출**하는 데 강점이 있음
- ResNet의 상위 계층(마지막 Fully Connected Layer)만 새롭게 학습하면 **적은 데이터로도 강력한 성능을 낼 수 있음**
- 그럼 ResNet VS VGG16 중에 어떤게 나을까?

    > 나는 기본적으로 ResNet 은 50층, VGG16은 16층이어서 작은 데이터 셋에선 VGG16 이 더 나을것이라고 생각했다.

    - 하지만 ResNet이 깊지만 작은 데이터에서도 나을 수 있음!
        - ResNet의 `잔차연결` 이 깊은 네트워크 문제를 해결함
        - VGG16은 16개 층이지만, 단순한 `3X3 Conv`  와 MaxPooling을 반복하는 구조이다
        - 원래 깊으면 `기울기 소실 문제` 로 학습이 잘 안되지만, 이러한 `잔차연결`은 깊어도 학습이 잘됨!
    -  ResNet은 더 깊은 계층에서 더욱 추상적인 특징을 학습할 수 있음: 감자 입 병해 진단은 복잡한 패턴이므로 `수준이 깊은 패턴` 을 학습하자! 
        -> 대상이 뭐냐에 따라 모델이 달라지는듯

- 그럼 VGG 16은 도대체 언제씀? 
    1.  계산량이 적어야할때 (모바일, 임베디드)
    2. 사전 학습된 모델(Feature Extractor)을 그대로 사용할때
    3. 이미지 특징이 단순한 경우 (예 : MNIST 같은 손글씨 인식)
    - 됐고 일단 두개다 해보자! 

---

- 그럼 ResNet 을 사용하기위해 이미지 파일 전처리 작업을 해야한다.

```python
import os
import torch
from torchvision import transforms, datasets
from torch.utils.data import DataLoader

# ✅ 데이터셋 경로 설정
DATASET_PATH = "/content/drive/MyDrive/Colab_Notebooks/[카카오 부트캠프]/Split_PlantVillage"

# ✅ 데이터 변환 설정 (ResNet 학습에 맞게 최적화)
transform = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),  # 🔥 다양한 크기에서 랜덤하게 잘라서 학습 (강력한 데이터 증강)
        transforms.RandomHorizontalFlip(),  # 🔥 좌우 반전 (일반적인 증강)
        transforms.RandomRotation(10),      # 🔥 최대 10도 회전
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),         # 🔥 검증 데이터는 크기를 256으로 맞추고,
        transforms.CenterCrop(224),     # 🔥 중앙 224x224 크기로 자름 (훈련 데이터와 일관성 유지)
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
}

# ✅ 데이터셋 로드 (ImageFolder 사용)
train_dataset = datasets.ImageFolder(root=os.path.join(DATASET_PATH, "train"), transform=transform['train'])
val_dataset = datasets.ImageFolder(root=os.path.join(DATASET_PATH, "val"), transform=transform['val'])
test_dataset = datasets.ImageFolder(root=os.path.join(DATASET_PATH, "test"), transform=transform['test'])

# ✅ 데이터 로더 생성
BATCH_SIZE = 32
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)  # 검증은 일반적으로 shuffle X
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)  # 테스트 데이터는 순서 고정

# ✅ 클래스 개수 확인
num_classes = len(train_dataset.classes)
print(f"✅ 클래스 개수: {num_classes}, 클래스 목록: {train_dataset.classes}")
```

-  위 코드는 수정 후 코드이다.
- 왜 수정했을까?

| **항목**            | **기존 코드**                                    | **수정 후**                                                 |
| ----------------- | -------------------------------------------- | -------------------------------------------------------- |
| **훈련 데이터 변환**     | Resize(224,224) → **모든 이미지가 똑같이 변형됨 (단조로움)** | RandomResizedCrop(224) → **다양한 크기로 변형 가능 (일반화 성능 증가)**   |
| **검증/테스트 변환**     | Resize(224,224)                              | Resize(256) → CenterCrop(224) **(훈련과 일관성 유지, 자연스러운 보정)** |
| **데이터 로더 속도 최적화** | num_workers=0                                | num_workers=2 (데이터 로드 속도 증가)                             |
| **shuffle 설정**    | shuffle=True (모든 데이터)                        | train만 shuffle=True, val/test는 shuffle=False             |

1.  `Resize(22,224)` 는 모든 이미지를 같은 크기로 강제 변환기에 비율이 달라질 수 있음

    \- `Resize(256)` 후 `CenterCrop(224)` 를 사용하면 **이미즈이 원본 비율을 유지하면서 훈련데이터와 일관성을 맞출수** 있다

2.  훈련데이터만 섞고 검증/ 테스트는 순서 유지
    -  검증(val)과 테스트(text) 에서는 결과의 일관성을 위해

    >>>> 여기서 문득 `RandomResizedCrop(224)` 와 `Padding + Pooling` 의 적용이 어떻게 다른지 궁금해졌다.

    - 두 방법의 차이점 

| **비교 요소**  | **RandomResizedCrop(224)** | **Padding + Pooling** |
| ---------- | -------------------------- | --------------------- |
| **목적**     | 데이터 증강, 다양한 크기 학습          | 다운샘플링, 연산량 감소         |
| **특징**     | 랜덤 크롭으로 다양한 시각 정보 제공       | 고정된 영역 내에서 중요한 특징만 유지 |
| **과적합 방지** | ✅ 가능 (다양한 변형 제공)           | ❌ 제한적 (오히려 정형화됨)      |
| **연산량**    | ❌ 증가 (여러 크기 변환 필요)         | ✅ 감소 (특징 압축)          |

- `RandomResizedCrop` : 데이터 증강을 위해 사용
- `Padding + Pooling` : 특징 압축 & 연산량 줄이기

---

- 데이터 증강
    - 데이터 증강은 **훈련 데이터가 적거나, 모델이 특정 패턴에 과적합(Overfitting)할 위험이 있을 때 필수적으로 사용해야 함.**

        1.  **데이터가 적은 경우** (3,000장 이하) → 필수

        2.  **이미지의 변형이 많은 경우 (다양한 각도, 조명, 크기)** → 필수

        3.  **오버피팅 위험이 높은 경우 (Train 성능만 좋고, Test 성능 낮음)** → 필수

        4.  **특정 클래스의 데이터가 적을 경우 (데이터 불균형)** → 필수

    - 테스트/검증 데이터에는 **절대 적용하면 안됨!**
        -  평가의 일관성이 깨짐 & 성능이 과대평가 될수 있음
    -  얼리스탑 기준
        - val_loss가 patience 횟수 동안 개선되지 않으면 학습 중단
        - patience: 몇 번의 에포크 동안 개선이 없을 때 학습을 중단할 것인지 결정하는 값 (보통 3~10 정도)
        - min_delta: 최소한의 개선 폭 (예: 0.001 이하로 개선되지 않으면 중단)