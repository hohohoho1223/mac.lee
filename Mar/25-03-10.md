# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 6주차 과제를 진행했다.

---

- VGG16 전이모델 코드중

    ```py
    # 라이브러리 임포트
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    import numpy as np
    from torchvision import models
    
    #가상 데이터셋 생성
    num_classes = 10
    input_shape = (3, 224, 224)
    
    # 가상 이미지 데이터 생성
    x_train = np.random.random((1000, 3, 224, 224)).astype(np.float32)
    y_train = np.random.randint(num_classes, size=(1000,))
    
    x_test = np.random.random((200, 3, 224, 224)).astype(np.float32)
    y_test = np.random.randint(num_classes, size=(200,))
    
    # 데이터셋 및 데이터 로더 생성
    train_dataset = TensorDataset(torch.tensor(x_train), torch.tensor(y_train))
    test_dataset = TensorDataset(torch.tensor(x_test), torch.tensor(y_test))
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    #사전 훈련된 VGG16 모델 로드
    base_model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1) # ImageNet 데이터셋에서 학습한 가중치를 사용
    base_model.classifier = nn.Sequential(*list(base_model.classifier.children())[:-1]) # 마지막 출력 레이어 제거 ->기존의 Feature Extractor 부분은 유지
    
    #새로운 FC모델 구축
    class CustomVGG16(nn.Module):
        def __init__(self, num_classes):
            super(CustomVGG16, self).__init__()
            self.base_model = base_model
            self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))
            self.fc1 = nn.Linear(512, 256)
            self.relu = nn.ReLU()
            self.fc2 = nn.Linear(256, num_classes)
            self.softmax = nn.Softmax(dim=1)
    
        def forward(self, x):
            x = self.base_model.features(x) # 기존의 VGG16 CNN 계층 사용
            x = self.global_avg_pool(x)
            x = torch.flatten(x, 1)
            x = self.fc1(x)
            x = self.relu(x)
            x = self.fc2(x)
            x = self.softmax(x)
            return x
    
    model = CustomVGG16(num_classes=num_classes)
    
    #모델 컴파일
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    #모델 훈련
    num_epochs = 10
    
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')
    
    #모델 평가
    model.eval()
    correct=0
    total =0
    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    accuracy = correct / total
    print(f'Test 정확도: {accuracy*100:.2f}%')
    ```

    - 여기서 `base_model.classifier = nn.Sequential(*list(base_model.classifier.children())[:-1])` 이부분에서 마지막 Fully Connected 층을 삭제한다

    > 	Q. VGG16층의 마지막 FC 3개층 전체가 날라가는건가? 싶어서 물어봤다.

    > 	A. VGG16의 원래 classifier부분 (FC layer)은 다음과 같다


    ```py
    classifier = nn.Sequential(
        nn.Linear(25088, 4096),
        nn.ReLU(inplace=True),
        nn.Dropout(),
        nn.Linear(4096, 4096),
        nn.ReLU(inplace=True),
        nn.Dropout(),
        nn.Linear(4096, 1000),  # 최종 출력층 (ImageNet 클래스 개수 = 1000)
    )
    ```

    > 여기서 마지막층 Linear(4096,1000) 층이 1000개의 클래스 분류를 위한 층인데, 해당 층을 삭제한다는 뜻이다. 

    > Q. 그럼 4096(기존층) 그다음 바로 내가 모델링 한 512 → 256 → num_classes 순으로 흘러가는건가?

    > A. 아니다! 모델 코드대로 바로 512->256→ num_classes순으로 진행된다!

    > Q. 엥? 근데 평탄화로 1차원 배열 수준인 4096 차원이 어떻게 바로 256으로 이어질수가 있는거지?

    - A. `self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))`  때문에 원래 VGG16에서 사용하던 4096차원이 아니라 512 차원으로 줄어든것임!

- ResNet과 VGG16의 학습 과정을 각각 실행한 뒤, 모델 비교(Model Comparison) 실험을 진행해보세요.

    ```python
    # 라이브러리 임포트
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    import numpy as np
    from torchvision import models
    
    # 가상 데이터 셋 생성
    num_classes = 10
    input_shape = (3, 32, 32)
    
    # 가상 이미지 데이터 생성
    x = np.random.random((1200, 3, 32, 32)).astype(np.float32)
    y = np.random.randint(num_classes, size=(1200,))
    
    # 데이터셋 및 데이터 로더 생성
    x_train, x_test = torch.tensor(x[:960]), torch.tensor(x[960:])
    y_train, y_test = torch.tensor(y[:960]), torch.tensor(y[960:])
    
    train_dataset = TensorDataset(x_train, y_train)
    test_dataset = TensorDataset(x_test, y_test)
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    # ResNet18 모델 불러오기 및 수정
    resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
    resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)  # 최종 출력층 변경
    
    # VGG16 모델 불러오기 및 수정
    vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)
    vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, num_classes)  # 최종 출력층 변경
    
    # Feature Extractor 부분 고정 (Fine-Tuning)
    for param in resnet.parameters():
        param.requires_grad = False
    for param in resnet.fc.parameters():
        param.requires_grad = True  # FC Layer만 학습
    
    for param in vgg16.features.parameters():
        param.requires_grad = False
    for param in vgg16.classifier[6].parameters():
        param.requires_grad = True  # FC Layer만 학습
    
    # 모델 학습 함수
    def train_model(model, optimizer, num_epochs=10):
        criterion = nn.CrossEntropyLoss()
        history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}
    
        for epoch in range(num_epochs):
            model.train()
            running_loss = 0.0
            correct = 0
            total = 0
    
            for inputs, labels in train_loader:
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                running_loss += loss.item()
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
    
            train_loss = running_loss / len(train_loader)
            train_accuracy = correct / total
    
            model.eval()
            val_loss = 0.0
            val_correct = 0
            val_total = 0
    
            with torch.no_grad():
                for inputs, labels in test_loader:
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    val_loss += loss.item()
                    _, predicted = torch.max(outputs, 1)
                    val_total += labels.size(0)
                    val_correct += (predicted == labels).sum().item()
    
            val_loss /= len(test_loader)
            val_accuracy = val_correct / val_total
    
            history['loss'].append(train_loss)
            history['val_loss'].append(val_loss)
            history['accuracy'].append(train_accuracy)
            history['val_accuracy'].append(val_accuracy)
    
            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, '
                  f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')
        
        return history
    
    # 옵티마이저 설정
    optimizer_resnet = optim.Adam(resnet.fc.parameters(), lr=0.0001)
    optimizer_vgg16 = optim.Adam(vgg16.classifier[6].parameters(), lr=0.0001)
    
    # ResNet18 훈련
    print("\n🔹 Training ResNet18...")
    history_resnet = train_model(resnet, optimizer_resnet)
    
    # VGG16 훈련
    print("\n🔹 Training VGG16...")
    history_vgg16 = train_model(vgg16, optimizer_vgg16)
    
    # 모델 평가 함수
    def evaluate_model(model):
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in test_loader:
                outputs = model(inputs)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        accuracy = correct / total
        print(f'Test Accuracy: {accuracy * 100:.2f}%')
        return accuracy
    
    # 모델 성능 평가
    print("\n🔹 Evaluating ResNet18...")
    accuracy_resnet = evaluate_model(resnet)
    
    print("\n🔹 Evaluating VGG16...")
    accuracy_vgg16 = evaluate_model(vgg16)
    
    # 결과 비교
    print("\n🔹 Model Comparison")
    print(f"ResNet18 Test Accuracy: {accuracy_resnet:.4f}")
    print(f"VGG16 Test Accuracy: {accuracy_vgg16:.4f}")
    
    if accuracy_resnet > accuracy_vgg16:
        print("✅ ResNet18 performs better!")
    else:
        print("✅ VGG16 performs better!")
    ```

    - 결과

    ```python
    🔹 Training ResNet18...
    Epoch 1/10, Loss: 2.5669, Accuracy: 0.0917, Val Loss: 2.3681, Val Accuracy: 0.1167
    Epoch 2/10, Loss: 2.5057, Accuracy: 0.1115, Val Loss: 2.5403, Val Accuracy: 0.1125
    Epoch 3/10, Loss: 2.4725, Accuracy: 0.1021, Val Loss: 2.5761, Val Accuracy: 0.1042
    Epoch 4/10, Loss: 2.4658, Accuracy: 0.1125, Val Loss: 2.5738, Val Accuracy: 0.1167
    Epoch 5/10, Loss: 2.4497, Accuracy: 0.1115, Val Loss: 2.5610, Val Accuracy: 0.1042
    Epoch 6/10, Loss: 2.4120, Accuracy: 0.1135, Val Loss: 2.5288, Val Accuracy: 0.1167
    Epoch 7/10, Loss: 2.4244, Accuracy: 0.1104, Val Loss: 2.5633, Val Accuracy: 0.1083
    Epoch 8/10, Loss: 2.3651, Accuracy: 0.1354, Val Loss: 2.5572, Val Accuracy: 0.0875
    Epoch 9/10, Loss: 2.4038, Accuracy: 0.1135, Val Loss: 2.5494, Val Accuracy: 0.1083
    Epoch 10/10, Loss: 2.3607, Accuracy: 0.1313, Val Loss: 2.5288, Val Accuracy: 0.0917
    
    🔹 Training VGG16...
    Epoch 1/10, Loss: 2.4737, Accuracy: 0.0990, Val Loss: 2.2858, Val Accuracy: 0.1375
    Epoch 2/10, Loss: 2.4471, Accuracy: 0.0969, Val Loss: 2.2872, Val Accuracy: 0.1208
    Epoch 3/10, Loss: 2.4451, Accuracy: 0.1052, Val Loss: 2.2935, Val Accuracy: 0.0917
    Epoch 4/10, Loss: 2.4193, Accuracy: 0.1125, Val Loss: 2.3060, Val Accuracy: 0.0917
    Epoch 5/10, Loss: 2.3972, Accuracy: 0.1167, Val Loss: 2.2972, Val Accuracy: 0.1083
    Epoch 6/10, Loss: 2.3877, Accuracy: 0.1208, Val Loss: 2.2990, Val Accuracy: 0.1042
    Epoch 7/10, Loss: 2.3704, Accuracy: 0.1135, Val Loss: 2.3041, Val Accuracy: 0.0917
    Epoch 8/10, Loss: 2.3832, Accuracy: 0.1104, Val Loss: 2.3038, Val Accuracy: 0.1167
    Epoch 9/10, Loss: 2.3746, Accuracy: 0.1281, Val Loss: 2.3098, Val Accuracy: 0.1000
    Epoch 10/10, Loss: 2.3837, Accuracy: 0.1198, Val Loss: 2.3102, Val Accuracy: 0.0958
    
    🔹 Evaluating ResNet18...
    Test Accuracy: 9.17%
    
    🔹 Evaluating VGG16...
    Test Accuracy: 9.58%
    
    🔹 Model Comparison
    ResNet18 Test Accuracy: 0.0917
    VGG16 Test Accuracy: 0.0958
    ✅ VGG16 performs better!
    ```

    - 여기서 의문이 생겼다. VGG16은 16층인데 왜 50층인 ResNet보다 성능이 안좋게 나왔을까?

	A. VGG16 : 비교적 단순한 모델이며 작은 데이터셋에 더 적합함(1200개는 매우작음) 

	ResNet : 아주 깊은 네트워크라서 오버피팅이 되었을 확률이 높음 → 더 적은 층인 ResNet18 or ResNet34 사용 추천

    |                   | **VGG16**                | **ResNet50**           |
    | ----------------- | ------------------------ | ---------------------- |
    | **총 층 수**         | 16층 (얕음)                 | 50층 (깊음)               |
    | **모델 구조**         | 단순 CNN + FC              | Residual Block 사용      |
    | **작은 데이터셋에서 성능**  | 높음                       | 낮을 가능성 있음 (오버피팅)       |
    | **대규모 데이터셋에서 성능** | ResNet보다 낮음              | 높음                     |
    | **적합한 데이터**       | 작은 이미지 (CIFAR-10, MNIST) | 큰 이미지 (ImageNet, COCO) |


- **GridSearch vs. RandomSearch 차이**

    |            | **GridSearch**     | **RandomSearch**       |
    | ---------- | ------------------ | ---------------------- |
    | **탐색 방식**222  | 모든 조합 탐색           | 랜덤 조합 일부 탐색            |
    | **시간 소요**  | 오래 걸림 (조합 많을수록)    | 빠름                     |
    | **적합한 경우** | 작은 검색 공간에서 최적 해 탐색 | 큰 검색 공간에서 대략적인 최적 해 탐색 |


- GridSearch

    ```py
    # 라이브러리 임포트 및 데이터 준비
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn.utils import shuffle
    from tensorflow.keras.applications import ResNet50
    from tensorflow.keras.models import Model
    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
    from tensorflow.keras.optimizers import Adam
    
    # 가상의 데이터셋 생성 (CIFAR-10과 유사한 데이터셋)
    num_classes = 10
    input_shape = (32, 32, 3)
    num_samples = 1000
    
    X = np.random.rand(num_samples, *input_shape)  # 1000개의 32x32x3 이미지 생성
    y = np.random.randint(num_classes, size=num_samples)  # 0부터 9까지의 정수 레이블 생성
    
    # 데이터셋 셔플 및 분할
    X, y = shuffle(X, y)  # 데이터를 섞어줌
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% 훈련, 20% 테스트
    
    #모델 정의
    def create_model(learning_rate=0.001):
        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)
        x = base_model.output
        x = GlobalAveragePooling2D()(x)  # 글로벌 평균 풀링 레이어 추가
        x = Dense(1024, activation='relu')(x)  # 완전 연결 레이어 추가
        predictions = Dense(num_classes, activation='softmax')(x)  # 출력 레이어 추가
    
        model = Model(inputs=base_model.input, outputs=predictions)
        opt = Adam(learning_rate=learning_rate)  # Adam 옵티마이저 설정
    
        model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # 모델 컴파일
        return model
    
    # 모델 훈련 및 평가
    learning_rates = [0.001, 0.01, 0.1]
    batch_sizes = [16, 32, 64]
    epochs = 10
    
    best_accuracy = 0
    best_params = {}
    
    # 하이퍼파라미터 조합을 수동으로 설정하여 모델 학습 및 평가
    for lr in learning_rates:
        for batch_size in batch_sizes:
            model = create_model(learning_rate=lr)
            model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=1)
    
            loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
            print(f"Learning Rate: {lr}, Batch Size: {batch_size}, Test Accuracy: {accuracy}")
    
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_params = {'learning_rate': lr, 'batch_size': batch_size}
    
    print("Best Parameters:", best_params)
    print("Best Test Accuracy:", best_accuracy)
    
    #최적의 하이퍼파라미터로 모델 재학습 및 평가
    # 최적의 하이퍼파라미터로 모델 재학습
    epochs = 10
    best_model = create_model(learning_rate=best_params['learning_rate'])
    best_model.fit(X_train, y_train, epochs=epochs, batch_size=best_params['batch_size'], validation_split=0.2)
    
    # 테스트 데이터셋으로 모델 평가
    test_loss, test_accuracy = best_model.evaluate(X_test, y_test)
    print(f"Test Accuracy: {test_accuracy:.2f}")
    print(f"Test Loss: {test_loss:.2f}")
    ```

    - 시간이 굉장히 오래 걸렸다.(~~에라이~~)
    - 하지만 모든 조합인 경우를 다루므로 정확한 학습 정확도를 배출한다

---

- RandomSearch

    ```python
    # 라이브러리 임포트 및 데이터셋 생성
    import numpy as np
    import tensorflow as tf
    from tensorflow.keras.applications import ResNet50
    from tensorflow.keras.models import Model
    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
    from tensorflow.keras.optimizers import Adam
    from sklearn.model_selection import train_test_split, ParameterSampler
    from sklearn.utils import shuffle
    from scipy.stats import uniform
    
    # 가상의 데이터셋 생성 (CIFAR-10과 유사한 데이터셋)
    num_classes = 10
    input_shape = (32, 32, 3)
    num_samples = 1000
    
    X = np.random.rand(num_samples, *input_shape)
    y = np.random.randint(num_classes, size=num_samples)
    
    # 데이터셋 셔플 및 분할
    X, y = shuffle(X, y)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    #모델 생성 함수
    def create_model(learning_rate=0.001):
        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)
        x = base_model.output
        x = GlobalAveragePooling2D()(x)
        x = Dense(1024, activation='relu')(x)
        predictions = Dense(num_classes, activation='softmax')(x)
    
        model = Model(inputs=base_model.input, outputs=predictions)
        opt = Adam(learning_rate=learning_rate)
    
        model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
        return model
    
    # 하이퍼파라미터 분포 정의
    param_dist = {
        'learning_rate': uniform(0.001, 0.1),
        'batch_size': [16, 32, 64]
    }
    
    best_accuracy = 0
    best_params = {}
    n_iter = 5
    
    # 랜덤하게 하이퍼파라미터 조합을 선택하여 시도
    for params in ParameterSampler(param_dist, n_iter=n_iter, random_state=42):
        model = create_model(learning_rate=params['learning_rate'])
        model.fit(X_train, y_train, epochs=10, batch_size=params['batch_size'], validation_split=0.2, verbose=0)
    
        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
        print(f"Params: {params}, Test Accuracy: {accuracy}")
    
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_params = params
    
    print("Best Parameters (RandomSearch):", best_params)
    print("Best Test Accuracy (RandomSearch):", best_accuracy)
    
    # 최적의 하이퍼파라미터로 모델 재학습
    best_model = create_model(learning_rate=best_params['learning_rate'])
    best_model.fit(X_train, y_train, epochs=10, batch_size=best_params['batch_size'], validation_split=0.2)
    
    # 테스트 데이터셋으로 모델 평가
    test_loss, test_accuracy = best_model.evaluate(X_test, y_test)
    print(f"Test Accuracy: {test_accuracy:.2f}")
    print(f"Test Loss: {test_loss:.2f}")
    ```

    - 배치사이즈를 랜덤 조합을 한뒤, `n_iter` 를 사용하여 시행횟수를 조절한다.
    - 배치사이즈를 랜덤 조합하는 이유는 모델의 학습성능에 직결 되기 떄문이다.

        - 작은 배치 사이즈(16,32) 

            - 일반화 성능이 좋고, 노이즈를 잘 반영하지만 **학습속도가  느림(연산량이 많아져서)**

        - 큰 배치 사이즈(64이상) 

            - 학습 속도는 빠르지만, 특정 패턴을 너무 강하게 학습하여 **오버피팅 가능성**이 높아짐

            - 만약 10000개 데이터라면 10,000 / 64 =  156.25 번 업데이트 → 업데이트 횟수가 적으면 상대적으로 학습기회가 줄어들어 가중치를 찾을 기회가 감소

    | **배치 사이즈**         | **장점**                                 | **단점**                          |
    | ------------------ | -------------------------------------- | ------------------------------- |
    | **작음 (16, 32)**    | \- 일반화 성능(테스트 성능)이 좋음- 노이즈를 활용한 학습이 가능 | \- 학습 속도가 느림- GPU 메모리 사용이 낮음    |
    | **큼 (64, 128 이상)** | \- 학습 속도가 빠름- 병렬 처리 최적화                | \- 일반화 성능이 낮아질 가능성- 오버피팅 가능성 증가 |

    -  아래는 데이터 크기별 시행횟수 추천이다.

    | **데이터 크기**  | **시행 횟수 ()** |
    | ----------- | ------------ |
    | 1,000개 이하   | 5~10회        |
    | 10,000개 이상  | 20~50회       |
    | 100,000개 이상 | 50~100회      |


	- 왜 16, 32, 64 같은 배수만 사용하나?

		- GPU 연산 최적화에 있다.

    > 딥러닝 모델은 GPU에서 연산할때 `벡터연산` (SMID, Single Instruction Multiple Data) 방식을 사용한다.

    > GPU 메모리는 2의 거듭제곱 크기로 할당 된다.

    | **데이터셋 크기**           | **권장 배치 사이즈**   | **이유**                        |
    | --------------------- | --------------- | ----------------------------- |
    | 데이터가 적음 (ex. 10K 이하)  | **16 ~ 32**     | 더 많은 가변성을 반영하여 일반화 성능을 높임     |
    | 데이터가 많음 (ex. 100K 이상) | **32 ~ 64**     | 학습 속도를 빠르게 하면서도 적절한 일반화 성능 유지 |
    | 매우 큰 데이터셋 (ex. 1M 이상) | **64 ~ 128 이상** | 속도 최적화가 중요하므로 큰 배치 사이즈 사용     |
