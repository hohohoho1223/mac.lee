# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 개인과제 중간발표가 있는 날이었다.

---

1. Potato_Plant_Disease Dataset 사용 
   +  데이터셋 링크
        [https://www.kaggle.com/datasets/hafiznouman786/potato-plant-diseases-data/data](https://www.kaggle.com/datasets/hafiznouman786/potato-plant-diseases-data/data) 
2. 데이터내 이미지 검토 결과 전처리는 따로 필요없다고 느낌

3. 클래스가 3개 및 데이터 현저히 작음 -> **데이터 분할 (8:1:1)**

    1. Train 데이터에만 shuffle(True) 진행
        - 모델이 특정 순서에 의존하지 않게 하기 위해
        - 각 Epoch마다 데이터 순서를 바꿔주면 일반화 성능 향상에 도움
    2. Validation / Test 에서는 **모델의 성능 평가**용이므로, 고정된 데이터 순서로 **일관되게 평**가하여 신뢰성있는 결과내도록 의도 

        > 비슷한 이유로 데이터증강은 Train 데이터에만 적용, 그외 성능평가용 데이터는 원본 그대로 두었음. 

4. 첫 시도는  ResNet 50모델을 사용
    + ResNet50 

        ![Image.png](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/89B55099-8D45-486F-97D3-15058ACB929D/F5F6D015-C86E-4E29-82A2-CB74B28F21EC_2/TaLRVYekFkAXDNEsbj8ldy91Qzn0rgovKuAH4tvfRQAz/Image.png)

        - Test Loss: 0.1191
        - Test Accuracy: 97.79%
        - 너무 성능이 좋아 다른 모델로도 실행 및 비교 진행
5. VGG16 & MobileNetV2 & GoogLeNet & ResNet 18을 사용 및 비교를 진행
    - 테스트 정확도(에폭 50 & 조기중단 적용) 

        ![각 모델 test acc(구글넷 FT 제외).png](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/89B55099-8D45-486F-97D3-15058ACB929D/C1B12599-80ED-42C3-89DD-F2541B9F5541_2/ZxWcCvuospCbnev4SEX3VSPy98L1W7BDOwzJ8d36mjAz/%20%20test%20acc%20FT%20.png)

        - 이중, GoogLeNet 모델의 Test_Accuracy : **82.11%** 
        - GoogLeNet 의 모델성능을 올리는 방향으로 진행

            > 보조 분류기(Auxiliary Classifiers) 활성화 : `use_aux=True`

        + GoogLeNet은 언제 유리한가?
            - **작은 모델 크기**로도 성능이 우수해서 **리소스가 제한된 환경**에 적합.
            - 학습 안정성을 위해 보조 분류기를 쓰는 점이 **소규모 데이터셋 학습에도 유리**
            + GoogLeNet 구조요약

            ![🔍 GoogLeNet Architecture Flow.png](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/89B55099-8D45-486F-97D3-15058ACB929D/5995694D-F5C2-4D52-8986-1C6B6A6D703E_2/eclEcMuDTpNe1aEcyejBwJOBbbkWHX2ayyhxKP4hsHIz/%20GoogLeNet%20Architecture%20Flow.png)

            ```python
            [입력]
            ↓
            [Conv + Inception 모듈들 → Feature Extractor]
            ↓
            [Average Pooling (7x7)]
            ↓
            [Flatten → FC (분류기)]
            ↓
            [Softmax → 최종 출력 (3개 클래스 등)]
            ```

- Auxiliary Classifier의 위치는 중간에 위치
- 학습 시 보조 손실로위 사용되며, 성능 향상 및 gradient vanishing 방지 목적

6. 파인튜닝을 진행

    ![Image.png](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/89B55099-8D45-486F-97D3-15058ACB929D/15EAB474-69AA-474D-99F2-4BFBBA9426BA_2/yJxvZzYvxZzFj6xhjmXPthdICpG8pFsCevb40ZQ5ok8z/Image.png)

    |                           | Test_Accuracy | Method                             |
    | ------------------------- | ------------- | ---------------------------------- |
    | GoogLeNet (기존)            | **82.11%**    | 출력층만 수정, 나머지 미고정                   |
    | Fine-tuned (전체 파라미터)      | **93.87%**    |  **가장 높은 정확도**                     |
    | Feature Extractor (백본 고정) | **79.90%**    |  가중치 고정 상태에서 분류기만 학습               |
    | Gradual Unfreeze          | **92.16%**    | 성능 좋음, 다만 Full Fine-tuning보단 살짝 낮음 |

    ![Image.png](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/89B55099-8D45-486F-97D3-15058ACB929D/69D4C1B9-51C4-4EF3-AE90-B81E59938385_2/d3EuUqi4xFEwlxXbcobQNbgJRrNPVYp5jdNRZzlfXIYz/Image.png)

+ 왜  전체 파라미터 튜닝이 가장 높은 성능을 냈는가?
    - **GoogLeNet 전체 레이어를 모두 학습 가능하게 풀어놓고, 데이터셋에 맞춰 끝까지 미세조정함.**
    + 백본 고정(Feature Extractor) 이란?
        - pretrained 모델의 **backbone (특징 추출기 부분)** 을 고정하고 **마지막 출력 레이어만 학습**하는 방식
            - Pretained 모델 =특징 추출기(Backbone**)** + 분류기(Head)
            - 백본(Backbone) : 특징을 추출하는 파트
    + Gradual Unfreeze 이란?
        - 조금씩 백본을 풀어가며 학습하는 전략
            -  시작은 `freeze_base=True`로 backbone을 잠궈둠
        - 특정 epoch 이후에 점진적으로 **백본도 학습 가능하게 변경**

            > epoch == 5가 되면 **gradual unfreeze 로 잠금을 풀고 전체 파인튜닝 전환**
            > 너무 빨리 열면 backbone이 초기화된 출력층에 과도하게 적응해버리고
            > 너무 늦게 열면 backbone 튜닝할 시간이 부족 -> 효과가 미미
            > 적당한 시점(5 epoch) 이후에 열어준다 

- 파인튜닝 한답시고  Feature Extractor (백본 고정) 을 했는데, 오히려 왜 더 정확도가 낮아졌을까?
    - 이유1
        - **백본(Backbone)을 완전히 고정했기 때문**
        - Pretained 백본을 그대로 사용하고 **출력층만 새로 학습**한다
        - GoogLeNet은 ImageNet(1000개 클래스)에 맞게 학습된 필터를 가지고 있었기기에 감자 데이터셋 클래스3개에 필터가 잘 안맞을 수도 있다.
    - 이유 2
        - 출력층 혼자서는 **충분한 표현력이 부족**

            > 출력층의 역할 : 백본이 뽑은 특징을 기반으로 판단

        - **특정 조건에서는 표현력 부족 + 작은 데이터 + 고정된 특징 조합**이 오히려 **출력층만의 과적합** 발생 

---

## 현재 상태 & 추후 진행

1. 현재 상태 

s
| ---------------------- | --------------------------------------- |
| 1. Conv 일부 풀기          | 이미 **Gradual Unfreeze**로 실험함            |
| 2. 데이터 증강              | 현재 상당히 잘 적용됨 (Blur, Jitter, Affine 등)   |
| 🔸 3. Loss Function 변경 | ❗ **아직 미적용**                            |
| 🔸 4. Scheduler 변경     | ❗ **StepLR → ReduceLROnPlateau**로 전환 가능 |
| 🔸 5. 백본 변경            | EfficientNet 등으로 확장 실험 가능               |
| 🔸 6. TTA / 앙상블        | 추론 단계 성능 향상 전략                          |

2. **추후 진행**
    - **Feature Extractor에서 성능이 낮았던 이유 분석**
        - 출력층의 표현력 증가를 위해 FCL(Fully Connected Layer)의 층을 늘려보기
        - 하이퍼파라미터 튜닝 필요 (ReLU, Dropout 등도 같이 고려)
    - **Loss Function 변경**
        - CrossEntropyLoss(label_smoothing=0.1) → 일반화 성능 증가
        - FocalLoss → 어려운 샘플에 집중
        - Class-Balanced Loss → 클래스 불균형에 강함
    - **Scheduler 변경**
        - 학습률을 조절
            + **ReduceLROnPlateau** 

            ```python
            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)
            ```

            - 의미 : “검증 손실(val_loss)이 일정 에폭(patience) 동안 **좋아지지 않을때** lr을 줄인다” -> 효율적