# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 개인과제2 를 이어서 모델에 대해 좀더 알아보았다.

---

- 왜 모델을 경량화 하는가?

| **구분**        | **설명**                                                                  |
| ------------- | ----------------------------------------------------------------------- |
| 💡 **속도 개선**  | 대규모 모델(VGG16, ResNet 등)은 실시간 처리에 부적합할 수 있음.                             |
| 💡 **메모리 절약** | 모바일/엣지 디바이스에는 GPU가 없거나 메모리 자원이 부족함.                                     |
| 💡 **배터리 절약** | 작은 모델은 전력 소모가 적고 지속적인 사용이 가능함.                                          |
| 💡 **배포 용이성** | 모델 크기를 줄이면 모바일 앱/웹에서 쉽게 배포 가능함 (PyTorch → ONNX → TensorRT or TFLite 등). |

- 어떤 모델이 경량화에 적정한가?>

| **모델**          | **파라미터 수** | **경량화 적합성** | **특징**                               |
| --------------- | ---------- | ----------- | ------------------------------------ |
| **VGG16**       | 약 138M     | ❌ 낮음        | 구조 단순, 성능은 좋으나 너무 큼                  |
| **ResNet18**    | 약 11M      | 🔶 중간       | skip connection으로 효율은 있으나 경량화는 한계 있음 |
| **GoogLeNet**   | 약 6.6M     | 🔷 보통       | inception 구조로 경량화 중간 수준              |
| **MobileNetV2** | 약 3.4M     | ✅ 매우 좋음     | depthwise conv 사용 → 경량화 최적화 모        |

- **내 모델에서 경량화 가능한가?**

| **항목**         | **가능 여부**        | **방법**                           |
| -------------- | ---------------- | -------------------------------- |
| GoogLeNet      | 🔷 **부분 경량화 가능** | 양자화, pruning, torchscript로 변환 가능 |
| MobileNetV2    | ✅ **이미 경량화 구조**  | 양자화 시 더 경량화 가능 (예: INT8 변환)      |
| VGG16 / ResNet | ❌ **크게 불리함**     | pruning하면 정확도 손실 위험 큼            |

- 경량화의 구체적인 방법은?

| **기법**                     | **설명**                      |
| -------------------------- | --------------------------- |
| **Pruning (가지치기)**         | 불필요한 weight 제거 → 연산 줄이기     |
| **Quantization**           | float32 → int8 등 낮은 정밀도로 변환 |
| **Knowledge Distillation** | 큰 모델의 지식을 작은 모델로 전달         |
| **TorchScript 변환**         | 파이토치 모델을 C++/모바일 배포용으로 변환   |
| **ONNX 변환**                | 다양한 플랫폼에서 호환되도록 변환          |