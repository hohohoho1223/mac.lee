# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 조기 중단 & Hyperparameter에 대해 배웠다.

---

- 정규화(=정칙화/regularization) 머신러닝과 딥러닝 모델에서 과적합을 방지하고 모델의 일반화 성능을 향상시키기 위해 사용되는 기술

    - 뉴런의 활성화를 제어

    - 데이터의 변동성이나 복잡성에 모델이 과도하게 적응하지 않도록

    - 특화를 줄여서 일반화를 하려는 시도(?) → 이게 normalization 아닌가
    > 정칙화도 일종의 정규화의 일부임. 하지만 머신러닝에서는 정칙화랑 정규화를 구별해서 쓴다.

    > 정칙화(Regularization) : 가중치를 조정하는것(모델의 복잡성을 낮춰 일반화 성능 향상)
    > 정규화(Normalization) : 입력데이터의 분포를 고르게 하는것(0~1사이)

---

- 조기중단(Early Stopping)

    - 과적합 방지(모델이 validation 단계에서 더이상 Loss가 안줄어들때)
    - 훈련 시간 절약(Epoch수를 지나치게 많이해서 낭비되는일이 없게끔)
    - 최적의 모델 선택

        - 다이나믹 프로그래밍(DP)

        - DP를 사용하면 **한 번 계산한 값을 저장하고 재사용하여 중복 계산을 없앨 수 있습니다**.

        - 두가지 방법

            - **Top-Down (메모이제이션)**

            - **Bottom-Up (반복문)**

        - **피보나치 수열** : F(n) = F(n-1) + F(n-2)로 예를 들어보자.

    - Top-Down(메모이제이션)

        - 재귀 호출을 이용하여 필요한 경우에만 부분문제 해결

        - 이미 계산된 값은 **배열에 저장**하여 중복 계산 방지

        - 보통 재귀 + 메모이제이션(배열) 사용

    ```py
    # 필요한 값만 계산하며, 중복 계산을 피함
    def fib(n, memo={}):
        if n <= 1:
            return n
        if n not in memo:
            memo[n] = fib(n-1, memo) + fib(n-2, memo)
        return memo[n]
    
    print(fib(10))  # 55
    ```


    > 여기서 `memo` 는 캐시(Cashe)역할을 한다.

    > 또한 `memo[n]` 는 리스트가 아닌 '딕셔너리’의 n의 키(key)를 뜻한다!

    > 왜 딕셔너리를 쓰는가? → 필요한 값만 저장하므로 메모리 사용량을 줄일수 있다

	- Bottom-Up(반복문)

        - 작은 문제부터 차례대로 해결하여 답 구함

        - 보통은 반복문 + 배열(테이블)을 사용하여 구현

    ```python
    def fib(n):
        dp = [0] * (n + 1)
        dp[1] = 1
    
        for i in range(2, n + 1):
          dp[i] = dp[i - 1] + dp[i - 2]
    
        return dp[n]
    
    print(fib(10))  # 55
    ```


	- Bottom-Up (공간 최적화)

    ```python
    def fib(n):
        if n <= 1:
            return n
    
        prev2, prev1 = 0, 1 # 변수 2개만 사용해 메모리 절약
        for _ in range(2, n + 1):
            curr = prev1 + prev2
            prev2, prev1 = prev1, curr
        
        return prev1
    
    print(fib(10))  # 55
    ```

    1. **최단 경로 알고리즘 (플로이드-워셜)**
    2. **배낭 문제 (Knapsack Problem)**
    3. **최장 공통 부분 수열 (LCS)**
    4. **동전 거스름돈 문제 (Coin Change Problem)**

    - 얼리 스탑핑 조건 설정

        - 검증손실(Validation Loss)이 더이상 감소하지않을때

        - 파이토치에서는 내장된 Early Stopping이 없으므로 직접 구현해야함ㄷㄷ

    ```python
    #Early Stopping 구현
    class EarlyStopping:
        def __init__(self, patience=3, min_delta=0):
            self.patience = patience
            self.min_delta = min_delta
            self.counter = 0
            self.best_loss = None
            self.early_stop = False
    
        def __call__(self, val_loss):
            if self.best_loss is None:
                self.best_loss = val_loss
            elif val_loss > self.best_loss - self.min_delta:
                self.counter += 1
                if self.counter >= self.patience:
                    self.early_stop = True
            else:
                self.best_loss = val_loss
                self.counter = 0
    
    early_stopping = EarlyStopping(patience=3, min_delta=0.001)
    ```

	- Hyperparameter Tuning

| **이름**                             | **내용**                                                     | **예시**                        |
| ---------------------------------- | ---------------------------------------------------------- | ----------------------------- |
| 학습 속도(Learning Rate)               | 가중치 업데이트의 크기를 결정하는 값                                       | 0.01, 0.001, 0.0001           |
| 배치 크기(Batch Size)                  | 한 번에 학습할 데이터 샘플의 개수                                        | 32, 64, 128                   |
| 에포크(Epochs)                        | 전체 데이터셋을 몇 번 반복하여 학습할지를 결정                                 | 10, 50, 100                   |
| 옵티마이저(Optimizer)                   | 모델 학습 과정을 최적화하는 알고리즘 선택                                    | SGD, Adam, RMSprop            |
| 모멘텀(Momentum)                      | SGD와 같은 옵티마이저에서 기울기 업데이트에 대한 관성을 추가하여 학습을 가속화하고 안정화하는 파라미터 | 0.9, 0.95, 0.99               |
| 드롭아웃 비율(Dropout Rate)              | 학습 과정에서 무작위로 뉴런을 끄는 비율                                     | 0.2, 0.5                      |
| 정규화 파라미터(Regularization Parameter) | 과적합을 방지하기 위해 가중치에 패널티를 부여하는 값                              | L2 정규화(lambda) 값: 0.01, 0.001 |
| 학습률 감쇠(Learning Rate Decay)        | 학습이 진행됨에 따라 학습률을 감소시키는 방법                                  | 0.1, 0.01, 0.001              |
| 활성화 함수(Activation Function)        | 각 뉴런의 출력값을 결정하는 함수                                         | ReLU, Sigmoid, Tanh           |
| 초기화 방법(Initialization Method)      | 가중치 초기화 방법                                                 | He, Glorot, Random            |
----


- 가중치를 왜 설정하는것일까?
    - 가중치는 실제값에 도달하기위해 사용되는 변수이다
    - 모델이 ‘학습한다’는 것은 가중치를 ‘조정한다’는 것이다.
    - 하지만, 층이 깊어질수록 기울기 소실 문제가 나타날수 있다. 아래 코드는 해당 경우를 나타낸것이다.

    ```python
    import numpy as np
    import matplotlib.pyplot as plt
    
    # Sigmoid 활성화 함수와 그 미분
    def sigmoid(x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(x):
        return sigmoid(x) * (1 - sigmoid(x))
    
    # 깊이 1~10의 신경망에서 기울기 변화 확인
    depths = range(1, 11)
    gradients = []
    
    x = np.random.randn(1)  # 임의의 입력값
    
    for depth in depths:
        grad = 1  # 초기 기울기
        for _ in range(depth):
            grad *= sigmoid_derivative(x)  # 각 층에서 기울기 업데이트
        gradients.append(grad)
    
    # 그래프 출력
    plt.plot(depths, gradients, marker='o')
    plt.xlabel("Network Depth (Number of Layers)")
    plt.ylabel("Gradient Value")
    plt.title("Vanishing Gradient Problem")
    plt.show()
    ```


![image](https://res.craft.do/user/full/641ffdb9-6693-37da-6dbd-e78e1756c2de/doc/3c17d71c-25ef-2249-36c5-6ac2c9747d25/CC933EF1-DB2D-48A2-8C69-CD832DF5BAEE_2/t8BX1IwheqPntBUQdC2waQxOaxSy9mocJCXovKeiNY0z/Image.png)


- 기울기 소실 해결 방안은 다음과 같다.
	1. 활성화 함수 변경(ReLU)

        - x>0 일때 ReLU의 기울기가 항상 1이므로, 깇은 신경망에서도 학습이 가능하다.

        - 그런데, x <=0 인경우, 출력이 항상 0으로 고정됨

        - 그래서 기울기가 0 이므로, 역전파할때 가중치 업데이트가 일어나지 않음

        - 결국 일부 뉴런이 죽는 ‘Dying ReLU’ 현상이 발생할수 있음

    → 그래서 `Leaky ReLU` 함수를 사용함.
    → x <= 0 일때 함수값을 0.01x로 설정하여 기울기 학습이 가능한 파라미터로 설정함.

	2.  가중치 초기화 개선

        - 기존에는 가중치를 랜덤하게 초기화 했지만, 가중치 값이 극단적일때 기울기 소실이 나타났음

        - 가중치를 입/출력 뉴런 개수에 맞춰 적절히 초기화하는 Xavier 초기화, He초기화 사용

            - Xavier - 적절한 분포에서 가중치를 초기화 하는 방법

			    - 주로 Sigmoid, Tanh 같은 양극성(-1~1) 활성화 함수와 함꼐 사용
                > W \sim \mathcal{N} \left(0, \frac{1}{n_{\text{in}} + n_{\text{out}}} \right)


				- 가중치 W를 정규분포 또는 균등분포에서 샘플링(각 입/출력 뉴런의 개수로 나눠서 균등하게 샘플링함)

				- 근데 ReLU함수에서 음수부분을 0으로 만들기 때문에 평균이 더 작아짐 → 그래서 He 초기화 사용!

			- He 초기화(Kaiming Initialization) - Xavier 초기화의 단점을 보완함

                > W \sim \mathcal{N} \left(0, \frac{2}{n_{\text{in}}} \right) 

                - Xavier와의 차이점 → He 초기화는 입력 뉴턴 수만 고려하고, 2를 분모에 추가

                - ReLU는 음수 값을 0으로 바꾸므로 출력의 평균&분산이 줄어들게됨 → 출력 값의 분산이 작아짐 → 역전파를 통해 전달되는 기울기(Gradient)값도 작아짐 →  학습 멈춤

                - 따라서 이를 보정하기위해 Xavier 초기화보다 **더 큰 분산을** 사용(분모가 더 작으므로 → 약 루트2배 더 큰 분산을 가짐)


	3. Batch Normalization 사용

		- 각 층의 입력데이터를 정규화 하여 기울기 변화를 줄이고 안정적인 학습을 유도


	4. 잔차 연결(Residual Connections, ResNet)

		- 각 출력층의 기울기 정보를 전파하여 소실되지 않도록 하는 기법

		-  `x → F(x) + x`  형식임

---

- 근데 역전파 과정에서 왜 편미분을 기울기로 사용할까?

    - 편미분은 각 가중치가 손실(Loss)에 미치는 영향을 측정하기 때문이다.

    - 즉, 가중치가 얼마나 손실을 증가/감소 시키는지를 나타내는것을 기반으로 가중치를 업데이트 하기 위함이다!

    - 신경망 학습의 목표 : 손실함수 L을 최소화하는 가중치 W를 찾아라!

        > 손실함수 L이 가중치 W에 대해 어떻게 변화하는지(경사/Gradient)를  알아야함

        > 이때 사용하는것이 편미분이다.


- <정리>

    가중치와 편향값을 가지고 순전파를 통과한 뒤, 역전파를 통해 가중치를 업데이트 하게 되는데, 이때 **손실함수를 가중치에 대해 편미분**하여 그래디언트(기울기)가 가장 빠르게 움직이는 지점을 찾아 반대 방향으로 이동하여 손실함수의 최소값을 찾아 가중치를 조정한다. 이떼 step의 크기는 그레디언트의 크기에 곱해지는 계수로 학습률을 나타낸다.
