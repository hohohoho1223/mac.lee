# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 개인과재2 진행했다!

---

- [ ] 앙상블 모델 설계해보기
    + 앙상블 모델(Ensemble Model)
    > 여러 개의 개별 모델을 결합해 하나의 강력한 모델을 만드는 방법

    - > 하나의 모델은 전문가 한명
    - > 앙상블은 **여러전문가의 의견을 모아 최종 결정**
    - > 앙상블 모델은 다양한 모델의 **장점을 결합**해 단일 모델보다 **더 강력하고 일반화된 예측 성능**을 얻기 위한 전략

    | **목표**      | **설명**                          |
    | ----------- | ------------------------------- |
    | ✅ 성능 향상     | 단일 모델보다 **정확도, F1-score 등**을 높임 |
    | ✅ 안정성 증가    | 특정 모델의 **과적합/노이즈 영향**을 줄임       |
    | ✅ 일반화 능력 향상 | 테스트 데이터에 대해 더 잘 작동하게 함          |

    - 앙상블 모델 설계 구성요소
        1. 개별 모델 선택
            - 서로 다른 아키텍처를 가진 모델 고르기( VGG16, ResNet50 , MobileNet)
            - 또는 같은 모델이더라도 데이터 샘플/ 하이퍼파라미터를 다르게 설정
        2. 훈련
            - 각 모델 독립적으로 학습
        3. 예측 결합 방식 선택
            - Hard Voting
            - Soft Voting
            - Stacking
            - Bagging
            - Boosting
        4. 최종 출력 계산
            - Voting 결과를 기반으로 최종 예측을 반환

| **방식**       | **설명**                          | **예시**             |
| ------------ | ------------------------------- | ------------------ |
| **Bagging**  | 데이터 샘플을 무작위로 뽑아 **여러 모델 병렬 학습** | Random Forest      |
| **Boosting** | 이전 모델이 틀린 부분을 보완하는 **순차 학습**    | XGBoost, LightGBM  |
| **Stacking** | 여러 모델의 예측 결과를 다시 다른 모델이 학습      | base 모델 + meta 모델  |
| **Voting**   | 여러 모델의 예측을 결합해 **투표 방식으로 예측**   | Hard / Soft Voting |

- 앙상블 설계 제안 (Soft Voting 기반)
    - **팁: GoogLeNet 제외 앙상블도 시도해보세요**
    - GoogLeNet을 넣었을 때 정확도가 낮아질 수도 있습니다.
    - Soft Voting → 최적 앙상블 조합 찾기 (그리디 탐색) 도 가능해요.
    - 그리디 탐색 : 전체 최적보장 안하지만 **매 단계 가장 최선의 선택을 하는것(빠름)**

---

## Softmax 출력값이 필요함 → .pth파일 속 가중치로 구하자!

    - best.pth vs final.pth 차이점

| **구분**       | **best.pth**                                          | **final.pth**                |
| ------------ | ----------------------------------------------------- | ---------------------------- |
| 의미           | Early Stopping 기준으로 **검증 성능(Val Acc)이 가장 좋았던 시점**의 모델 | 모든 에폭(예: 50)에 도달한 **마지막 모델** |
| 보통 더 좋은 선택은? | ✅ **best.pth**                                        | ⛔ overfitting 가능             |
| 왜?           | 일반적으로 검증 성능이 가장 좋았던 타이밍에서 모델을 저장한 것이기 때문              |                              |

> 👉 소프트보팅 앙상블에서는 다양성(diversity)이 중요하기 때문에

> 성능이 낮아도 **의미 있는 역할**을 할 수 있음!!

- 최종 확정 조합

| **모델**    | **사용할 파일명**             |
| --------- | ----------------------- |
| GoogLeNet | googlenet_best.pth ✅    |
| VGG16     | vgg16_best.pth ✅        |
| MobileNet | mobilenet_v2_best.pth ✅ |
| ResNet18  | resnet18_best.pth ✅     |

- `model = models.googlenet(pretrained=True, aux_logits=True)` 이것은 구조만 포함시킨것이지 실제 학습에 사용하려면 
- loss 계산 시 aux도 반영해야 함

    ```python
    outputs = model(images)
    if isinstance(outputs, tuple) or hasattr(outputs, 'logits'):
        outputs = outputs.logits  # ✅ aux는 여기서 무시됨
    ```

    - **“GoogLeNet 앙상블에 aux는 무시해야 해?”**
    - aux는 성능보다 보조 목적, main 출력이 최종 결과이므로 aux는 무시하고 main output만 ensemble 사용 권장

| 항목                  | 설명                                     |
| ------------------- | -------------------------------------- |
| aux_logits=True 설정  | 모델 구조에 aux1, aux2 포함 (옵션적으로)           |
| 실제 학습 시 aux 사용      | ❌ 하지 않음 (loss 계산에 포함 안 됨)              |
| softmax 추출 시 aux 사용 | ❌ 하지 않음 (logits만 추출)                   |
| 결론                  | 💯 aux 구조는 있어도 실제 결과에는 전혀 영향 없음! 걱정 ㄴㄴ |

- 표로 정리하자면

| **모델**        | **문제 유형**                                  | **에러 메시지 요약**                                   | **원인**                                                                  | **해결 방법**                                                                                |
| ------------- | ------------------------------------------ | ----------------------------------------------- | ----------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- |
| **GoogLeNet** | size mismatch                              | aux1.fc2.weight, aux2.fc2.weight shape mismatch | 저장된 모델은 aux_logits=True (클래스 1000), 현재 모델은 클래스 3                        | 🔧 aux_logits=True로 모델 생성하고,❗ state_dict에서 aux1.fc2, aux2.fc2 key 제거 후 strict=False 로 로딩 |
| **GoogLeNet** | unexpected key                             | aux1.*, aux2.* 키가 예상치 못한 key로 인식됨               | 저장된 모델은 aux 포함 (aux_logits=True)인데,불러오는 모델은 aux_logits=False로 aux 구조 없음 | 🔧 모델을 aux_logits=True로 생성하고,그에 맞게 구조 일치시켜야 함                                            |
| **VGG16**     | missing key, unexpected key, size mismatch | features 블록에서 다수의 키 mismatch                    | 학습은 vgg16(BatchNorm 없음)으로 했는데,불러올 때 vgg16_bn(BatchNorm 있음)으로 불러옴        | ✅ 저장 시 사용한 구조인 models.vgg16()으로 정확히 맞춰서 불러오기 (❌ vgg16_bn)                                |

---

## 알게된것들

- 파일 폴더 경로 설정할때 띄어쓰기 조심하기 /abc != / abc → 틀림!!!

| **확장자** | **의미**          | **내용**                          |
| ------- | --------------- | ------------------------------- |
| .pth    | PyTorch Weights | state_dict (모델 가중치)             |
| .pt     | PyTorch 객체 저장   | softmax, tensor, dict 등 아무거나 가능 |

- 내가 처음에 생각한 앙상블 모델 구조는

    > 말씀하신 건 **구조적 앙상블(Structural Ensemble)** 또는

    > **Fusion 모델**, 또는 **멀티-백본 모델** 같은 형태임

- 이거고 백본 조합 구조

```python
[GoogLeNet conv layers]     [ResNet conv layers]
           ↓                      ↓
          Concat (Feature Fusion) → Shared FC Layer → Prediction
```

- 이런 모델은 각 백본에서 특징(geature)을 추출하고 그걸 합쳐서 하나의 예측으로 만드는 형태임.
- 지피티가 알려준것은 **“후처리 기반의 확률 앙상블”** 임

    > 모델 구조를 새로 설계하거나 결합하지 않고

    > 각각 독립적으로 **학습된 모델들의 출력값**(softmax 확률)만 가지고 조합

```python
학습된 GoogLeNet
      ↓
     .pth (가중치 저장)
      ↓
  test_loader → Softmax 확률
                        ↘
학습된 ResNet           앙상블 평균 → 최종 예측
      ↓                    ↗
     .pth                ...
```

 - 오직 최종 softmax결과만 평균냄ㅇㅇ

---

- 리퀘스트 & 리스폰스 (요청-응답 사이클)
- 서버 효율화가 필요_ 여러 서버를 돌릴 수 있는 가상환경 구축
    - 로드밸런서 → 분배하는 역할
- PaaS
- Microservices
    - twilio(SaaS) 

| **전략**                        | **시도 여부** | **설명**                           |
| ----------------------------- | --------- | -------------------------------- |
| 전체 학습 (fine-tuning)           | ✅         | 모든 레이어 학습                        |
| 백본 freeze (feature extractor) | ✅         | fc/aux만 학습                       |
| Gradual Unfreeze              | ✅         | 초기엔 freeze, 특정 시점부터 점진적 unfreeze |
| 보조 분류기(aux) 사용                | ✅         | GoogLeNet 특화 기능 활용               |

- 추가로 고려해볼 수 있는 것들
    1. 데이터셋 클래스 불균형 보정
        - class_weight 또는 oversampling
    1. Loss 변경
        - CrossEntropy → Focal Loss 등으로 미세조정
    3. **Test셋과의 Domain  Gap 존재 여부 체크**
        - train/ val 은 잘 맞는데, test만 낮다면, distribution 차이 의심
        - test 이미지 전처리 , 해상도, 비율 확인
    1. Dropout추가 / Augmentation 강화
        - GoogLeNet 내부 Dropout 확률 조정
        - 이미지 augmentation 다양화(RandomErase, AutoAugment 등)