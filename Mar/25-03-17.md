# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 7주차 과제를 진행하였다.

---

1. OpenAIEmbeddings 클래스를 사용해 문장 임베딩을 해보세요.

2. 사용자의 상황이나 배경을 제공해주면 그에 따라 이메일 양식을 만들어주는 챗봇을 만들어보세요.
    ex) 거래처에 새해 인사와 함께 신규 계약건에 대해 이메일을 보내야한다.

3. 최신 뉴스를 브리핑 해주는 챗봇을 만들어보세요.

---

# 1. OpenAIEmbeddings 클래스를 사용해 문장 임베딩을 해보세요.

```python
import openai
import os
from dotenv import load_dotenv

load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    raise ValueError("❌ OpenAI API 키가 설정되지 않았습니다. Colab 비밀 변수에서 'OPENAI_API_KEY'를 추가하세요.")
else:
    print("✅ OpenAI API 키가 정상적으로 로드되었습니다.")

# OpenAI 클라이언트 생성
client = openai.Client(api_key=api_key)

def get_openai_embedding(text, model="text-embedding-ada-002"):
    """
    주어진 텍스트를 OpenAI 임베딩 모델을 사용하여 벡터로 변환하는 함수.

    :param text: 변환할 입력 텍스트 (문자열)
    :param model: 사용할 임베딩 모델 (기본값: "text-embedding-ada-002")
    :return: 임베딩 벡터 (리스트)
    """
    response = client.embeddings.create(
        input=[text],  # 최신 API는 리스트 형식으로 입력 필요
        model=model
    )
    return response.data[0].embedding

# 
text = "아 학부에다가 경력이 없는데 어떻게 취업하지?"
embedding = get_openai_embedding(text)
print(f"임베딩 벡터:{embedding}")
```

- `text`   : 변환할 입력 테스트(string)
- `model="text-embedding-ada-002"` : 사용할 임베딩 모델을 지정
    - 몰론 특정 모델을 쓰고싶으면 설정이 가능하다
- `response.data[0].embedding`  을 사용하는 이유?

```python
response = client.embeddings.create(
    input=[text],  # 최신 API는 리스트 형식으로 입력 필요
    model=model
)
return response.data[0].embedding
```

- OpenAI의 임베딩 API를 호출하면 `response` 라는 객체가 반환됨
- `response` 구조

```python
{
  "data": [
    {
      "embedding": [0.123, 0.456, ...],  # 변환된 벡터 데이터(리스트)
      "index": 0,   # 이 문장이 원래 입력 리스트에서 몇 번째였는지 나타냄
      "object": "embedding"
    }
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 12,
    "total_tokens": 12
  }
}
```

> 나는 여기서 data[0] 을 사용하면 “embedding” 리스트에서 첫번째 값이라고 생각했다.

- `data[0]` 을 하면 전체 embedding 딕셔너리를 가져온다.
-  `”index=0”` 은 입력 리스트에서 몇 번째였는지 나타냄

-  data[0]을 선택하는 이유?
    - `response[“data”]`는 **입력된 문장 개수만큼의 리스트**를 반환함
    - 하지만 우리는 단일 문장에 대한 임베딩을 요청했으므로, data 리스트에는 **오직 하나의 항목만 존재함**
    -  따라서 `response["data”][0]`  을 통해 첫번째(그리고 유일한) 항목을 가져온다.
- `.embedding` 을 선택한 이유?
    - `data[0]` 내부에는 여러정보가 들어 있지만, 우리가 필요한 것은 embedding 이므로 텍스트가 벡터로 변환된 **실제 데이터**를 반환해야함

- **그럼 단일문장을 임베딩 할것이란걸 어떻게 알았나?**

    > 사실 코드만 보면 단일 문장을 임베딩할 것이라고 확신할 수 있는 근거는 없음. 다만 몇가지 정황과 코드 작성 패턴을 통해 단일 문장을 처리한다고 추론함

    1. 리스트 형태로 감싸는 방식

    ```python
    response = client.embeddings.create(
        input=[text],  # 최신 API는 리스트 형식으로 입력 필요
        model=model
    )
    ```
        - OpenAI의 임베딩 API는 **리스트 형**태의 입력을 기대함
        - 그런데 text 변수를 리스트 형태 `[text]` 로 감싼다는점에서 사용자가 단일 문장을 넣을 것으로 예상 할 수 있음
        - if, 다중 문장을 고려했다면 `text` 가 리스트인지 먼저 체크하는 로직이 있어야 함

    2. `response.data[0]` 을 직접 반환
        -  만약 여러문장이 입력될 가능성이 있다면, response.data는 리스트이므로, 여러 개의 값을 처리하는 로직이 필요

    3.  함수 호출 방식
        -  만약 다중 문장을 고려했가면 text를 **리스트**로 전달했을 가능성이 큼

---

## 추가 코드 리뷰 ##

```py
#최신 패키지 설치
!pip install -U langchain-huggingface sentence-transformers

# 새로운 모듈에서 HuggingFaceEmbeddings 주입
from langchain_huggingface import HuggingFaceEmbeddings

# BERT 기반 임베딩 모델 로드(단일 문장/쿼리 임베딩)
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

#임베딩할 텍스트 설정
input_text = "Alex는 친절합니다. 화이팅!"

#텍스트 데이터를 벡터로 변환 및 출력
vector = embedding_model.embed_query(input_text)
print(vector)
```

- `embed_query()` : 단일 문장을 벡터로 변환
- `embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")`
    > 해당 코드는 `HuggingFaceEmbeddings`를 사용했으며 `단일 문장`을 벡터로 변환
- 이 모델은 사전 학습됨 모델이며 문장을 384차원 벡터로 변환하도록 설계되었다.
- L6 : 6개의 `Transformer` 레이어를 갖고 있다는 뜻

    > 몰론 차원이 더 큰 벡터를 포함한 모델도 존재함  
- 여기서 질문이 생겼다.

    > Q. 트랜스포머도 벡터화 하는데 왜 문장임베딩에는 따로 모델이 필요한걸까?

    > A. 트랜스포머는 입력 문장을 `토큰단위`로 변환한 후, 각 토큰을 벡터로 표현함 -> 기본적으로 토큰단위의 벡터만 출력할 뿐, 문장 ㅌ체를 하나의 벡터로 변환해주지 않는다!

    1. [CLS] 토큰 사용: BERT 계열 모델에서는 첫번째 [CLS] 토큰을 문장의 대표 벡터로 사용
        But, 최적의 성능이 안나옴(텍스트 분류에선 유용)
        - CLS(Classification) : BERT계열 트랜스포머 모델에서 입력 문장의 첫 번째에 자동으로 추가되는 `특수 토큰`임.
        - SEP(Separator) : 문장 끝에 붙는 토큰
    
    2. 토큰 벡터들의 평균값(Pooling)
        - 문장의 모든 단어(토큰) 벡터를 평균내어 하나의 문장 벡터로 만듦
        - sentence-transformer 라이브러리의 방식임
    
    3. Fine-tuning된 문장 임베딩 모델 사용
        - sentence-transformers 같은 라이브러리는 문장 벡터를 잘 추출할 수 있도록 `추가학습`한 모델을 제공


```python
# 문서 임베딩(BERT기반)
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2') # 사전 학습된 BERT모델

documents = ["나는 오늘 커피를 마셨다.", "커피는 정말 맛있다.", "나는 오늘 커피를 마시고 자전거를 타며 산책했다."]

document_embeddings = model.encode(documents) #여러개의 문장을 한꺼번에 벡터로 변환(유사도 분석 및 추천 시스템)

print(document_embeddings.shape)  # (문서 개수, 벡터 차원)
```

- 해당 코드는 여러개 문장을 벡터로 변환
- `encode()` : 여러개의 문장을 한꺼번에 벡터화
- BERT 임베딩 방식은 애초에 처음부터 384차원 벡터로 변환하기에, 희소행렬이 아닌 '밀집 행렬' 형태이다!(각 차원마다 실수 값을 가짐)

- 주요 차이점 비교

| **특징**    | **HuggingFaceEmbeddings **(LangChain)**** | **SentenceTransformer **(일반 문서 임베딩)**** |
| --------- | ----------------------------------------- | --------------------------------------- |
| **주요 목적** | 검색/챗봇 쿼리 임베딩                              | 문서(여러 문장) 벡터화                           |
| **입력**    | 단일 문장 (input_text)                        | 여러 문장 리스트 (documents)                   |
| **출력 크기** | (384,) → 1개 벡터                            | (문서 개수, 384) → 여러 개 벡터                  |
| **사용 예시** | LangChain 기반 검색 시스템                       | 문서 유사도 분석, 추천 시스템                       |

- TF (Term Frequency, 단어 빈도) VS TF-IDF(Term Frequency-Inverse Document Frequency)

```python
from sklearn.feature_extraction.text import TfidfVectorizer

documents = ["This is a sample document.", "Document embedding is useful.", "We use embeddings for NLP tasks."]

vectorizer = TfidfVectorizer() # 영어의 불용어 제거, 소문자로 변환, 단어 토큰화 수행
# 불용어란?> 자연어 처리에서 빈번하게 등장하지만, 분석에 큰 의미를 주지 않는 단어들 (the, is, in, and)

#텍스트 데이터 변환
X = vectorizer.fit_transform(documents) # X는 변환된 문서들의 TF-IDF 벡터를 담고 있는 행렬 : 희소 행렬임

print(X) # TF-IDF 값이 출력(TF * IDF 값) IDF
print(vectorizer.get_feature_names_out()) # 단어 인덱스를 알 수 있다
print(X.toarray()) # 희소 행렬을 밀집 행렬로 변환
```

- 해당 코드는 TF-IDF 이므로 임베딩이 아닌 "문서표현(Document Representation)" 방식중 하나인 `벡터화` 이다!
- TF-IDF 는 단순한 가중치 벡터일 뿐, 문장의 의미를 학습하는것이 아님.

- 여기서 TF-IDF 값이 출력된다.
- TF 값이 높다 -> 해당문서내 빈도수가 높은 단어
- IDF 값이 높다 -> 단어가 해당 문서 '내에서만' 등장하는 단어임(다른문서에선 별로 안나타나지만 중요단어 일수도 있음)

| **방법**   | **장점**              | **단점**      | **활용 사례**         |
| -------- | ------------------- | ----------- | ----------------- |
| TF-IDF   | 빠르고 가벼움, 키워드 검색에 강함 | 문맥을 반영하지 못함 | 기본 검색, 키워드 기반 필터링 |
| BERT 임베딩 | 문맥을 반영한 의미 기반 벡터 생성 | 연산 비용이 큼    | 의미 기반 검색, 추천 시스템  |

---

# 2. 사용자의 상황이나 배경을 제공해주면 그에 따라 이메일 양식을 만들어주는 챗봇을 만들어보세요.

```py
import os
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# 프롬프트 정의
prompt = PromptTemplate.from_template("""
사용자의 상황 및 배경을 통해 이메일 양식을 작성하시오.
발신자 : {sender}
수신자 : {receiver}
상황 : {situation}
배경 : {background}
언어 : {language}
""")

llm_model = ChatOpenAI(model_name="gpt-4", openai_api_key=api_key)
llm_chain = LLMChain(llm=llm_model, prompt=prompt)

sender = input("발신자를 입력하세요: ")
receiver = input("수신자를 입력하세요: ")
situation = input("상황을 입력하세요: ")
background = input("배경을 입력하세요: ")
language = input("언어를 입력하세요: ")

result = llm_chain.run(sender=sender,receiver = receiver, situation = situation, background = background,language=language)
print(f"아래는 이메일 양식입니다.: \n",result)
```

- 해당 코드는 API KEY를 이용하여 프롬프트 설계를 진행 하였다.

- 결과

```
발신자를 입력하세요: mac
수신자를 입력하세요: alex
상황을 입력하세요: 새해인사
배경을 입력하세요: 카카오 부트캠프 수료후 맞이하는 첫 새해날
언어를 입력하세요: 한국어
아래는 이메일 양식입니다.: 
 제목: 새해의 시작을 함께하는 기쁨을 담아

안녕하세요, Alex님.

새해가 밝아왔습니다. 새로운 한 해가 우리 모두에게 행운을 가져다주기를 바라며, 무엇보다 Alex님께서는 건강하시고, 일상에서 행복을 느끼실 수 있는 한 해가 되시길 진심으로 기원합니다.

지난 해 우리가 함께한 카카오 부트캠프는 저에게 많은 것을 가르쳐주었습니다. 그 중에서도 Alex님과 함께한 시간은 저에게 가장 큰 성장의 원동력이었습니다. 감사의 마음을 담아 이렇게 글을 적게 되었습니다.

새해에는 새로운 시작이 있기를 바랍니다. Alex님과 함께할 수 있는 기회가 또다시 있기를 소망하며, 그때까지 Alex님의 일상이 더욱 풍요롭고, 행복이 가득하시길 바랍니다.

새해 복 많이 받으세요.

Mac 드림.
```

---

# 3. 최신 뉴스를 브리핑 해주는 챗봇을 만들어보세요.

```py
import openai
import os
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import time

# 환경 변수 로드
load_dotenv()

def latest_news():
    url = "https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko" # RSS 피드로 설정
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    session = requests.Session()
    response = session.get(url, headers=headers)

    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "xml")
        headlines = soup.find_all("title")[1:6]  # 최신 뉴스 5개 가져오기 (첫 번째는 'Google 뉴스' 제목이므로 제외)

        if not headlines:
            return ["뉴스 데이터를 가져올 수 없습니다. (구조 변경 가능)"]

        return [headline.get_text(strip=True) for headline in headlines]
    else:
        return [f"뉴스 요청 실패 (응답 코드: {response.status_code})"]

def generate_news_briefing():
    news_list = latest_news()
    news_context = "\n".join(news_list)

    # OpenAI API 키 불러오기
    api_key = os.getenv("OPENAI_API_KEY")
    # OpenAI API 호출
    client = openai.OpenAI(api_key=api_key)

    messages = [
        {"role": "system", "content": "너는 브리핑해주는 챗봇이야. 한국어로 요약하고 알려줘"},
        {"role": "user", "content": f"가장 최근의 뉴스 헤드라인이야.\n{news_context}\n전문적이고 사실에 근거하여 요약해줘"}
    ]

    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        max_tokens=500
    )

    return response.choices[0].message.content.strip()

if __name__ == "__main__":
    # 뉴스 브리핑 생성
    try:
        news_briefing = generate_news_briefing()
        print("Latest News Briefing:\n", news_briefing)
    except ValueError as e:
        print("오류:", e)
```

- `url = "https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko"`
- 해당 코드는 RSS(Really Simple Syndication) 피드로 url을 설정했음(구글 뉴스를 Parsing)

    >  뉴스, 블로그 등의 콘텐츠를 `XML` 형식으로 제공하는 표준 방식임

    > 이 피드를 사용하면 특정 뉴스 웹사이트에 직접 방문하지 않고도 최신뉴스 기사 목록을 받아 볼수 있음.

    - hl = ko
    > 한국어로 뉴스 제공

    - gl = KR
    > 대한민국 지역 뉴스 제공

    - ceid = KR:ko
    > 대한민국 뉴스 + 한국어로 제공