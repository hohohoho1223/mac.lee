# 오늘 내가 배운 것들(Today I Learned)

- 오늘은 7주차 과제를 진행하였다.

---

1. OpenAIEmbeddings 클래스를 사용해 문장 임베딩을 해보세요.

2. 사용자의 상황이나 배경을 제공해주면 그에 따라 이메일 양식을 만들어주는 챗봇을 만들어보세요.
    ex) 거래처에 새해 인사와 함께 신규 계약건에 대해 이메일을 보내야한다.

3. 최신 뉴스를 브리핑 해주는 챗봇을 만들어보세요.

---

# 1. OpenAIEmbeddings 클래스를 사용해 문장 임베딩을 해보세요.

```py
#최신 패키지 설치
!pip install -U langchain-huggingface sentence-transformers

# 새로운 모듈에서 HuggingFaceEmbeddings 주입
from langchain_huggingface import HuggingFaceEmbeddings

# BERT 기반 임베딩 모델 로드(단일 문장/쿼리 임베딩)
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

#임베딩할 텍스트 설정
input_text = "Alex는 친절합니다. 화이팅!"

#텍스트 데이터를 벡터로 변환 및 출력
vector = embedding_model.embed_query(input_text)
print(vector)
```

- `embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")`
- 이 모델은 사전 학습됨 모델이며 문장을 384차원 벡터로 변환하도록 설계되었다.
- L6 : 6개의 `Transformer` 레이어를 갖고 있다는 뜻
- 몰론 차원이 더 큰 벡터를 포함한 모델도 존재함
- 여기서 질문이 생겼다.

    > Q. 트랜스포머도 벡터화 하는데 왜 문장임베딩에는 따로 모델이 필요한걸까?

    > A. 트랜스포머는 입력 문장을 `토큰단위`로 변환한 후, 각 토큰을 벡터로 표현함 -> 기본적으로 토큰단위의 벡터만 출력할 뿐, 문장 ㅌ체를 하나의 벡터로 변환해주지 않는다!

    1. [CLS] 토큰 사용: BERT 계열 모델에서는 첫번째 [CLS] 토큰을 문장의 대표 벡터로 사용
        But, 최적의 성능이 안나옴(텍스트 분류에선 유용)
        - CLS(Classification) : BERT계열 트랜스포머 모델에서 입력 문장의 첫 번째에 자동으로 추가되는 `특수 토큰`임.
        - SEP(Separator) : 문장 끝에 붙는 토큰
    
    2. 토큰 벡터들의 평균값(Pooling)
        - 문장의 모든 단어(토큰) 벡터를 평균내어 하나의 문장 벡터로 만듦
        - sentence-transformer 라이브러리의 방식임
    
    3. Fine-tuning된 문장 임베딩 모델 사용
        - sentence-transformers 같은 라이브러리는 문장 벡터를 잘 추출할 수 있동ㄹ록 `추가학습`한 모델을 제공

---

```python
#최신 패키지 설치
!pip install -U langchain-huggingface sentence-transformers

# 새로운 모듈에서 HuggingFaceEmbeddings 주입
from langchain_huggingface import HuggingFaceEmbeddings

# BERT 기반 임베딩 모델 로드(단일 문장/쿼리 임베딩)
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

#임베딩할 텍스트 설정
input_text = "Alex는 친절합니다. 화이팅!"

#텍스트 데이터를 벡터로 변환 및 출력
vector = embedding_model.embed_query(input_text)
print(vector)
```

- 해당 코드는 `단일 문장`을 벡터로 변환
- `embed_query()` : 단일 문장을 벡터로 변환


```python
#최신 패키지 설치
!pip install -U langchain-huggingface sentence-transformers

# 새로운 모듈에서 HuggingFaceEmbeddings 주입
from langchain_huggingface import HuggingFaceEmbeddings

# BERT 기반 임베딩 모델 로드(단일 문장/쿼리 임베딩)
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

#임베딩할 텍스트 설정
input_text = "Alex는 친절합니다. 화이팅!"

#텍스트 데이터를 벡터로 변환 및 출력
vector = embedding_model.embed_query(input_text)
print(vector)
```

```python
# 문서 임베딩(BERT기반)
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2') # 사전 학습된 BERT모델

documents = ["나는 오늘 커피를 마셨다.", "커피는 정말 맛있다.", "나는 오늘 커피를 마시고 자전거를 타며 산책했다."]

document_embeddings = model.encode(documents) #여러개의 문장을 한꺼번에 벡터로 변환(유사도 분석 및 추천 시스템)

print(document_embeddings.shape)  # (문서 개수, 벡터 차원)
```

- 해당 코드는 여러개 문장을 벡터로 변환
- `encode()` : 여러개의 문장을 한꺼번에 벡터화
- BERT 임베딩 방식은 애초에 처음부터 384차원 벡터로 변환하기에, 희소행렬이 아닌 '밀집 행렬' 형태이다!(각 차원마다 실수 값을 가짐)

- 주요 차이점 비교

| **특징**    | **HuggingFaceEmbeddings **(LangChain)**** | **SentenceTransformer **(일반 문서 임베딩)**** |
| --------- | ----------------------------------------- | --------------------------------------- |
| **주요 목적** | 검색/챗봇 쿼리 임베딩                              | 문서(여러 문장) 벡터화                           |
| **입력**    | 단일 문장 (input_text)                        | 여러 문장 리스트 (documents)                   |
| **출력 크기** | (384,) → 1개 벡터                            | (문서 개수, 384) → 여러 개 벡터                  |
| **사용 예시** | LangChain 기반 검색 시스템                       | 문서 유사도 분석, 추천 시스템                       |

---

- TF (Term Frequency, 단어 빈도) VS TF-IDF(Term Frequency-Inverse Document Frequency)

```python
from sklearn.feature_extraction.text import TfidfVectorizer

documents = ["This is a sample document.", "Document embedding is useful.", "We use embeddings for NLP tasks."]

vectorizer = TfidfVectorizer() # 영어의 불용어 제거, 소문자로 변환, 단어 토큰화 수행
# 불용어란?> 자연어 처리에서 빈번하게 등장하지만, 분석에 큰 의미를 주지 않는 단어들 (the, is, in, and)

#텍스트 데이터 변환
X = vectorizer.fit_transform(documents) # X는 변환된 문서들의 TF-IDF 벡터를 담고 있는 행렬 : 희소 행렬임

print(X) # TF-IDF 값이 출력(TF * IDF 값) IDF
print(vectorizer.get_feature_names_out()) # 단어 인덱스를 알 수 있다
print(X.toarray()) # 희소 행렬을 밀집 행렬로 변환
```

- 여기서 TF-IDF 값이 출력된다.
- TF 값이 높다 -> 해당문서내 빈도수가 높은 단어
- IDF 값이 높다 -> 단어가 해당 문서 '내에서만' 등장하는 단어임(다른문서에선 별로 안나타나지만 중요단어 일수도 있음)

| **방법**   | **장점**              | **단점**      | **활용 사례**         |
| -------- | ------------------- | ----------- | ----------------- |
| TF-IDF   | 빠르고 가벼움, 키워드 검색에 강함 | 문맥을 반영하지 못함 | 기본 검색, 키워드 기반 필터링 |
| BERT 임베딩 | 문맥을 반영한 의미 기반 벡터 생성 | 연산 비용이 큼    | 의미 기반 검색, 추천 시스템  |

---

# 2. 사용자의 상황이나 배경을 제공해주면 그에 따라 이메일 양식을 만들어주는 챗봇을 만들어보세요.

```py
import os
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# 프롬프트 정의
prompt = PromptTemplate.from_template("""
사용자의 상황 및 배경을 통해 이메일 양식을 작성하시오.
발신자 : {sender}
수신자 : {receiver}
상황 : {situation}
배경 : {background}
언어 : {language}
""")

llm_model = ChatOpenAI(model_name="gpt-4", openai_api_key=api_key)
llm_chain = LLMChain(llm=llm_model, prompt=prompt)

sender = input("발신자를 입력하세요: ")
receiver = input("수신자를 입력하세요: ")
situation = input("상황을 입력하세요: ")
background = input("배경을 입력하세요: ")
language = input("언어를 입력하세요: ")

result = llm_chain.run(sender=sender,receiver = receiver, situation = situation, background = background,language=language)
print(f"아래는 이메일 양식입니다.: \n",result)
```

- 해당 코드는 API KEY를 이용하여 프롬프트 설계를 진행 하였다.

- 결과

```
발신자를 입력하세요: mac
수신자를 입력하세요: alex
상황을 입력하세요: 새해인사
배경을 입력하세요: 카카오 부트캠프 수료후 맞이하는 첫 새해날
언어를 입력하세요: 한국어
아래는 이메일 양식입니다.: 
 제목: 새해의 시작을 함께하는 기쁨을 담아

안녕하세요, Alex님.

새해가 밝아왔습니다. 새로운 한 해가 우리 모두에게 행운을 가져다주기를 바라며, 무엇보다 Alex님께서는 건강하시고, 일상에서 행복을 느끼실 수 있는 한 해가 되시길 진심으로 기원합니다.

지난 해 우리가 함께한 카카오 부트캠프는 저에게 많은 것을 가르쳐주었습니다. 그 중에서도 Alex님과 함께한 시간은 저에게 가장 큰 성장의 원동력이었습니다. 감사의 마음을 담아 이렇게 글을 적게 되었습니다.

새해에는 새로운 시작이 있기를 바랍니다. Alex님과 함께할 수 있는 기회가 또다시 있기를 소망하며, 그때까지 Alex님의 일상이 더욱 풍요롭고, 행복이 가득하시길 바랍니다.

새해 복 많이 받으세요.

Mac 드림.
```

---

# 3. 최신 뉴스를 브리핑 해주는 챗봇을 만들어보세요.

```py
import openai
import os
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import time

# 환경 변수 로드
load_dotenv()

def latest_news():
    url = "https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko" # RSS 피드로 설정
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    session = requests.Session()
    response = session.get(url, headers=headers)

    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "xml")
        headlines = soup.find_all("title")[1:6]  # 최신 뉴스 5개 가져오기 (첫 번째는 'Google 뉴스' 제목이므로 제외)

        if not headlines:
            return ["뉴스 데이터를 가져올 수 없습니다. (구조 변경 가능)"]

        return [headline.get_text(strip=True) for headline in headlines]
    else:
        return [f"뉴스 요청 실패 (응답 코드: {response.status_code})"]

def generate_news_briefing():
    news_list = latest_news()
    news_context = "\n".join(news_list)

    # OpenAI API 키 불러오기
    api_key = os.getenv("OPENAI_API_KEY")
    # OpenAI API 호출
    client = openai.OpenAI(api_key=api_key)

    messages = [
        {"role": "system", "content": "너는 브리핑해주는 챗봇이야. 한국어로 요약하고 알려줘"},
        {"role": "user", "content": f"가장 최근의 뉴스 헤드라인이야.\n{news_context}\n전문적이고 사실에 근거하여 요약해줘"}
    ]

    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        max_tokens=500
    )

    return response.choices[0].message.content.strip()

if __name__ == "__main__":
    # 뉴스 브리핑 생성
    try:
        news_briefing = generate_news_briefing()
        print("Latest News Briefing:\n", news_briefing)
    except ValueError as e:
        print("오류:", e)
```

- `url = "https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko"`
- 해당 코드는 RSS(Really Simple Syndication) 피드로 url을 설정했음(구글 뉴스를 Parsing)

    >  뉴스, 블로그 등의 콘텐츠를 `XML` 형식으로 제공하는 표준 방식임

    > 이 피드를 사용하면 특정 뉴스 웹사이트에 직접 방문하지 않고도 최신뉴스 기사 목록을 받아 볼수 있음.

    - hl = ko
    > 한국어로 뉴스 제공

    - gl = KR
    > 대한민국 지역 뉴스 제공

    - ceid = KR:ko
    > 대한민국 뉴스 + 한국어로 제공